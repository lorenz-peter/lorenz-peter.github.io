<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://lorenz-peter.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://lorenz-peter.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-18T11:15:29+00:00</updated><id>https://lorenz-peter.github.io/feed.xml</id><title type="html">blank</title><subtitle>Personal Website </subtitle><entry><title type="html">AdaMSI-FGM</title><link href="https://lorenz-peter.github.io/blog/2024/adaptive-mi-fgsm/" rel="alternate" type="text/html" title="AdaMSI-FGM"/><published>2024-12-30T16:40:16+00:00</published><updated>2024-12-30T16:40:16+00:00</updated><id>https://lorenz-peter.github.io/blog/2024/adaptive-mi-fgsm</id><content type="html" xml:base="https://lorenz-peter.github.io/blog/2024/adaptive-mi-fgsm/"><![CDATA[<h1 id="on-the-convergence-of-an-adaptive-momentum-method-for-adversarial-attacks">On the Convergence of an Adaptive Momentum Method for Adversarial Attacks</h1> <h2 id="introduction">Introduction</h2> <p>This paper [1] aims to fill the gap between empirical evaluations and theoretical fundamentals of MI-FGSM. MI-FGSM improves the itertive FGSM (i-FGSM or BIM) by adding a momenumt which helps to overcome local minima and hence the adversarial examples transfer better. However, it is a sign-based attack method, where the sign gives an bound of the magnitude of the gradient step. Sign-based methods fail to converge to the optimum in convex settings. To address these concerns, the authors propose a novel method (AdaMSI-FGM), which incorporates both an innovative adaptive momentum parameter with monotonicity assumptions and an adaptive step-size scheme that replaces the sign operation.</p> <h2 id="key-insights">Key insights</h2> <ul> <li>Sign-based attack methods are well-known and this better showed there is still research to be done.</li> <li>The sign method can be replaced with an adaptive update step.</li> <li>Derive a regret upper bound for general convex functions.</li> </ul> <h1 id="references">References</h1> <ul> <li>[1] <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29323">On the Convergence of an Adaptive Momentum Method for Adversarial Attack, 2024, AAAI.</a></li> </ul>]]></content><author><name></name></author><category term="adversarial-examples"/><category term="paper"/><summary type="html"><![CDATA[On the Convergence of an Adaptive Momentum Method for Adversarial Attacks]]></summary></entry><entry><title type="html">AutoAttack</title><link href="https://lorenz-peter.github.io/blog/2024/autoattack/" rel="alternate" type="text/html" title="AutoAttack"/><published>2024-12-19T16:40:16+00:00</published><updated>2024-12-19T16:40:16+00:00</updated><id>https://lorenz-peter.github.io/blog/2024/autoattack</id><content type="html" xml:base="https://lorenz-peter.github.io/blog/2024/autoattack/"><![CDATA[<h1 id="autoattack-for-adversarial-robustness">AutoAttack for Adversarial Robustness</h1> <h2 id="introduction">Introduction</h2> <p>Adversarial training is about robustify a neural network against adversarial attacks.</p> <ul> <li>More details: <a href="https://adversarial-ml-tutorial.org/adversarial_training">here</a>.</li> <li>Link to <a href="https://arxiv.org/pdf/2003.01690">AutoAttack</a>.</li> </ul> <h2 id="key-insights">Key insights</h2> <p>Authors do not argue that AutoAttack [1] is the ultimate adversarial attack but rather that it should become the minimal test for any new defense, since it reliably reaches good performance in all tested models, without any hyperparameter tuning and at a relatively low computational cost.</p> <p>3 weaknesses of PGD:</p> <ol> <li>Fixed step size: suboptimal, even for convex problems this does not guarantee convergence, and the performance of the algorithm is highly influenced by the choice of the value. [2]</li> <li>Agnostic of the budget: The loss plateaus after a few iterations, except for extremely small step sizes, which however do not translate into better results. Judging the strength of an attack by the number of iterations is misleading. [3]</li> <li>Unaware of the trend: Does not consider whether the optimization is evolving successfully and is not able to react of this. Authors present an automatic scheme fixing this issue.</li> </ol> <h1 id="references">References</h1> <ul> <li>[1] [2003.01690] Reliable Evaluation of Adversarial Robustness with an Ensemble of Diverse Parameter-free Attacks</li> <li>[2] [1810.12042] Logit Pairing Methods Can Fool Gradient-Based Attacks</li> <li>[3] [1902.06705] On Evaluating Adversarial Robustness</li> </ul>]]></content><author><name></name></author><category term="adversarial-examples"/><category term="paper"/><summary type="html"><![CDATA[AutoAttack for Adversarial Robustness]]></summary></entry><entry><title type="html">Clear Thinking: Turning Ordinary Moments into Extraordinary Results</title><link href="https://lorenz-peter.github.io/blog/2024/clear-thinking-turning-ordinary-moments-into-extraordinary-results/" rel="alternate" type="text/html" title="Clear Thinking: Turning Ordinary Moments into Extraordinary Results"/><published>2024-11-29T09:43:09+00:00</published><updated>2024-11-29T09:43:09+00:00</updated><id>https://lorenz-peter.github.io/blog/2024/clear-thinking-turning-ordinary-moments-into-extraordinary-results</id><content type="html" xml:base="https://lorenz-peter.github.io/blog/2024/clear-thinking-turning-ordinary-moments-into-extraordinary-results/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Confidence in public speaking and presenting</title><link href="https://lorenz-peter.github.io/blog/2024/confidence-in-public-speaking-and-presenting/" rel="alternate" type="text/html" title="Confidence in public speaking and presenting"/><published>2024-11-08T07:56:29+00:00</published><updated>2024-11-08T07:56:29+00:00</updated><id>https://lorenz-peter.github.io/blog/2024/confidence-in-public-speaking-and-presenting</id><content type="html" xml:base="https://lorenz-peter.github.io/blog/2024/confidence-in-public-speaking-and-presenting/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">How to lead when you are not in charge?</title><link href="https://lorenz-peter.github.io/blog/2024/how-to-lead-when-you-are-not-in-charge/" rel="alternate" type="text/html" title="How to lead when you are not in charge?"/><published>2024-11-03T05:46:47+00:00</published><updated>2024-11-03T05:46:47+00:00</updated><id>https://lorenz-peter.github.io/blog/2024/how-to-lead-when-you-are-not-in-charge</id><content type="html" xml:base="https://lorenz-peter.github.io/blog/2024/how-to-lead-when-you-are-not-in-charge/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Parse the Paper List</title><link href="https://lorenz-peter.github.io/blog/2024/load-json/" rel="alternate" type="text/html" title="Parse the Paper List"/><published>2024-11-02T18:37:00+00:00</published><updated>2024-11-02T18:37:00+00:00</updated><id>https://lorenz-peter.github.io/blog/2024/load-json</id><content type="html" xml:base="https://lorenz-peter.github.io/blog/2024/load-json/"><![CDATA[<div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/load_json.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="research"/><category term="research"/><summary type="html"><![CDATA[Parse the json file]]></summary></entry><entry><title type="html">Regulate your blood sugar! — Nourish to Flourish: Harnessing Glycogen for Peak Performance at Work</title><link href="https://lorenz-peter.github.io/blog/2024/regulate-your-blood-sugarnourish-to-flourish-harnessing-glycogen-for-peak-performance-at-work/" rel="alternate" type="text/html" title="Regulate your blood sugar! — Nourish to Flourish: Harnessing Glycogen for Peak Performance at Work"/><published>2024-10-19T10:28:22+00:00</published><updated>2024-10-19T10:28:22+00:00</updated><id>https://lorenz-peter.github.io/blog/2024/regulate-your-blood-sugarnourish-to-flourish-harnessing-glycogen-for-peak-performance-at-work</id><content type="html" xml:base="https://lorenz-peter.github.io/blog/2024/regulate-your-blood-sugarnourish-to-flourish-harnessing-glycogen-for-peak-performance-at-work/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Analysis of Adversarial Examples (PhD Thesis)</title><link href="https://lorenz-peter.github.io/blog/2024/phdthesis/" rel="alternate" type="text/html" title="Analysis of Adversarial Examples (PhD Thesis)"/><published>2024-08-31T16:40:16+00:00</published><updated>2024-08-31T16:40:16+00:00</updated><id>https://lorenz-peter.github.io/blog/2024/phdthesis</id><content type="html" xml:base="https://lorenz-peter.github.io/blog/2024/phdthesis/"><![CDATA[<h1 id="analysis-of-adversarial-examples">Analysis of Adversarial Examples</h1> <p>I earned my PhD with magna cum laude from Heidelberg University, Germany, where I was advised by my ex-team lead <a href="https://www.itwm.fraunhofer.de/en/departments/hpc/staff/janis-keuper.html">Janis Keuper</a> and supervised by Prof. <a href="https://hci.iwr.uni-heidelberg.de/vislearn/people/ullrich-koethe">Ullrich Köthe</a>. I am an external Ph.D. student at the University of Heidelberg (2nd best-ranked German university). My key research interest was the <strong>analysis of adversarial examples</strong> on DNN. In particular, deep neural networks’ <strong>robustness</strong> and <strong>trustworthiness</strong>.</p> <p>I also had the opportunity to intern with Prof. Sijia Liu (<a href="https://lsjxjtu.github.io/">MSU</a> &amp; <a href="https://mitibmwatsonailab.mit.edu/people/sijia-liu/">MIT-IBM</a>) and Pin-Yu Chen (<a href="https://sites.google.com/site/pinyuchenpage/home">MIT-IBM</a>), focusing on adversarial machine learning. Our “Visual Prompting for Adversarial Robustness” paper achieved recognition within the top 3% at the ICASSP conference.</p> <h2 id="thesis-abstract">Thesis Abstract</h2> <p>The rise of artificial intelligence (AI) has significantly impacted the field of computer vision (CV). In particular, deep learning (DL) has advanced the development of algorithms that comprehend visual data. In specific tasks, DL exhibits human capabilities and is impacting our everyday lives such as virtual assistants, entertainment or web searches. Despite of the success of visual algorithms, in this thesis we study the threat adversarial examples, which are input manipulation to let to misclassification.</p> <h2 id="important-links">Important Links</h2> <p><a href="https://www.mathinf.uni-heidelberg.de/en/thesis-defenses/analysis-of-adversarial-examples-2024-07-30">Defense announcement</a></p> <p><a href="https://drive.google.com/file/d/1tgZ5exAoadPo64Rd4rc7cAEjTGCuQi63/view?usp=sharing">Slides</a></p> <p><a href="https://archiv.ub.uni-heidelberg.de/volltextserver/35211/1/main.pdf">Thesis</a></p>]]></content><author><name></name></author><category term="thesis"/><category term="adversarial"/><category term="examples"/><summary type="html"><![CDATA[research]]></summary></entry><entry><title type="html">Habits</title><link href="https://lorenz-peter.github.io/blog/2024/habits/" rel="alternate" type="text/html" title="Habits"/><published>2024-06-06T16:21:53+00:00</published><updated>2024-06-06T16:21:53+00:00</updated><id>https://lorenz-peter.github.io/blog/2024/habits</id><content type="html" xml:base="https://lorenz-peter.github.io/blog/2024/habits/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">How to write a good scientific review?</title><link href="https://lorenz-peter.github.io/blog/2024/how-to-write-a-good-scientific-review/" rel="alternate" type="text/html" title="How to write a good scientific review?"/><published>2024-06-06T16:05:07+00:00</published><updated>2024-06-06T16:05:07+00:00</updated><id>https://lorenz-peter.github.io/blog/2024/how-to-write-a-good-scientific-review</id><content type="html" xml:base="https://lorenz-peter.github.io/blog/2024/how-to-write-a-good-scientific-review/"><![CDATA[]]></content><author><name></name></author></entry></feed>