[
    {
        "date": "2025-08",
        "title": "Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video",
        "author": "Dave Goel, Matthew Guzdial, and Anurag Sarkar",
        "link": "http://arxiv.org/abs/2508.11836v1",
        "abstract": "World models are defined as a compressed spatial and temporal learned\nrepresentation of an environment. The learned representation is typically a\nneural network, making transfer of the learned environment dynamics and\nexplainability a challenge. In this paper, we propose an approach, Finite\nAutomata Extraction (FAE), that learns a neuro-symbolic world model from\ngameplay video represented as programs in a novel domain-specific language\n(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more\nprecise model of the environment and more general code than prior DSL-based\napproaches."
    },
    {
        "date": "2025-08",
        "title": "VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models",
        "author": "Ming Cheng, Tong Wu, Jiazhen Hu, Jiaying Gong, and Hoda Eldardiry",
        "link": "http://arxiv.org/abs/2508.11801v1",
        "abstract": "Attribute Value Extraction (AVE) is important for structuring product\ninformation in e-commerce. However, existing AVE datasets are primarily limited\nto text-to-text or image-to-text settings, lacking support for product videos,\ndiverse attribute coverage, and public availability. To address these gaps, we\nintroduce VideoAVE, the first publicly available video-to-text e-commerce AVE\ndataset across 14 different domains and covering 172 unique attributes. To\nensure data quality, we propose a post-hoc CLIP-based Mixture of Experts\nfiltering system (CLIP-MoE) to remove the mismatched video-product pairs,\nresulting in a refined dataset of 224k training data and 25k evaluation data.\nIn order to evaluate the usability of the dataset, we further establish a\ncomprehensive benchmark by evaluating several state-of-the-art video vision\nlanguage models (VLMs) under both attribute-conditioned value prediction and\nopen attribute-value pair extraction tasks. Our results analysis reveals that\nvideo-to-text AVE remains a challenging problem, particularly in open settings,\nand there is still room for developing more advanced VLMs capable of leveraging\neffective temporal information. The dataset and benchmark code for VideoAVE are\navailable at: https://github.com/gjiaying/VideoAVE"
    },
    {
        "date": "2025-08",
        "title": "Model Interpretability and Rationale Extraction by Input Mask Optimization",
        "author": "Marc Brinner, and Sina Zarriess",
        "link": "http://arxiv.org/abs/2508.11388v1",
        "abstract": "Concurrent to the rapid progress in the development of neural-network based\nmodels in areas like natural language processing and computer vision, the need\nfor creating explanations for the predictions of these black-box models has\nrisen steadily. We propose a new method to generate extractive explanations for\npredictions made by neural networks, that is based on masking parts of the\ninput which the model does not consider to be indicative of the respective\nclass. The masking is done using gradient-based optimization combined with a\nnew regularization scheme that enforces sufficiency, comprehensiveness and\ncompactness of the generated explanation, three properties that are known to be\ndesirable from the related field of rationale extraction in natural language\nprocessing. In this way, we bridge the gap between model interpretability and\nrationale extraction, thereby proving that the latter of which can be performed\nwithout training a specialized model, only on the basis of a trained\nclassifier. We further apply the same method to image inputs and obtain high\nquality explanations for image classifications, which indicates that the\nconditions proposed for rationale extraction in natural language processing are\nmore broadly applicable to different input types."
    },
    {
        "date": "2025-08",
        "title": "Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks",
        "author": "Jiaqi Yin, Yi-Wei Chen, Meng-Lung Lee, and Xiya Liu",
        "link": "http://arxiv.org/abs/2508.07179v1",
        "abstract": "Enterprise data pipelines, characterized by complex transformations across\nmultiple programming languages, often cause a semantic disconnect between\noriginal metadata and downstream data. This \"semantic drift\" compromises data\nreproducibility and governance, and impairs the utility of services like\nretrieval-augmented generation (RAG) and text-to-SQL systems. To address this,\na novel framework is proposed for the automated extraction of fine-grained\nschema lineage from multilingual enterprise pipeline scripts. This method\nidentifies four key components: source schemas, source tables, transformation\nlogic, and aggregation operations, creating a standardized representation of\ndata transformations. For the rigorous evaluation of lineage quality, this\npaper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that\nassesses both structural correctness and semantic fidelity. A new benchmark is\nalso presented, comprising 1,700 manually annotated lineages from real-world\nindustrial scripts. Experiments were conducted with 12 language models, from\n1.3B to 32B small language models (SLMs) to large language models (LLMs) like\nGPT-4o and GPT-4.1. The results demonstrate that the performance of schema\nlineage extraction scales with model size and the sophistication of prompting\ntechniques. Specially, a 32B open-source model, using a single reasoning trace,\ncan achieve performance comparable to the GPT series under standard prompting.\nThis finding suggests a scalable and economical approach for deploying\nschema-aware agents in practical applications."
    },
    {
        "date": "2025-08",
        "title": "Towards Effective Prompt Stealing Attack against Text-to-Image Diffusion Models",
        "author": "Shiqian Zhao, Chong Wang, Yiming Li, Yihao Huang, Wenjie Qu, Siew-Kei Lam, Yi Xie, Kangjie Chen, Jie Zhang, and Tianwei Zhang",
        "link": "http://arxiv.org/abs/2508.06837v1",
        "abstract": "Text-to-Image (T2I) models, represented by DALL$\\cdot$E and Midjourney, have\ngained huge popularity for creating realistic images. The quality of these\nimages relies on the carefully engineered prompts, which have become valuable\nintellectual property. While skilled prompters showcase their AI-generated art\non markets to attract buyers, this business incidentally exposes them to\n\\textit{prompt stealing attacks}. Existing state-of-the-art attack techniques\nreconstruct the prompts from a fixed set of modifiers (i.e., style\ndescriptions) with model-specific training, which exhibit restricted\nadaptability and effectiveness to diverse showcases (i.e., target images) and\ndiffusion models.\n  To alleviate these limitations, we propose Prometheus, a training-free,\nproxy-in-the-loop, search-based prompt-stealing attack, which reverse-engineers\nthe valuable prompts of the showcases by interacting with a local proxy model.\nIt consists of three innovative designs. First, we introduce dynamic modifiers,\nas a supplement to static modifiers used in prior works. These dynamic\nmodifiers provide more details specific to the showcases, and we exploit NLP\nanalysis to generate them on the fly. Second, we design a contextual matching\nalgorithm to sort both dynamic and static modifiers. This offline process helps\nreduce the search space of the subsequent step. Third, we interact with a local\nproxy model to invert the prompts with a greedy search algorithm. Based on the\nfeedback guidance, we refine the prompt to achieve higher fidelity. The\nevaluation results show that Prometheus successfully extracts prompts from\npopular platforms like PromptBase and AIFrog against diverse victim models,\nincluding Midjourney, Leonardo.ai, and DALL$\\cdot$E, with an ASR improvement of\n25.0\\%. We also validate that Prometheus is resistant to extensive potential\ndefenses, further highlighting its severity in practice."
    },
    {
        "date": "2025-08",
        "title": "SPEX: A Vision-Language Model for Land Cover Extraction on Spectral Remote Sensing Images",
        "author": "Dongchen Si, Di Wang, Erzhong Gao, Xiaolei Qin, Liu Zhao, Jing Zhang, Minqiang Xu, Jianbo Zhan, Jianshe Wang, Lin Liu, Bo Du, and Liangpei Zhang",
        "link": "http://arxiv.org/abs/2508.05202v1",
        "abstract": "Spectral information has long been recognized as a critical cue in remote\nsensing observations. Although numerous vision-language models have been\ndeveloped for pixel-level interpretation, spectral information remains\nunderutilized, resulting in suboptimal performance, particularly in\nmultispectral scenarios. To address this limitation, we construct a\nvision-language instruction-following dataset named SPIE, which encodes\nspectral priors of land-cover objects into textual attributes recognizable by\nlarge language models (LLMs), based on classical spectral index computations.\nLeveraging this dataset, we propose SPEX, a multimodal LLM designed for\ninstruction-driven land cover extraction. To this end, we introduce several\ncarefully designed components and training strategies, including multiscale\nfeature aggregation, token context condensation, and multispectral visual\npre-training, to achieve precise and flexible pixel-level interpretation. To\nthe best of our knowledge, SPEX is the first multimodal vision-language model\ndedicated to land cover extraction in spectral remote sensing imagery.\nExtensive experiments on five public multispectral datasets demonstrate that\nSPEX consistently outperforms existing state-of-the-art methods in extracting\ntypical land cover categories such as vegetation, buildings, and water bodies.\nMoreover, SPEX is capable of generating textual explanations for its\npredictions, thereby enhancing interpretability and user-friendliness. Code\nwill be released at: https://github.com/MiliLab/SPEX."
    },
    {
        "date": "2025-08",
        "title": "A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health",
        "author": "Song Wang, Yishu Wei, Haotian Ma, Max Lovitt, Kelly Deng, Yuan Meng, Zihan Xu, Jingze Zhang, Yunyu Xiao, Ying Ding, Xuhai Xu, Joydeep Ghosh, and Yifan Peng",
        "link": "http://arxiv.org/abs/2508.05003v1",
        "abstract": "Background: Understanding social determinants of health (SDoH) factors\ncontributing to suicide incidents is crucial for early intervention and\nprevention. However, data-driven approaches to this goal face challenges such\nas long-tailed factor distributions, analyzing pivotal stressors preceding\nsuicide incidents, and limited model explainability. Methods: We present a\nmulti-stage large language model framework to enhance SDoH factor extraction\nfrom unstructured text. Our approach was compared to other state-of-the-art\nlanguage models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning\nmodels (i.e., DeepSeek-R1). We also evaluated how the model's explanations help\npeople annotate SDoH factors more quickly and accurately. The analysis included\nboth automated comparisons and a pilot user study. Results: We show that our\nproposed framework demonstrated performance boosts in the overarching task of\nextracting SDoH factors and in the finer-grained tasks of retrieving relevant\ncontext. Additionally, we show that fine-tuning a smaller, task-specific model\nachieves comparable or better performance with reduced inference costs. The\nmulti-stage design not only enhances extraction but also provides intermediate\nexplanations, improving model explainability. Conclusions: Our approach\nimproves both the accuracy and transparency of extracting suicide-related SDoH\nfrom unstructured texts. These advancements have the potential to support early\nidentification of individuals at risk and inform more effective prevention\nstrategies."
    },
    {
        "date": "2025-08",
        "title": "VisuCraft: Enhancing Large Vision-Language Models for Complex Visual-Guided Creative Content Generation via Structured Information Extraction",
        "author": "Rongxin Jiang, Robert Long, Chenghao Gu, and Mingrui Yan",
        "link": "http://arxiv.org/abs/2508.02890v1",
        "abstract": "This paper introduces VisuCraft, a novel framework designed to significantly\nenhance the capabilities of Large Vision-Language Models (LVLMs) in complex\nvisual-guided creative content generation. Existing LVLMs often exhibit\nlimitations in maintaining high visual fidelity, genuine creativity, and\nprecise adherence to nuanced user instructions when generating long-form texts.\nVisuCraft addresses these challenges by integrating a multimodal structured\ninformation extractor (E) and a dynamic prompt generation module (G). The\nextractor distills fine-grained visual attributes from input images into a\nrich, structured representation, which the dynamic prompt module then combines\nwith user instructions to create highly optimized prompts for underlying LVLMs\n(e.g., LLaVA, InstructBLIP). Evaluated on the self-constructed\nImageStoryGen-500K dataset using VisuGen Metrics (Visual Grounding, Creativity,\nand Instruction Adherence), VisuCraft consistently outperforms baseline LVLMs\nacross tasks like story generation and poetry composition. Our results\ndemonstrate remarkable improvements, particularly in creativity and instruction\nadherence, validating VisuCraft's effectiveness in producing imaginative,\nvisually grounded, and user-aligned long-form creative text. This work unlocks\nnew potential for LVLMs in sophisticated creative AI applications."
    },
    {
        "date": "2025-08",
        "title": "Contextual Graph Transformer: A Small Language Model for Enhanced Engineering Document Information Extraction",
        "author": "Karan Reddy, and Mayukha Pal",
        "link": "http://arxiv.org/abs/2508.02532v1",
        "abstract": "Standard transformer-based language models, while powerful for general text,\noften struggle with the fine-grained syntax and entity relationships in complex\ntechnical, engineering documents. To address this, we propose the Contextual\nGraph Transformer (CGT), a hybrid neural architecture that combines Graph\nNeural Networks (GNNs) and Transformers for domain-specific question answering.\nCGT constructs a dynamic graph over input tokens using sequential, skip-gram,\nand semantic similarity edges, which is processed by GATv2Conv layers for local\nstructure learning. These enriched embeddings are then passed to a Transformer\nencoder to capture global dependencies. Unlike generic large models, technical\ndomains often require specialized language models with stronger\ncontextualization and structure awareness. CGT offers a parameter-efficient\nsolution for such use cases. Integrated into a Retrieval-Augmented Generation\n(RAG) pipeline, CGT outperforms baselines like GPT-2 and BERT, achieving 24.7%\nhigher accuracy than GPT-2 with 62.4% fewer parameters. This gain stems from\nCGTs ability to jointly model structural token interactions and long-range\nsemantic coherence. The model is trained from scratch using a two-phase\napproach: pretraining on general text followed by fine-tuning on\ndomain-specific manuals. This highlights CGTs adaptability to technical\nlanguage, enabling better grounding, entity tracking, and retrieval-augmented\nresponses in real-world applications."
    },
    {
        "date": "2025-07",
        "title": "Benefits of Feature Extraction and Temporal Sequence Analysis for Video Frame Prediction: An Evaluation of Hybrid Deep Learning Models",
        "author": "Jose M. S\u00e1nchez Vel\u00e1zquez, Mingbo Cai, Andrew Coney, \u00c1lvaro J. Garc\u00eda- Tejedor, and Alberto Nogales",
        "link": "http://arxiv.org/abs/2508.00898v1",
        "abstract": "In recent years, advances in Artificial Intelligence have significantly\nimpacted computer science, particularly in the field of computer vision,\nenabling solutions to complex problems such as video frame prediction. Video\nframe prediction has critical applications in weather forecasting or autonomous\nsystems and can provide technical improvements, such as video compression and\nstreaming. Among Artificial Intelligence methods, Deep Learning has emerged as\nhighly effective for solving vision-related tasks, although current frame\nprediction models still have room for enhancement. This paper evaluates several\nhybrid deep learning approaches that combine the feature extraction\ncapabilities of autoencoders with temporal sequence modelling using Recurrent\nNeural Networks (RNNs), 3D Convolutional Neural Networks (3D CNNs), and related\narchitectures. The proposed solutions were rigorously evaluated on three\ndatasets that differ in terms of synthetic versus real-world scenarios and\ngrayscale versus color imagery. Results demonstrate that the approaches perform\nwell, with SSIM metrics increasing from 0.69 to 0.82, indicating that hybrid\nmodels utilizing 3DCNNs and ConvLSTMs are the most effective, and greyscale\nvideos with real data are the easiest to predict."
    },
    {
        "date": "2025-07",
        "title": "Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic Cystic Lesion Feature Extraction and Risk Categorization",
        "author": "Ebrahim Rasromani, Stella K. Kang, Yanqi Xu, Beisong Liu, Garvit Luhadia, Wan Fung Chui, Felicia L. Pasadyn, Yu Chih Hung, Julie Y. An, Edwin Mathieu, Zehui Gu, Carlos Fernandez-Granda, Ammar A. Javed, Greg D. Sacks, Tamas Gonda, Chenchan Huang, and Yiqiu Shen",
        "link": "http://arxiv.org/abs/2507.19973v1",
        "abstract": "Background: Manual extraction of pancreatic cystic lesion (PCL) features from\nradiology reports is labor-intensive, limiting large-scale studies needed to\nadvance PCL research. Purpose: To develop and evaluate large language models\n(LLMs) that automatically extract PCL features from MRI/CT reports and assign\nrisk categories based on guidelines. Materials and Methods: We curated a\ntraining dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134\npatients that described PCLs. Labels were generated by GPT-4o using\nchain-of-thought (CoT) prompting to extract PCL and main pancreatic duct\nfeatures. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated\nCoT data. Features were mapped to risk categories per institutional guideline\nbased on the 2017 ACR White Paper. Evaluation was performed on 285 held-out\nhuman-annotated reports. Model outputs for 100 cases were independently\nreviewed by three radiologists. Feature extraction was evaluated using exact\nmatch accuracy, risk categorization with macro-averaged F1 score, and\nradiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning\nimproved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79%\nto 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved\n(LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no\nstatistically significant differences. Radiologist inter-reader agreement was\nhigh (Fleiss' Kappa = 0.888) and showed no statistically significant difference\nwith the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT\n(Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels\non par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT\nsupervision enable accurate, interpretable, and efficient phenotyping for\nlarge-scale PCL research, achieving performance comparable to GPT-4o."
    },
    {
        "date": "2025-07",
        "title": "Deepfake Detection Via Facial Feature Extraction and Modeling",
        "author": "Benjamin Carter, Nathan Dilla, Micheal Callahan, and Atuhaire Ambala",
        "link": "http://arxiv.org/abs/2507.18815v1",
        "abstract": "The rise of deepfake technology brings forth new questions about the\nauthenticity of various forms of media found online today. Videos and images\ngenerated by artificial intelligence (AI) have become increasingly more\ndifficult to differentiate from genuine media, resulting in the need for new\nmodels to detect artificially-generated media. While many models have attempted\nto solve this, most focus on direct image processing, adapting a convolutional\nneural network (CNN) or a recurrent neural network (RNN) that directly\ninteracts with the video image data. This paper introduces an approach of using\nsolely facial landmarks for deepfake detection. Using a dataset consisting of\nboth deepfake and genuine videos of human faces, this paper describes an\napproach for extracting facial landmarks for deepfake detection, focusing on\nidentifying subtle inconsistencies in facial movements instead of raw image\nprocessing. Experimental results demonstrated that this feature extraction\ntechnique is effective in various neural network models, with the same facial\nlandmarks tested on three neural network models, with promising performance\nmetrics indicating its potential for real-world applications. The findings\ndiscussed in this paper include RNN and artificial neural network (ANN) models\nwith accuracy between 96% and 93%, respectively, with a CNN model hovering\naround 78%. This research challenges the assumption that raw image processing\nis necessary to identify deepfake videos by presenting a facial feature\nextraction approach compatible with various neural network models while\nrequiring fewer parameters."
    },
    {
        "date": "2025-07",
        "title": "Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers",
        "author": "Lee Harris",
        "link": "http://arxiv.org/abs/2507.22921v1",
        "abstract": "Language models can capture complex relationships in given text, but these\nare notorious for being costly and for producing information that does not\nexist (i.e., hallucinations). Furthermore, the resources invested into\nproducing this information would be wasted if it were incorrect. We address\nthese issues by proposing, implementing, and applying the Language Model Chain\n(LMC) algorithm. In this, a language model's response to a given prompt about\ngiven text is only correct if it exists in the collection of possible (i.e.,\ncandidate) answers, and text corresponding to incorrect responses is fed into a\nmore predictive (but slower) language model. This process is repeated for a\ncollection of language models, or until all predictions about the text are\ncorrect. We used the LMC algorithm to extract patient dates of birth from\nmedical documents, and combining a collection of language models in a\nmulti-stage cascade significantly increased prediction speed and accuracy over\nindividual language models, while greatly reducing the number of corresponding\nhallucinations. We believe that the novel LMC algorithm significantly\ncontributes to the knowledge extraction field, and that this should be explored\nmuch further in the future."
    },
    {
        "date": "2025-07",
        "title": "Extracting Visual Facts from Intermediate Layers for Mitigating Hallucinations in Multimodal Large Language Models",
        "author": "Haoran Zhou, Zihan Zhang, and Hao Chen",
        "link": "http://arxiv.org/abs/2507.15652v1",
        "abstract": "Multimodal Large Language Models (MLLMs) have made significant strides by\ncombining visual recognition and language understanding to generate content\nthat is both coherent and contextually accurate. However, MLLMs continue to\nstruggle with object hallucinations, where models produce seemingly plausible\nbut factually incorrect outputs, including objects that do not exist in the\nimage. Recent work has revealed that the prior knowledge in MLLMs significantly\nsuppresses visual information in deep layers, causing hallucinatory outputs.\nHowever, how these priors suppress visual information at the intermediate layer\nstage in MLLMs remains unclear. We observe that visual factual knowledge and\nthe differences between intermediate-layer prior/original probability\ndistributions show similar evolutionary trends in intermediate layers.\nMotivated by this, we introduce Decoding by Extracting Visual Facts (EVA), a\nsimple, training-free method that dynamically selects intermediate layers with\nthe most significant visual factual information. By contrasting the output\ndistributions of the selected layer derived from the original input and\npure-text input, EVA extracts visual factual knowledge and proportionally\nincorporates it into the final layer to correct the output logits. Importantly,\nEVA is model-agnostic, seamlessly integrates with various classic decoding\nstrategies, and is applicable across different MLLMs. We validate EVA on\nwidely-used benchmarks, and the results show that it significantly reduces\nhallucination rates compared to baseline methods, underscoring its\neffectiveness in mitigating hallucinations."
    },
    {
        "date": "2025-07",
        "title": "What Level of Automation is \"Good Enough\"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction",
        "author": "Lingbo Li, Anuradha Mathrani, and Teo Susnjak",
        "link": "http://arxiv.org/abs/2507.15152v1",
        "abstract": "Automating data extraction from full-text randomised controlled trials (RCTs)\nfor meta-analysis remains a significant challenge. This study evaluates the\npractical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini)\nacross tasks involving statistical results, risk-of-bias assessments, and\nstudy-level characteristics in three medical domains: hypertension, diabetes,\nand orthopaedics. We tested four distinct prompting strategies (basic\nprompting, self-reflective prompting, model ensemble, and customised prompts)\nto determine how to improve extraction quality. All models demonstrate high\nprecision but consistently suffer from poor recall by omitting key information.\nWe found that customised prompts were the most effective, boosting recall by up\nto 15\\%. Based on this analysis, we propose a three-tiered set of guidelines\nfor using LLMs in data extraction, matching data types to appropriate levels of\nautomation based on task complexity and risk. Our study offers practical advice\nfor automating data extraction in real-world meta-analyses, balancing LLM\nefficiency with expert oversight through targeted, task-specific automation."
    },
    {
        "date": "2025-07",
        "title": "Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models",
        "author": "Hosein Azarbonyad, Zi Long Zhu, Georgios Cheirmpos, Zubair Afzal, Vikrant Yadav, and Georgios Tsatsaronis",
        "link": "http://arxiv.org/abs/2507.13827v1",
        "abstract": "When deciding to read an article or incorporate it into their research,\nscholars often seek to quickly identify and understand its main ideas. In this\npaper, we aim to extract these key concepts and contributions from scientific\narticles in the form of Question and Answer (QA) pairs. We propose two distinct\napproaches for generating QAs. The first approach involves selecting salient\nparagraphs, using a Large Language Model (LLM) to generate questions, ranking\nthese questions by the likelihood of obtaining meaningful answers, and\nsubsequently generating answers. This method relies exclusively on the content\nof the articles. However, assessing an article's novelty typically requires\ncomparison with the existing literature. Therefore, our second approach\nleverages a Knowledge Graph (KG) for QA generation. We construct a KG by\nfine-tuning an Entity Relationship (ER) extraction model on scientific articles\nand using it to build the graph. We then employ a salient triplet extraction\nmethod to select the most pertinent ERs per article, utilizing metrics such as\nthe centrality of entities based on a triplet TF-IDF-like measure. This measure\nassesses the saliency of a triplet based on its importance within the article\ncompared to its prevalence in the literature. For evaluation, we generate QAs\nusing both approaches and have them assessed by Subject Matter Experts (SMEs)\nthrough a set of predefined metrics to evaluate the quality of both questions\nand answers. Our evaluations demonstrate that the KG-based approach effectively\ncaptures the main ideas discussed in the articles. Furthermore, our findings\nindicate that fine-tuning the ER extraction model on our scientific corpus is\ncrucial for extracting high-quality triplets from such documents."
    },
    {
        "date": "2025-07",
        "title": "Extracting Important Tokens in E-Commerce Queries with a Tag Interaction-Aware Transformer Model",
        "author": "Md. Ahsanul Kabir, Mohammad Al Hasan, Aritra Mandal, Liyang Hao, Ishita Khan, Daniel Tunkelang, and Zhe Wu",
        "link": "http://arxiv.org/abs/2507.10385v1",
        "abstract": "The major task of any e-commerce search engine is to retrieve the most\nrelevant inventory items, which best match the user intent reflected in a\nquery. This task is non-trivial due to many reasons, including ambiguous\nqueries, misaligned vocabulary between buyers, and sellers, over- or\nunder-constrained queries by the presence of too many or too few tokens. To\naddress these challenges, query reformulation is used, which modifies a user\nquery through token dropping, replacement or expansion, with the objective to\nbridge semantic gap between query tokens and users' search intent. Early\nmethods of query reformulation mostly used statistical measures derived from\ntoken co-occurrence frequencies from selective user sessions having clicks or\npurchases. In recent years, supervised deep learning approaches, specifically\ntransformer-based neural language models, or sequence-to-sequence models are\nbeing used for query reformulation task. However, these models do not utilize\nthe semantic tags of a query token, which are significant for capturing user\nintent of an e-commerce query. In this work, we pose query reformulation as a\ntoken classification task, and solve this task by designing a dependency-aware\ntransformer-based language model, TagBERT, which makes use of semantic tags of\na token for learning superior query phrase embedding. Experiments on large,\nreal-life e-commerce datasets show that TagBERT exhibits superior performance\nthan plethora of competing models, including BERT, eBERT, and\nSequence-to-Sequence transformer model for important token classification task."
    },
    {
        "date": "2025-07",
        "title": "Extracting Cause-Effect Pairs from a Sentence with a Dependency-Aware Transformer Model",
        "author": "Md Ahsanul Kabir, Abrar Jahin, and Mohammad Al Hasan",
        "link": "http://arxiv.org/abs/2507.09925v1",
        "abstract": "Extracting cause and effect phrases from a sentence is an important NLP task,\nwith numerous applications in various domains, including legal, medical,\neducation, and scientific research. There are many unsupervised and supervised\nmethods proposed for solving this task. Among these, unsupervised methods\nutilize various linguistic tools, including syntactic patterns, dependency\ntree, dependency relations, etc. among different sentential units for\nextracting the cause and effect phrases. On the other hand, the contemporary\nsupervised methods use various deep learning based mask language models\nequipped with a token classification layer for extracting cause and effect\nphrases. Linguistic tools, specifically, dependency tree, which organizes a\nsentence into different semantic units have been shown to be very effective for\nextracting semantic pairs from a sentence, but existing supervised methods do\nnot have any provision for utilizing such tools within their model framework.\nIn this work, we propose DepBERT, which extends a transformer-based model by\nincorporating dependency tree of a sentence within the model framework.\nExtensive experiments over three datasets show that DepBERT is better than\nvarious state-of-the art supervised causality extraction methods."
    },
    {
        "date": "2025-07",
        "title": "Taming generative video models for zero-shot optical flow extraction",
        "author": "Seungwoo Kim, Khai Loong Aw, Klemen Kotar, Cristobal Eyzaguirre, Wanhee Lee, Yunong Liu, Jared Watrous, Stefan Stojanov, Juan Carlos Niebles, Jiajun Wu, and Daniel L. K. Yamins",
        "link": "http://arxiv.org/abs/2507.09082v1",
        "abstract": "Extracting optical flow from videos remains a core computer vision problem.\nMotivated by the success of large general-purpose models, we ask whether frozen\nself-supervised video models trained only for future frame prediction can be\nprompted, without fine-tuning, to output flow. Prior work reading out depth or\nillumination from video generators required fine-tuning, which is impractical\nfor flow where labels are scarce and synthetic datasets suffer from a\nsim-to-real gap. Inspired by the Counterfactual World Model (CWM) paradigm,\nwhich can obtain point-wise correspondences by injecting a small tracer\nperturbation into a next-frame predictor and tracking its propagation, we\nextend this idea to generative video models. We explore several popular\narchitectures and find that successful zero-shot flow extraction in this manner\nis aided by three model properties: (1) distributional prediction of future\nframes (avoiding blurry or noisy outputs); (2) factorized latents that treat\neach spatio-temporal patch independently; and (3) random-access decoding that\ncan condition on any subset of future pixels. These properties are uniquely\npresent in the recent Local Random Access Sequence (LRAS) architecture.\nBuilding on LRAS, we propose KL-tracing: a novel test-time procedure that\ninjects a localized perturbation into the first frame, rolls out the model one\nstep, and computes the Kullback-Leibler divergence between perturbed and\nunperturbed predictive distributions. Without any flow-specific fine-tuning,\nour method outperforms state-of-the-art models on real-world TAP-Vid DAVIS\ndataset (16.6% relative improvement for endpoint error) and synthetic TAP-Vid\nKubric (4.7% relative improvement). Our results indicate that counterfactual\nprompting of controllable generative video models is a scalable and effective\nalternative to supervised or photometric-loss approaches for high-quality flow."
    },
    {
        "date": "2025-07",
        "title": "Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models",
        "author": "Sedigh Khademi, Jim Black, Christopher Palmer, Muhammad Javed, Hazel Clothier, Jim Buttery, and Gerardo Luis Dimaguila",
        "link": "http://arxiv.org/abs/2507.07599v1",
        "abstract": "This study evaluates fine-tuned Llama 3.2 models for extracting\nvaccine-related information from emergency department triage notes to support\nnear real-time vaccine safety surveillance. Prompt engineering was used to\ninitially create a labeled dataset, which was then confirmed by human\nannotators. The performance of prompt-engineered models, fine-tuned models, and\na rule-based approach was compared. The fine-tuned Llama 3 billion parameter\nmodel outperformed other models in its accuracy of extracting vaccine names.\nModel quantization enabled efficient deployment in resource-constrained\nenvironments. Findings demonstrate the potential of large language models in\nautomating data extraction from emergency department notes, supporting\nefficient vaccine safety surveillance and early detection of emerging adverse\nevents following immunization issues."
    },
    {
        "date": "2025-07",
        "title": "BarkBeetle: Stealing Decision Tree Models with Fault Injection",
        "author": "Qifan Wang, Jonas Sander, Minmin Jiang, Thomas Eisenbarth, and David Oswald",
        "link": "http://arxiv.org/abs/2507.06986v1",
        "abstract": "Machine learning models, particularly decision trees (DTs), are widely\nadopted across various domains due to their interpretability and efficiency.\nHowever, as ML models become increasingly integrated into privacy-sensitive\napplications, concerns about their confidentiality have grown, particularly in\nlight of emerging threats such as model extraction and fault injection attacks.\nAssessing the vulnerability of DTs under such attacks is therefore important.\nIn this work, we present BarkBeetle, a novel attack that leverages fault\ninjection to extract internal structural information of DT models. BarkBeetle\nemploys a bottom-up recovery strategy that uses targeted fault injection at\nspecific nodes to efficiently infer feature splits and threshold values. Our\nproof-of-concept implementation demonstrates that BarkBeetle requires\nsignificantly fewer queries and recovers more structural information compared\nto prior approaches, when evaluated on DTs trained with public UCI datasets. To\nvalidate its practical feasibility, we implement BarkBeetle on a Raspberry Pi\nRP2350 board and perform fault injections using the Faultier voltage glitching\ntool. As BarkBeetle targets general DT models, we also provide an in-depth\ndiscussion on its applicability to a broader range of tree-based applications,\nincluding data stream classification, DT variants, and cryptography schemes."
    },
    {
        "date": "2025-07",
        "title": "Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review",
        "author": "James Stewart-Evans, Emma Wilson, Tessa Langley, Andrew Prayle, Angela Hands, Karen Exley, and Jo Leonardi-Bee",
        "link": "http://arxiv.org/abs/2507.06623v1",
        "abstract": "The data extraction stages of reviews are resource-intensive, and researchers\nmay seek to expediate data extraction using online (large language models) LLMs\nand review protocols. Claude 3.5 Sonnet was used to trial two approaches that\nused a review protocol to prompt data extraction from 10 evidence sources\nincluded in a case study scoping review. A protocol-based approach was also\nused to review extracted data. Limited performance evaluation was undertaken\nwhich found high accuracy for the two extraction approaches (83.3% and 100%)\nwhen extracting simple, well-defined citation details; accuracy was lower (9.6%\nand 15.8%) when extracting more complex, subjective data items. Considering all\ndata items, both approaches had precision >90% but low recall (<25%) and F1\nscores (<40%). The context of a complex scoping review, open response types and\nmethodological approach likely impacted performance due to missed and\nmisattributed data. LLM feedback considered the baseline extraction accurate\nand suggested minor amendments: four of 15 (26.7%) to citation details and 8 of\n38 (21.1%) to key findings data items were considered to potentially add value.\nHowever, when repeating the process with a dataset featuring deliberate errors,\nonly 2 of 39 (5%) errors were detected. Review-protocol-based methods used for\nexpediency require more robust performance evaluation across a range of LLMs\nand review contexts with comparison to conventional prompt engineering\napproaches. We recommend researchers evaluate and report LLM performance if\nusing them similarly to conduct data extraction or review extracted data. LLM\nfeedback contributed to protocol adaptation and may assist future review\nprotocol drafting."
    },
    {
        "date": "2025-07",
        "title": "Deep Learning to Automate Parameter Extraction and Model Fitting of Two-Dimensional Transistors",
        "author": "Robert K. A. Bennett, Jan-Lucas Uslu, Harmon F. Gault, Asir Intisar Khan, Lauren Hoang, Tara Pe\u00f1a, Kathryn Neilson, Young Suh Song, Zhepeng Zhang, Andrew J. Mannix, and Eric Pop",
        "link": "http://arxiv.org/abs/2507.05134v1",
        "abstract": "We present a deep learning approach to extract physical parameters (e.g.,\nmobility, Schottky contact barrier height, defect profiles) of two-dimensional\n(2D) transistors from electrical measurements, enabling automated parameter\nextraction and technology computer-aided design (TCAD) fitting. To facilitate\nthis task, we implement a simple data augmentation and pre-training approach by\ntraining a secondary neural network to approximate a physics-based device\nsimulator. This method enables high-quality fits after training the neural\nnetwork on electrical data generated from physics-based simulations of ~500\ndevices, a factor >40$\\times$ fewer than other recent efforts. Consequently,\nfitting can be achieved by training on physically rigorous TCAD models,\nincluding complex geometry, self-consistent transport, and electrostatic\neffects, and is not limited to computationally inexpensive compact models. We\napply our approach to reverse-engineer key parameters from experimental\nmonolayer WS$_2$ transistors, achieving a median coefficient of determination\n($R^2$) = 0.99 when fitting measured electrical data. We also demonstrate that\nthis approach generalizes and scales well by reverse-engineering electrical\ndata on high-electron-mobility transistors while fitting 35 parameters\nsimultaneously. To facilitate future research on deep learning approaches for\ninverse transistor design, we have published our code and sample data sets\nonline."
    },
    {
        "date": "2025-07",
        "title": "Model Inversion Attacks on Llama 3: Extracting PII from Large Language Models",
        "author": "Sathesh P. Sivashanmugam",
        "link": "http://arxiv.org/abs/2507.04478v1",
        "abstract": "Large language models (LLMs) have transformed natural language processing,\nbut their ability to memorize training data poses significant privacy risks.\nThis paper investigates model inversion attacks on the Llama 3.2 model, a\nmultilingual LLM developed by Meta. By querying the model with carefully\ncrafted prompts, we demonstrate the extraction of personally identifiable\ninformation (PII) such as passwords, email addresses, and account numbers. Our\nfindings highlight the vulnerability of even smaller LLMs to privacy attacks\nand underscore the need for robust defenses. We discuss potential mitigation\nstrategies, including differential privacy and data sanitization, and call for\nfurther research into privacy-preserving machine learning techniques."
    },
    {
        "date": "2025-07",
        "title": "Intrinsic Fingerprint of LLMs: Continue Training is NOT All You Need to Steal A Model!",
        "author": "Do-hyeon Yoon, Minsoo Chun, Thomas Allen, Hans M\u00fcller, Min Wang, and Rajesh Sharma",
        "link": "http://arxiv.org/abs/2507.03014v1",
        "abstract": "Large language models (LLMs) face significant copyright and intellectual\nproperty challenges as the cost of training increases and model reuse becomes\nprevalent. While watermarking techniques have been proposed to protect model\nownership, they may not be robust to continue training and development, posing\nserious threats to model attribution and copyright protection. This work\nintroduces a simple yet effective approach for robust LLM fingerprinting based\non intrinsic model characteristics. We discover that the standard deviation\ndistributions of attention parameter matrices across different layers exhibit\ndistinctive patterns that remain stable even after extensive continued\ntraining. These parameter distribution signatures serve as robust fingerprints\nthat can reliably identify model lineage and detect potential copyright\ninfringement. Our experimental validation across multiple model families\ndemonstrates the effectiveness of our method for model authentication. Notably,\nour investigation uncovers evidence that a recently Pangu Pro MoE model\nreleased by Huawei is derived from Qwen-2.5 14B model through upcycling\ntechniques rather than training from scratch, highlighting potential cases of\nmodel plagiarism, copyright violation, and information fabrication. These\nfindings underscore the critical importance of developing robust fingerprinting\nmethods for protecting intellectual property in large-scale model development\nand emphasize that deliberate continued training alone is insufficient to\ncompletely obscure model origins."
    },
    {
        "date": "2025-06",
        "title": "A Survey on Model Extraction Attacks and Defenses for Large Language Models",
        "author": "Kaixiang Zhao, Lincan Li, Kaize Ding, Neil Zhenqiang Gong, Yue Zhao, and Yushun Dong",
        "link": "http://arxiv.org/abs/2506.22521v1",
        "abstract": "Model extraction attacks pose significant security threats to deployed\nlanguage models, potentially compromising intellectual property and user\nprivacy. This survey provides a comprehensive taxonomy of LLM-specific\nextraction attacks and defenses, categorizing attacks into functionality\nextraction, training data extraction, and prompt-targeted attacks. We analyze\nvarious attack methodologies including API-based knowledge distillation, direct\nquerying, parameter recovery, and prompt stealing techniques that exploit\ntransformer architectures. We then examine defense mechanisms organized into\nmodel protection, data privacy protection, and prompt-targeted strategies,\nevaluating their effectiveness across different deployment scenarios. We\npropose specialized metrics for evaluating both attack effectiveness and\ndefense performance, addressing the specific challenges of generative language\nmodels. Through our analysis, we identify critical limitations in current\napproaches and propose promising research directions, including integrated\nattack methodologies and adaptive defense mechanisms that balance security with\nmodel utility. This work serves NLP researchers, ML engineers, and security\nprofessionals seeking to protect language models in production environments."
    },
    {
        "date": "2025-06",
        "title": "Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives",
        "author": "Brian Liu, Rahul Mazumder, and Peter Radchenko",
        "link": "http://arxiv.org/abs/2506.20114v3",
        "abstract": "Tree ensembles are non-parametric methods widely recognized for their\naccuracy and ability to capture complex interactions. While these models excel\nat prediction, they are difficult to interpret and may fail to uncover useful\nrelationships in the data. We propose an estimator to extract compact sets of\ndecision rules from tree ensembles. The extracted models are accurate and can\nbe manually examined to reveal relationships between the predictors and the\nresponse. A key novelty of our estimator is the flexibility to jointly control\nthe number of rules extracted and the interaction depth of each rule, which\nimproves accuracy. We develop a tailored exact algorithm to efficiently solve\noptimization problems underlying our estimator and an approximate algorithm for\ncomputing regularization paths, sequences of solutions that correspond to\nvarying model sizes. We also establish novel non-asymptotic prediction error\nbounds for our proposed approach, comparing it to an oracle that chooses the\nbest data-dependent linear combination of the rules in the ensemble subject to\nthe same complexity constraint as our estimator. The bounds illustrate that the\nlarge-sample predictive performance of our estimator is on par with that of the\noracle. Through experiments, we demonstrate that our estimator outperforms\nexisting algorithms for rule extraction."
    },
    {
        "date": "2025-06",
        "title": "T-Rex: Task-Adaptive Spatial Representation Extraction for Robotic Manipulation with Vision-Language Models",
        "author": "Yiteng Chen, Wenbo Li, Shiyi Wang, Huiping Zhuang, and Qingyao Wu",
        "link": "http://arxiv.org/abs/2506.19498v1",
        "abstract": "Building a general robotic manipulation system capable of performing a wide\nvariety of tasks in real-world settings is a challenging task. Vision-Language\nModels (VLMs) have demonstrated remarkable potential in robotic manipulation\ntasks, primarily due to the extensive world knowledge they gain from\nlarge-scale datasets. In this process, Spatial Representations (such as points\nrepresenting object positions or vectors representing object orientations) act\nas a bridge between VLMs and real-world scene, effectively grounding the\nreasoning abilities of VLMs and applying them to specific task scenarios.\nHowever, existing VLM-based robotic approaches often adopt a fixed spatial\nrepresentation extraction scheme for various tasks, resulting in insufficient\nrepresentational capability or excessive extraction time. In this work, we\nintroduce T-Rex, a Task-Adaptive Framework for Spatial Representation\nExtraction, which dynamically selects the most appropriate spatial\nrepresentation extraction scheme for each entity based on specific task\nrequirements. Our key insight is that task complexity determines the types and\ngranularity of spatial representations, and Stronger representational\ncapabilities are typically associated with Higher overall system operation\ncosts. Through comprehensive experiments in real-world robotic environments, we\nshow that our approach delivers significant advantages in spatial\nunderstanding, efficiency, and stability without additional training."
    },
    {
        "date": "2025-06",
        "title": "Assessing Risk of Stealing Proprietary Models for Medical Imaging Tasks",
        "author": "Ankita Raj, Harsh Swaika, Deepankar Varma, and Chetan Arora",
        "link": "http://arxiv.org/abs/2506.19464v1",
        "abstract": "The success of deep learning in medical imaging applications has led several\ncompanies to deploy proprietary models in diagnostic workflows, offering\nmonetized services. Even though model weights are hidden to protect the\nintellectual property of the service provider, these models are exposed to\nmodel stealing (MS) attacks, where adversaries can clone the model's\nfunctionality by querying it with a proxy dataset and training a thief model on\nthe acquired predictions. While extensively studied on general vision tasks,\nthe susceptibility of medical imaging models to MS attacks remains inadequately\nexplored. This paper investigates the vulnerability of black-box medical\nimaging models to MS attacks under realistic conditions where the adversary\nlacks access to the victim model's training data and operates with limited\nquery budgets. We demonstrate that adversaries can effectively execute MS\nattacks by using publicly available datasets. To further enhance MS\ncapabilities with limited query budgets, we propose a two-step model stealing\napproach termed QueryWise. This method capitalizes on unlabeled data obtained\nfrom a proxy distribution to train the thief model without incurring additional\nqueries. Evaluation on two medical imaging models for Gallbladder Cancer and\nCOVID-19 classification substantiates the effectiveness of the proposed attack.\nThe source code is available at https://github.com/rajankita/QueryWise."
    },
    {
        "date": "2025-06",
        "title": "PARALLELPROMPT: Extracting Parallelism from Large Language Model Queries",
        "author": "Steven Kolawole, Keshav Santhanam, Virginia Smith, and Pratiksha Thaker",
        "link": "http://arxiv.org/abs/2506.18728v2",
        "abstract": "LLM serving systems typically treat user prompts as monolithic inputs,\noptimizing inference through decoding tricks or inter-query batching. However,\nmany real-world prompts contain latent semantic parallelism--decomposable\nstructures where subtasks can be executed independently to reduce latency while\npreserving meaning. We introduce PARALLELPROMPT, the first benchmark for\nmeasuring intra-query parallelism in natural user prompts. Our dataset\ncomprises over 37,000 real-world prompts from public LLM chat logs, each\nannotated with a structured schema capturing task templates, shared context,\nand iteration inputs. These schemas are extracted using LLM-assisted prompting\nwith rule-based multilingual validation. To evaluate the benefits of\ndecomposition, we provide an execution suite that benchmarks serial vs.\nparallel strategies, measuring latency, structural adherence, and semantic\nfidelity. Our results show that intra-query parallelism can be successfully\nparsed in over 75% of curated datasets, unlocking up to 5x speedups on tasks\nlike translation, comprehension, and comparative analysis, with minimal quality\ndegradation. By releasing this benchmark, curation pipeline, and evaluation\nsuite, we provide the first standardized testbed for studying structure-aware\nexecution in LLM serving pipelines."
    },
    {
        "date": "2025-06",
        "title": "A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction",
        "author": "Chengjie Liu, Weiyu Chen, Huiyao Xu, Yuan Du, Jun Yang, and Li Du",
        "link": "http://arxiv.org/abs/2506.18424v1",
        "abstract": "In the design process of the analog circuit pre-layout phase, device sizing\nis an important step in determining whether an analog circuit can meet the\nrequired performance metrics. Many existing techniques extract the circuit\nsizing task as a mathematical optimization problem to solve and continuously\nimprove the optimization efficiency from a mathematical perspective. But they\nignore the automatic introduction of prior knowledge, fail to achieve effective\npruning of the search space, which thereby leads to a considerable compression\nmargin remaining in the search space. To alleviate this problem, we propose a\nlarge language model (LLM)-based multi-agent framework for analog circuits'\nsizing relationships extraction from academic papers. The search space in the\nsizing process can be effectively pruned based on the sizing relationship\nextracted by this framework. Eventually, we conducted tests on 3 types of\ncircuits, and the optimization efficiency was improved by $2.32 \\sim 26.6\n\\times$. This work demonstrates that the LLM can effectively prune the search\nspace for analog circuit sizing, providing a new solution for the combination\nof LLMs and conventional analog circuit design automation methods."
    },
    {
        "date": "2025-06",
        "title": "CEGA: A Cost-Effective Approach for Graph-Based Model Extraction and Acquisition",
        "author": "Zebin Wang, Menghan Lin, Bolin Shen, Ken Anderson, Molei Liu, Tianxi Cai, and Yushun Dong",
        "link": "http://arxiv.org/abs/2506.17709v1",
        "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable utility across\ndiverse applications, and their growing complexity has made Machine Learning as\na Service (MLaaS) a viable platform for scalable deployment. However, this\naccessibility also exposes GNN to serious security threats, most notably model\nextraction attacks (MEAs), in which adversaries strategically query a deployed\nmodel to construct a high-fidelity replica. In this work, we evaluate the\nvulnerability of GNNs to MEAs and explore their potential for cost-effective\nmodel acquisition in non-adversarial research settings. Importantly, adaptive\nnode querying strategies can also serve a critical role in research,\nparticularly when labeling data is expensive or time-consuming. By selectively\nsampling informative nodes, researchers can train high-performing GNNs with\nminimal supervision, which is particularly valuable in domains such as\nbiomedicine, where annotations often require expert input. To address this, we\npropose a node querying strategy tailored to a highly practical yet\nunderexplored scenario, where bulk queries are prohibited, and only a limited\nset of initial nodes is available. Our approach iteratively refines the node\nselection mechanism over multiple learning cycles, leveraging historical\nfeedback to improve extraction efficiency. Extensive experiments on benchmark\ngraph datasets demonstrate our superiority over comparable baselines on\naccuracy, fidelity, and F1 score under strict query-size constraints. These\nresults highlight both the susceptibility of deployed GNNs to extraction\nattacks and the promise of ethical, efficient GNN acquisition methods to\nsupport low-resource research environments."
    },
    {
        "date": "2025-06",
        "title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
        "author": "Sajratul Y. Rubaiat, and Hasan M. Jamil",
        "link": "http://arxiv.org/abs/2506.17580v1",
        "abstract": "The exponential growth of scientific literature challenges researchers\nextracting and synthesizing knowledge. Traditional search engines return many\nsources without direct, detailed answers, while general-purpose LLMs may offer\nconcise responses that lack depth or omit current information. LLMs with search\ncapabilities are also limited by context window, yielding short, incomplete\nanswers. This paper introduces WISE (Workflow for Intelligent Scientific\nKnowledge Extraction), a system addressing these limits by using a structured\nworkflow to extract, refine, and rank query-specific knowledge. WISE uses an\nLLM-powered, tree-based architecture to refine data, focusing on query-aligned,\ncontext-aware, and non-redundant information. Dynamic scoring and ranking\nprioritize unique contributions from each source, and adaptive stopping\ncriteria minimize processing overhead. WISE delivers detailed, organized\nanswers by systematically exploring and synthesizing knowledge from diverse\nsources. Experiments on HBB gene-associated diseases demonstrate WISE reduces\nprocessed text by over 80% while achieving significantly higher recall over\nbaselines like search engines and other LLM-based approaches. ROUGE and BLEU\nmetrics reveal WISE's output is more unique than other systems, and a novel\nlevel-based metric shows it provides more in-depth information. We also explore\nhow the WISE workflow can be adapted for diverse domains like drug discovery,\nmaterial science, and social science, enabling efficient knowledge extraction\nand synthesis from unstructured scientific papers and web sources."
    },
    {
        "date": "2025-06",
        "title": "VideoMat: Extracting PBR Materials from Video Diffusion Models",
        "author": "Jacob Munkberg, Zian Wang, Ruofan Liang, Tianchang Shen, and Jon Hasselgren",
        "link": "http://arxiv.org/abs/2506.09665v2",
        "abstract": "We leverage finetuned video diffusion models, intrinsic decomposition of\nvideos, and physically-based differentiable rendering to generate high quality\nmaterials for 3D models given a text prompt or a single image. We condition a\nvideo diffusion model to respect the input geometry and lighting condition.\nThis model produces multiple views of a given 3D model with coherent material\nproperties. Secondly, we use a recent model to extract intrinsics (base color,\nroughness, metallic) from the generated video. Finally, we use the intrinsics\nalongside the generated video in a differentiable path tracer to robustly\nextract PBR materials directly compatible with common content creation tools."
    },
    {
        "date": "2025-06",
        "title": "GLD-Road:A global-local decoding road network extraction model for remote sensing images",
        "author": "Ligao Deng, Yupeng Deng, Yu Meng, Jingbo Chen, Zhihao Xi, Diyou Liu, and Qifeng Chu",
        "link": "http://arxiv.org/abs/2506.09553v1",
        "abstract": "Road networks are crucial for mapping, autonomous driving, and disaster\nresponse. While manual annotation is costly, deep learning offers efficient\nextraction. Current methods include postprocessing (prone to errors), global\nparallel (fast but misses nodes), and local iterative (accurate but slow). We\npropose GLD-Road, a two-stage model combining global efficiency and local\nprecision. First, it detects road nodes and connects them via a Connect Module.\nThen, it iteratively refines broken roads using local searches, drastically\nreducing computation. Experiments show GLD-Road outperforms state-of-the-art\nmethods, improving APLS by 1.9% (City-Scale) and 0.67% (SpaceNet3). It also\nreduces retrieval time by 40% vs. Sat2Graph (global) and 92% vs. RNGDet++\n(local). The experimental results are available at\nhttps://github.com/ucas-dlg/GLD-Road."
    },
    {
        "date": "2025-06",
        "title": "Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models",
        "author": "Yingqi Hu, Zhuo Zhang, Jingyuan Zhang, Lizhen Qu, and Zenglin Xu",
        "link": "http://arxiv.org/abs/2506.06060v1",
        "abstract": "Federated fine-tuning of large language models (FedLLMs) presents a promising\napproach for achieving strong model performance while preserving data privacy\nin sensitive domains. However, the inherent memorization ability of LLMs makes\nthem vulnerable to training data extraction attacks. To investigate this risk,\nwe introduce simple yet effective extraction attack algorithms specifically\ndesigned for FedLLMs. In contrast to prior \"verbatim\" extraction attacks, which\nassume access to fragments from all training data, our approach operates under\na more realistic threat model, where the attacker only has access to a single\nclient's data and aims to extract previously unseen personally identifiable\ninformation (PII) from other clients. This requires leveraging contextual\nprefixes held by the attacker to generalize across clients. To evaluate the\neffectiveness of our approaches, we propose two rigorous metrics-coverage rate\nand efficiency-and extend a real-world legal dataset with PII annotations\naligned with CPIS, GDPR, and CCPA standards, achieving 89.9% human-verified\nprecision. Experimental results show that our method can extract up to 56.57%\nof victim-exclusive PII, with \"Address,\" \"Birthday,\" and \"Name\" being the most\nvulnerable categories. Our findings underscore the pressing need for robust\ndefense strategies and contribute a new benchmark and evaluation framework for\nfuture research in privacy-preserving federated learning."
    },
    {
        "date": "2025-06",
        "title": "Stealix: Model Stealing via Prompt Evolution",
        "author": "Zhixiong Zhuang, Hui-Po Wang, Maria-Irina Nicolae, and Mario Fritz",
        "link": "http://arxiv.org/abs/2506.05867v1",
        "abstract": "Model stealing poses a significant security risk in machine learning by\nenabling attackers to replicate a black-box model without access to its\ntraining data, thus jeopardizing intellectual property and exposing sensitive\ninformation. Recent methods that use pre-trained diffusion models for data\nsynthesis improve efficiency and performance but rely heavily on manually\ncrafted prompts, limiting automation and scalability, especially for attackers\nwith little expertise. To assess the risks posed by open-source pre-trained\nmodels, we propose a more realistic threat model that eliminates the need for\nprompt design skills or knowledge of class names. In this context, we introduce\nStealix, the first approach to perform model stealing without predefined\nprompts. Stealix uses two open-source pre-trained models to infer the victim\nmodel's data distribution, and iteratively refines prompts through a genetic\nalgorithm, progressively improving the precision and diversity of synthetic\nimages. Our experimental results demonstrate that Stealix significantly\noutperforms other methods, even those with access to class names or\nfine-grained prompts, while operating under the same query budget. These\nfindings highlight the scalability of our approach and suggest that the risks\nposed by pre-trained generative models in model stealing may be greater than\npreviously recognized."
    },
    {
        "date": "2025-06",
        "title": "AssetDropper: Asset Extraction via Diffusion Models with Reward-Driven Optimization",
        "author": "Lanjiong Li, Guanhua Zhao, Lingting Zhu, Zeyu Cai, Lequan Yu, Jian Zhang, and Zeyu Wang",
        "link": "http://arxiv.org/abs/2506.07738v1",
        "abstract": "Recent research on generative models has primarily focused on creating\nproduct-ready visual outputs; however, designers often favor access to\nstandardized asset libraries, a domain that has yet to be significantly\nenhanced by generative capabilities. Although open-world scenes provide ample\nraw materials for designers, efficiently extracting high-quality, standardized\nassets remains a challenge. To address this, we introduce AssetDropper, the\nfirst framework designed to extract assets from reference images, providing\nartists with an open-world asset palette. Our model adeptly extracts a front\nview of selected subjects from input images, effectively handling complex\nscenarios such as perspective distortion and subject occlusion. We establish a\nsynthetic dataset of more than 200,000 image-subject pairs and a real-world\nbenchmark with thousands more for evaluation, facilitating the exploration of\nfuture research in downstream tasks. Furthermore, to ensure precise asset\nextraction that aligns well with the image prompts, we employ a pre-trained\nreward model to fulfill a closed-loop with feedback. We design the reward model\nto perform an inverse task that pastes the extracted assets back into the\nreference sources, which assists training with additional consistency and\nmitigates hallucination. Extensive experiments show that, with the aid of\nreward-driven optimization, AssetDropper achieves the state-of-the-art results\nin asset extraction. Project page: AssetDropper.github.io."
    },
    {
        "date": "2025-06",
        "title": "A Threat Intelligence Event Extraction Conceptual Model for Cyber Threat Intelligence Feeds",
        "author": "Jamal H. Al-Yasiri, Mohamad Fadli Bin Zolkipli, Nik Fatinah N Mohd Farid, Mohammed Alsamman, and Zainab Ali Mohammed",
        "link": "http://arxiv.org/abs/2506.03551v1",
        "abstract": "In response to the escalating cyber threats, the efficiency of Cyber Threat\nIntelligence (CTI) data collection has become paramount in ensuring robust\ncybersecurity. However, existing works encounter significant challenges in\npreprocessing large volumes of multilingual threat data, leading to\ninefficiencies in real-time threat analysis. This paper presents a systematic\nreview of current techniques aimed at enhancing CTI data collection efficiency.\nAdditionally, it proposes a conceptual model to further advance the\neffectiveness of threat intelligence feeds. Following the PRISMA guidelines,\nthe review examines relevant studies from the Scopus database, highlighting the\ncritical role of artificial intelligence (AI) and machine learning models in\noptimizing CTI data preprocessing. The findings underscore the importance of\nAI-driven methods, particularly supervised and unsupervised learning, in\nsignificantly improving the accuracy of threat detection and event extraction,\nthereby strengthening cybersecurity. Furthermore, the study identifies a gap in\nthe existing research and introduces XBC conceptual model integrating\nXLM-RoBERTa, BiGRU, and CRF, specifically developed to address this gap. This\npaper contributes conceptually to the field by providing a detailed analysis of\ncurrent CTI data collection techniques and introducing an innovative conceptual\nmodel to enhance future threat intelligence capabilities."
    },
    {
        "date": "2025-06",
        "title": "MISLEADER: Defending against Model Extraction with Ensembles of Distilled Models",
        "author": "Xueqi Cheng, Minxing Zheng, Shixiang Zhu, and Yushun Dong",
        "link": "http://arxiv.org/abs/2506.02362v1",
        "abstract": "Model extraction attacks aim to replicate the functionality of a black-box\nmodel through query access, threatening the intellectual property (IP) of\nmachine-learning-as-a-service (MLaaS) providers. Defending against such attacks\nis challenging, as it must balance efficiency, robustness, and utility\npreservation in the real-world scenario. Despite the recent advances, most\nexisting defenses presume that attacker queries have out-of-distribution (OOD)\nsamples, enabling them to detect and disrupt suspicious inputs. However, this\nassumption is increasingly unreliable, as modern models are trained on diverse\ndatasets and attackers often operate under limited query budgets. As a result,\nthe effectiveness of these defenses is significantly compromised in realistic\ndeployment scenarios. To address this gap, we propose MISLEADER (enseMbles of\ndIStiLled modEls Against moDel ExtRaction), a novel defense strategy that does\nnot rely on OOD assumptions. MISLEADER formulates model protection as a bilevel\noptimization problem that simultaneously preserves predictive fidelity on\nbenign inputs and reduces extractability by potential clone models. Our\nframework combines data augmentation to simulate attacker queries with an\nensemble of heterogeneous distilled models to improve robustness and diversity.\nWe further provide a tractable approximation algorithm and derive theoretical\nerror bounds to characterize defense effectiveness. Extensive experiments\nacross various settings validate the utility-preserving and\nextraction-resistant properties of our proposed defense strategy. Our code is\navailable at https://github.com/LabRAI/MISLEADER."
    },
    {
        "date": "2025-05",
        "title": "Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models",
        "author": "Fardin Ahsan Sakib, Ziwei Zhu, Karen Trister Grace, Meliha Yetisgen, and Ozlem Uzuner",
        "link": "http://arxiv.org/abs/2506.00134v1",
        "abstract": "Social determinants of health (SDOH) extraction from clinical text is\ncritical for downstream healthcare analytics. Although large language models\n(LLMs) have shown promise, they may rely on superficial cues leading to\nspurious predictions. Using the MIMIC portion of the SHAC (Social History\nAnnotation Corpus) dataset and focusing on drug status extraction as a case\nstudy, we demonstrate that mentions of alcohol or smoking can falsely induce\nmodels to predict current/past drug use where none is present, while also\nuncovering concerning gender disparities in model performance. We further\nevaluate mitigation strategies - such as prompt engineering and\nchain-of-thought reasoning - to reduce these false positives, providing\ninsights into enhancing LLM reliability in health domains."
    },
    {
        "date": "2025-05",
        "title": "Breaking the Gold Standard: Extracting Forgotten Data under Exact Unlearning in Large Language Models",
        "author": "Xiaoyu Wu, Yifei Pang, Terrance Liu, and Zhiwei Steven Wu",
        "link": "http://arxiv.org/abs/2505.24379v1",
        "abstract": "Large language models are typically trained on datasets collected from the\nweb, which may inadvertently contain harmful or sensitive personal information.\nTo address growing privacy concerns, unlearning methods have been proposed to\nremove the influence of specific data from trained models. Of these, exact\nunlearning -- which retrains the model from scratch without the target data --\nis widely regarded the gold standard, believed to be robust against\nprivacy-related attacks. In this paper, we challenge this assumption by\nintroducing a novel data extraction attack that compromises even exact\nunlearning. Our method leverages both the pre- and post-unlearning models: by\nguiding the post-unlearning model using signals from the pre-unlearning model,\nwe uncover patterns that reflect the removed data distribution. Combining model\nguidance with a token filtering strategy, our attack significantly improves\nextraction success rates -- doubling performance in some cases -- across common\nbenchmarks such as MUSE, TOFU, and WMDP. Furthermore, we demonstrate our\nattack's effectiveness on a simulated medical diagnosis dataset to highlight\nreal-world privacy risks associated with exact unlearning. In light of our\nfindings, which suggest that unlearning may, in a contradictory way, increase\nthe risk of privacy leakage, we advocate for evaluation of unlearning methods\nto consider broader threat models that account not only for post-unlearning\nmodels but also for adversarial access to prior checkpoints."
    },
    {
        "date": "2025-05",
        "title": "System Prompt Extraction Attacks and Defenses in Large Language Models",
        "author": "Badhan Chandra Das, M. Hadi Amini, and Yanzhao Wu",
        "link": "http://arxiv.org/abs/2505.23817v1",
        "abstract": "The system prompt in Large Language Models (LLMs) plays a pivotal role in\nguiding model behavior and response generation. Often containing private\nconfiguration details, user roles, and operational instructions, the system\nprompt has become an emerging attack target. Recent studies have shown that LLM\nsystem prompts are highly susceptible to extraction attacks through\nmeticulously designed queries, raising significant privacy and security\nconcerns. Despite the growing threat, there is a lack of systematic studies of\nsystem prompt extraction attacks and defenses. In this paper, we present a\ncomprehensive framework, SPE-LLM, to systematically evaluate System Prompt\nExtraction attacks and defenses in LLMs. First, we design a set of novel\nadversarial queries that effectively extract system prompts in state-of-the-art\n(SOTA) LLMs, demonstrating the severe risks of LLM system prompt extraction\nattacks. Second, we propose three defense techniques to mitigate system prompt\nextraction attacks in LLMs, providing practical solutions for secure LLM\ndeployments. Third, we introduce a set of rigorous evaluation metrics to\naccurately quantify the severity of system prompt extraction attacks in LLMs\nand conduct comprehensive experiments across multiple benchmark datasets, which\nvalidates the efficacy of our proposed SPE-LLM framework."
    },
    {
        "date": "2025-05",
        "title": "A Lightweight Multi-Expert Generative Language Model System for Engineering Information and Knowledge Extraction",
        "author": "Bogdan Bogachov, and Yaoyao Fiona Zhao",
        "link": "http://arxiv.org/abs/2505.21109v1",
        "abstract": "Despite recent advancements in domain adaptation techniques for large\nlanguage models, these methods remain computationally intensive, and the\nresulting models can still exhibit hallucination issues. Most existing\nadaptation methods do not prioritize reducing the computational resources\nrequired for fine-tuning and inference of language models. Hallucination issues\nhave gradually decreased with each new model release. However, they remain\nprevalent in engineering contexts, where generating well-structured text with\nminimal errors and inconsistencies is critical. This work introduces a novel\napproach called the Small Language Graph (SLG), which is a lightweight\nadaptation solution designed to address the two key challenges outlined above.\nThe system is structured in the form of a graph, where each node represents a\nlightweight expert - a small language model fine-tuned on specific and concise\ntexts. The results of this study have shown that SLG was able to surpass\nconventional fine-tuning methods on the Exact Match metric by 3 times.\nAdditionally, the fine-tuning process was 1.7 times faster compared to that of\na larger stand-alone language model. These findings introduce a potential for\nsmall to medium-sized engineering companies to confidently use generative AI\ntechnologies, such as LLMs, without the necessity to invest in expensive\ncomputational resources. Also, the graph architecture and the small size of\nexpert nodes offer a possible opportunity for distributed AI systems, thus\npotentially diverting the global need for expensive centralized compute\nclusters."
    },
    {
        "date": "2025-05",
        "title": "RADEP: A Resilient Adaptive Defense Framework Against Model Extraction Attacks",
        "author": "Amit Chakraborty, Sayyed Farid Ahamed, Sandip Roy, Soumya Banerjee, Kevin Choi, Abdul Rahman, Alison Hu, Edward Bowen, and Sachin Shetty",
        "link": "http://arxiv.org/abs/2505.19364v1",
        "abstract": "Machine Learning as a Service (MLaaS) enables users to leverage powerful\nmachine learning models through cloud-based APIs, offering scalability and ease\nof deployment. However, these services are vulnerable to model extraction\nattacks, where adversaries repeatedly query the application programming\ninterface (API) to reconstruct a functionally similar model, compromising\nintellectual property and security. Despite various defense strategies being\nproposed, many suffer from high computational costs, limited adaptability to\nevolving attack techniques, and a reduction in performance for legitimate\nusers. In this paper, we introduce a Resilient Adaptive Defense Framework for\nModel Extraction Attack Protection (RADEP), a multifaceted defense framework\ndesigned to counteract model extraction attacks through a multi-layered\nsecurity approach. RADEP employs progressive adversarial training to enhance\nmodel resilience against extraction attempts. Malicious query detection is\nachieved through a combination of uncertainty quantification and behavioral\npattern analysis, effectively identifying adversarial queries. Furthermore, we\ndevelop an adaptive response mechanism that dynamically modifies query outputs\nbased on their suspicion scores, reducing the utility of stolen models.\nFinally, ownership verification is enforced through embedded watermarking and\nbackdoor triggers, enabling reliable identification of unauthorized model use.\nExperimental evaluations demonstrate that RADEP significantly reduces\nextraction success rates while maintaining high detection accuracy with minimal\nimpact on legitimate queries. Extensive experiments show that RADEP effectively\ndefends against model extraction attacks and remains resilient even against\nadaptive adversaries, making it a reliable security framework for MLaaS models."
    },
    {
        "date": "2025-05",
        "title": "Evaluating Query Efficiency and Accuracy of Transfer Learning-based Model Extraction Attack in Federated Learning",
        "author": "Sayyed Farid Ahamed, Sandip Roy, Soumya Banerjee, Marc Vucovich, Kevin Choi, Abdul Rahman, Alison Hu, Edward Bowen, and Sachin Shetty",
        "link": "http://arxiv.org/abs/2505.23791v1",
        "abstract": "Federated Learning (FL) is a collaborative learning framework designed to\nprotect client data, yet it remains highly vulnerable to Intellectual Property\n(IP) threats. Model extraction (ME) attacks pose a significant risk to Machine\nLearning as a Service (MLaaS) platforms, enabling attackers to replicate\nconfidential models by querying black-box (without internal insight) APIs.\nDespite FL's privacy-preserving goals, its distributed nature makes it\nparticularly susceptible to such attacks. This paper examines the vulnerability\nof FL-based victim models to two types of model extraction attacks. For various\nfederated clients built under the NVFlare platform, we implemented ME attacks\nacross two deep learning architectures and three image datasets. We evaluate\nthe proposed ME attack performance using various metrics, including accuracy,\nfidelity, and KL divergence. The experiments show that for different FL\nclients, the accuracy and fidelity of the extracted model are closely related\nto the size of the attack query set. Additionally, we explore a transfer\nlearning based approach where pretrained models serve as the starting point for\nthe extraction process. The results indicate that the accuracy and fidelity of\nthe fine-tuned pretrained extraction models are notably higher, particularly\nwith smaller query sets, highlighting potential advantages for attackers."
    },
    {
        "date": "2025-05",
        "title": "Architectural Backdoors for Within-Batch Data Stealing and Model Inference Manipulation",
        "author": "Nicolas K\u00fcchler, Ivan Petrov, Conrad Grobler, and Ilia Shumailov",
        "link": "http://arxiv.org/abs/2505.18323v1",
        "abstract": "For nearly a decade the academic community has investigated backdoors in\nneural networks, primarily focusing on classification tasks where adversaries\nmanipulate the model prediction. While demonstrably malicious, the immediate\nreal-world impact of such prediction-altering attacks has remained unclear. In\nthis paper we introduce a novel and significantly more potent class of\nbackdoors that builds upon recent advancements in architectural backdoors. We\ndemonstrate how these backdoors can be specifically engineered to exploit\nbatched inference, a common technique for hardware utilization, enabling\nlarge-scale user data manipulation and theft. By targeting the batching\nprocess, these architectural backdoors facilitate information leakage between\nconcurrent user requests and allow attackers to fully control model responses\ndirected at other users within the same batch. In other words, an attacker who\ncan change the model architecture can set and steal model inputs and outputs of\nother users within the same batch. We show that such attacks are not only\nfeasible but also alarmingly effective, can be readily injected into prevalent\nmodel architectures, and represent a truly malicious threat to user privacy and\nsystem integrity. Critically, to counteract this new class of vulnerabilities,\nwe propose a deterministic mitigation strategy that provides formal guarantees\nagainst this new attack vector, unlike prior work that relied on Large Language\nModels to find the backdoors. Our mitigation strategy employs a novel\nInformation Flow Control mechanism that analyzes the model graph and proves\nnon-interference between different user inputs within the same batch. Using our\nmitigation strategy we perform a large scale analysis of models hosted through\nHugging Face and find over 200 models that introduce (unintended) information\nleakage between batch entries due to the use of dynamic quantization."
    },
    {
        "date": "2025-05",
        "title": "Extracting Probabilistic Knowledge from Large Language Models for Bayesian Network Parameterization",
        "author": "Aliakbar Nafar, Kristen Brent Venable, Zijun Cui, and Parisa Kordjamshidi",
        "link": "http://arxiv.org/abs/2505.15918v2",
        "abstract": "In this work, we evaluate the potential of Large Language Models (LLMs) in\nbuilding Bayesian Networks (BNs) by approximating domain expert priors. LLMs\nhave demonstrated potential as factual knowledge bases; however, their\ncapability to generate probabilistic knowledge about real-world events remains\nunderstudied. We explore utilizing the probabilistic knowledge inherent in LLMs\nto derive probability estimates for statements regarding events and their\nrelationships within a BN. Using LLMs in this context allows for the\nparameterization of BNs, enabling probabilistic modeling within specific\ndomains. Our experiments on eighty publicly available Bayesian Networks, from\nhealthcare to finance, demonstrate that querying LLMs about the conditional\nprobabilities of events provides meaningful results when compared to baselines,\nincluding random and uniform distributions, as well as approaches based on\nnext-token generation probabilities. We explore how these LLM-derived\ndistributions can serve as expert priors to refine distributions extracted from\ndata, especially when data is scarce. Overall, this work introduces a promising\nstrategy for automatically constructing Bayesian Networks by combining\nprobabilistic knowledge extracted from LLMs with real-world data. Additionally,\nwe establish the first comprehensive baseline for assessing LLM performance in\nextracting probabilistic knowledge."
    },
    {
        "date": "2025-05",
        "title": "Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models",
        "author": "Zihao Li, Xu Wang, Yuzhe Yang, Ziyu Yao, Haoyi Xiong, and Mengnan Du",
        "link": "http://arxiv.org/abs/2505.15634v4",
        "abstract": "Large Language Models (LLMs) demonstrate the ability to solve reasoning and\nmathematical problems using the Chain-of-Thought (CoT) technique. Expanding CoT\nlength, as seen in models such as DeepSeek-R1, significantly enhances this\nreasoning for complex problems, but requires costly and high-quality long CoT\ndata and fine-tuning. This work, inspired by the deep thinking paradigm of\nDeepSeek-R1, utilizes a steering technique to enhance the reasoning ability of\nan LLM without external datasets. Our method first employs Sparse Autoencoders\n(SAEs) to extract interpretable features from vanilla CoT. These features are\nthen used to steer the LLM's internal states during generation. Recognizing\nthat many LLMs do not have corresponding pre-trained SAEs, we further introduce\na novel SAE-free steering algorithm, which directly computes steering\ndirections from the residual activations of an LLM, obviating the need for an\nexplicit SAE. Experimental results demonstrate that both our SAE-based and\nsubsequent SAE-free steering algorithms significantly enhance the reasoning\ncapabilities of LLMs."
    },
    {
        "date": "2025-05",
        "title": "LOD1 3D City Model from LiDAR: The Impact of Segmentation Accuracy on Quality of Urban 3D Modeling and Morphology Extraction",
        "author": "Fatemeh Chajaei, and Hossein Bagheri",
        "link": "http://arxiv.org/abs/2505.14747v1",
        "abstract": "Three-dimensional reconstruction of buildings, particularly at Level of\nDetail 1 (LOD1), plays a crucial role in various applications such as urban\nplanning, urban environmental studies, and designing optimized transportation\nnetworks. This study focuses on assessing the potential of LiDAR data for\naccurate 3D building reconstruction at LOD1 and extracting morphological\nfeatures from these models. Four deep semantic segmentation models, U-Net,\nAttention U-Net, U-Net3+, and DeepLabV3+, were used, applying transfer learning\nto extract building footprints from LiDAR data. The results showed that U-Net3+\nand Attention U-Net outperformed the others, achieving IoU scores of 0.833 and\n0.814, respectively. Various statistical measures, including maximum, range,\nmode, median, and the 90th percentile, were used to estimate building heights,\nresulting in the generation of 3D models at LOD1. As the main contribution of\nthe research, the impact of segmentation accuracy on the quality of 3D building\nmodeling and the accuracy of morphological features like building area and\nexternal wall surface area was investigated. The results showed that the\naccuracy of building identification (segmentation performance) significantly\naffects the 3D model quality and the estimation of morphological features,\ndepending on the height calculation method. Overall, the UNet3+ method,\nutilizing the 90th percentile and median measures, leads to accurate height\nestimation of buildings and the extraction of morphological features."
    },
    {
        "date": "2025-05",
        "title": "LLM-based Evaluation Policy Extraction for Ecological Modeling",
        "author": "Qi Cheng, Licheng Liu, Qing Zhu, Runlong Yu, Zhenong Jin, Yiqun Xie, and Xiaowei Jia",
        "link": "http://arxiv.org/abs/2505.13794v1",
        "abstract": "Evaluating ecological time series is critical for benchmarking model\nperformance in many important applications, including predicting greenhouse gas\nfluxes, capturing carbon-nitrogen dynamics, and monitoring hydrological cycles.\nTraditional numerical metrics (e.g., R-squared, root mean square error) have\nbeen widely used to quantify the similarity between modeled and observed\necosystem variables, but they often fail to capture domain-specific temporal\npatterns critical to ecological processes. As a result, these methods are often\naccompanied by expert visual inspection, which requires substantial human labor\nand limits the applicability to large-scale evaluation. To address these\nchallenges, we propose a novel framework that integrates metric learning with\nlarge language model (LLM)-based natural language policy extraction to develop\ninterpretable evaluation criteria. The proposed method processes pairwise\nannotations and implements a policy optimization mechanism to generate and\ncombine different assessment metrics. The results obtained on multiple datasets\nfor evaluating the predictions of crop gross primary production and carbon\ndioxide flux have confirmed the effectiveness of the proposed method in\ncapturing target assessment preferences, including both synthetically generated\nand expert-annotated model comparisons. The proposed framework bridges the gap\nbetween numerical metrics and expert knowledge while providing interpretable\nevaluation policies that accommodate the diverse needs of different ecosystem\nmodeling studies."
    },
    {
        "date": "2025-05",
        "title": "Extracting memorized pieces of (copyrighted) books from open-weight language models",
        "author": "A. Feder Cooper, Aaron Gokaslan, Ahmed Ahmed, Amy B. Cyphert, Christopher De Sa, Mark A. Lemley, Daniel E. Ho, and Percy Liang",
        "link": "http://arxiv.org/abs/2505.12546v2",
        "abstract": "Plaintiffs and defendants in copyright lawsuits over generative AI often make\nsweeping, opposing claims about the extent to which large language models\n(LLMs) have memorized plaintiffs' protected expression. Drawing on adversarial\nML and copyright law, we show that these polarized positions dramatically\noversimplify the relationship between memorization and copyright. To do so, we\nleverage a recent probabilistic extraction technique to extract pieces of the\nBooks3 dataset from 17 open-weight LLMs. Through numerous experiments, we show\nthat it's possible to extract substantial parts of at least some books from\ndifferent LLMs. This is evidence that these LLMs have memorized the extracted\ntext; this memorized content is copied inside the model parameters. But the\nresults are complicated: the extent of memorization varies both by model and by\nbook. With our specific experiments, we find that the largest LLMs don't\nmemorize most books--either in whole or in part. However, we also find that\nLlama 3.1 70B memorizes some books, like Harry Potter and the Sorcerer's Stone\nand 1984, almost entirely. In fact, Harry Potter is so memorized that, using a\nseed prompt consisting of just the first line of chapter 1, we can\ndeterministically generate the entire book near-verbatim. We discuss why our\nresults have significant implications for copyright cases, though not ones that\nunambiguously favor either side."
    },
    {
        "date": "2025-05",
        "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models",
        "author": "Luca Collini, Baleegh Ahmad, Joey Ah-kiow, and Ramesh Karri",
        "link": "http://arxiv.org/abs/2505.11963v2",
        "abstract": "Hardware security verification is a challenging and time-consuming task. For\nthis purpose, design engineers may utilize tools such as formal verification,\nlinters, and functional simulation tests, coupled with analysis and a deep\nunderstanding of the hardware design being inspected. Large Language Models\n(LLMs) have been used to assist during this task, either directly or in\nconjunction with existing tools. We improve the state of the art by proposing\nMARVEL, a multi-agent LLM framework for a unified approach to decision-making,\ntool use, and reasoning. MARVEL mimics the cognitive process of a designer\nlooking for security vulnerabilities in RTL code. It consists of a supervisor\nagent that devises the security policy of the system-on-chips (SoCs) using its\nsecurity documentation. It delegates tasks to validate the security policy to\nindividual executor agents. Each executor agent carries out its assigned task\nusing a particular strategy. Each executor agent may use one or more tools to\nidentify potential security bugs in the design and send the results back to the\nsupervisor agent for further analysis and confirmation. MARVEL includes\nexecutor agents that leverage formal tools, linters, simulation tests,\nLLM-based detection schemes, and static analysis-based checks. We test our\napproach on a known buggy SoC based on OpenTitan from the Hack@DATE\ncompetition. We find that 20 of the 48 issues reported by MARVEL pose security\nvulnerabilities."
    },
    {
        "date": "2025-05",
        "title": "LAMP: Extracting Locally Linear Decision Surfaces from LLM World Models",
        "author": "Ryan Chen, Youngmin Ko, Zeyu Zhang, Catherine Cho, Sunny Chung, Mauro Giuffr\u00e9, Dennis L. Shung, and Bradly C. Stadie",
        "link": "http://arxiv.org/abs/2505.11772v2",
        "abstract": "We introduce LAMP (Linear Attribution Mapping Probe), a method that shines\nlight onto a black-box language model's decision surface and studies how\nreliably a model maps its stated reasons to its predictions through a locally\nlinear model approximating the decision surface. LAMP treats the model's own\nself-reported explanations as a coordinate system and fits a locally linear\nsurrogate that links those weights to the model's output. By doing so, it\nreveals which stated factors steer the model's decisions, and by how much. We\napply LAMP to three tasks: sentiment analysis, controversial-topic detection,\nand safety-prompt auditing. Across these tasks, LAMP reveals that many LLMs\nexhibit locally linear decision landscapes. In addition, these surfaces\ncorrelate with human judgments on explanation quality and, on a clinical\ncase-file data set, aligns with expert assessments. Since LAMP operates without\nrequiring access to model gradients, logits, or internal activations, it serves\nas a practical and lightweight framework for auditing proprietary language\nmodels, and enabling assessment of whether a model behaves consistently with\nthe explanations it provides."
    },
    {
        "date": "2025-05",
        "title": "On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction",
        "author": "Fatima Ezzeddine, Rinad Akel, Ihab Sbeity, Silvia Giordano, Marc Langheinrich, and Omran Ayoub",
        "link": "http://arxiv.org/abs/2505.08847v1",
        "abstract": "Machine Learning as a Service (MLaaS) has gained important attraction as a\nmeans for deploying powerful predictive models, offering ease of use that\nenables organizations to leverage advanced analytics without substantial\ninvestments in specialized infrastructure or expertise. However, MLaaS\nplatforms must be safeguarded against security and privacy attacks, such as\nmodel extraction (MEA) attacks. The increasing integration of explainable AI\n(XAI) within MLaaS has introduced an additional privacy challenge, as attackers\ncan exploit model explanations particularly counterfactual explanations (CFs)\nto facilitate MEA. In this paper, we investigate the trade offs among model\nperformance, privacy, and explainability when employing Differential Privacy\n(DP), a promising technique for mitigating CF facilitated MEA. We evaluate two\ndistinct DP strategies: implemented during the classification model training\nand at the explainer during CF generation."
    },
    {
        "date": "2025-05",
        "title": "CM1 -- A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models",
        "author": "Fabian Wolf, Oliver T\u00fcselmann, Arthur Matei, Lukas Hennies, Christoph Rass, and Gernot A. Fink",
        "link": "http://arxiv.org/abs/2505.04214v1",
        "abstract": "The automatic extraction of key-value information from handwritten documents\nis a key challenge in document analysis. A reliable extraction is a\nprerequisite for the mass digitization efforts of many archives. Large Vision\nLanguage Models (LVLM) are a promising technology to tackle this problem\nespecially in scenarios where little annotated training data is available. In\nthis work, we present a novel dataset specifically designed to evaluate the\nfew-shot capabilities of LVLMs. The CM1 documents are a historic collection of\nforms with handwritten entries created in Europe to administer the Care and\nMaintenance program after World War Two. The dataset establishes three\nbenchmarks on extracting name and birthdate information and, furthermore,\nconsiders different training set sizes. We provide baseline results for two\ndifferent LVLMs and compare performances to an established full-page extraction\nmodel. While the traditional full-page model achieves highly competitive\nperformances, our experiments show that when only a few training samples are\navailable the considered LVLMs benefit from their size and heavy pretraining\nand outperform the classical approach."
    },
    {
        "date": "2025-05",
        "title": "DMRL: Data- and Model-aware Reward Learning for Data Extraction",
        "author": "Zhiqiang Wang, and Ruoxi Cheng",
        "link": "http://arxiv.org/abs/2505.06284v1",
        "abstract": "Large language models (LLMs) are inherently vulnerable to unintended privacy\nbreaches. Consequently, systematic red-teaming research is essential for\ndeveloping robust defense mechanisms. However, current data extraction methods\nsuffer from several limitations: (1) rely on dataset duplicates (addressable\nvia deduplication), (2) depend on prompt engineering (now countered by\ndetection and defense), and (3) rely on random-search adversarial generation.\nTo address these challenges, we propose DMRL, a Data- and Model-aware Reward\nLearning approach for data extraction. This technique leverages inverse\nreinforcement learning to extract sensitive data from LLMs. Our method consists\nof two main components: (1) constructing an introspective reasoning dataset\nthat captures leakage mindsets to guide model behavior, and (2) training reward\nmodels with Group Relative Policy Optimization (GRPO), dynamically tuning\noptimization based on task difficulty at both the data and model levels.\nComprehensive experiments across various LLMs demonstrate that DMRL outperforms\nall baseline methods in data extraction performance."
    },
    {
        "date": "2025-05",
        "title": "Non-Adaptive Cryptanalytic Time-Space Lower Bounds via a Shearer-like Inequality for Permutations",
        "author": "Itai Dinur, Nathan Keller, and Avichai Marmor",
        "link": "http://arxiv.org/abs/2505.00894v2",
        "abstract": "The power of adaptivity in algorithms has been intensively studied in diverse\nareas of theoretical computer science. In this paper, we obtain a number of\nsharp lower bound results which show that adaptivity provides a significant\nextra power in cryptanalytic time-space tradeoffs with (possibly unlimited)\npreprocessing time.\n  Most notably, we consider the discrete logarithm (DLOG) problem in a generic\ngroup of $N$ elements. The classical `baby-step giant-step' algorithm for the\nproblem has time complexity $T=O(\\sqrt{N})$, uses $O(\\sqrt{N})$ bits of space\n(up to logarithmic factors in $N$) and achieves constant success probability.\n  We examine a generalized setting where an algorithm obtains an advice string\nof $S$ bits and is allowed to make $T$ arbitrary non-adaptive queries that\ndepend on the advice string (but not on the challenge group element).\n  We show that in this setting, the $T=O(\\sqrt{N})$ online time complexity of\nthe baby-step giant-step algorithm cannot be improved, unless the advice string\nis more than $\\Omega(\\sqrt{N})$ bits long. This lies in stark contrast with the\nclassical adaptive Pollard's rho algorithm for DLOG, which can exploit\npreprocessing to obtain the tradeoff curve $ST^2=O(N)$. We obtain similar sharp\nlower bounds for several other cryptanalytic problems.\n  To obtain our results, we present a new model that allows analyzing\nnon-adaptive preprocessing algorithms for a wide array of search and decision\nproblems in a unified way. Since previous proof techniques inherently cannot\ndistinguish between adaptive and non-adaptive algorithms for the problems in\nour model, they cannot be used to obtain our results. Consequently, our proof\nuses a variant of Shearer's lemma for this setting, due to Barthe,\nCordero-Erausquin, Ledoux, and Maurey (2011). This seems to be the first time a\nvariant of Shearer's lemma for permutations is used in an algorithmic context."
    },
    {
        "date": "2025-04",
        "title": "DeeP-Mod: Deep Dynamic Programming based Environment Modelling using Feature Extraction",
        "author": "Chris Child, and Lam Ngo",
        "link": "http://arxiv.org/abs/2504.20535v1",
        "abstract": "The DeeP-Mod framework builds an environment model using features from a Deep\nDynamic Programming Network (DDPN), trained via a Deep Q-Network (DQN). While\nDeep Q-Learning is effective in decision-making, state information is lost in\ndeeper DQN layers due to mixed state-action representations. We address this by\nusing Dynamic Programming (DP) to train a DDPN, where Value Iteration ensures\nthe output represents state values, not state-action pairs. Extracting features\nfrom the DDPN preserves state information, enabling task and action set\nindependence. We show that a reduced DDPN can be trained using features\nextracted from the original DDPN trained on an identical problem. This reduced\nDDPN achieves faster convergence under noise and outperforms the original DDPN.\nFinally, we introduce the DeeP-Mod framework, which creates an environment\nmodel using the evolution of features extracted from a DDPN in response to\nactions. A second DDPN, which learns directly from this feature model rather\nthan raw states, can learn an effective feature-value representation and thus\noptimal policy. A key advantage of DeeP-Mod is that an externally defined\nenvironment model is not needed at any stage, making DDPN applicable to a wide\nrange of environments."
    },
    {
        "date": "2025-04",
        "title": "A Multimodal Pipeline for Clinical Data Extraction: Applying Vision-Language Models to Scans of Transfusion Reaction Reports",
        "author": "Henning Sch\u00e4fer, Cynthia S. Schmidt, Johannes Wutzkowsky, Kamil Lorek, Lea Reinartz, Johannes R\u00fcckert, Christian Temme, Britta B\u00f6ckmann, Peter A. Horn, and Christoph M. Friedrich",
        "link": "http://arxiv.org/abs/2504.20220v1",
        "abstract": "Despite the growing adoption of electronic health records, many processes\nstill rely on paper documents, reflecting the heterogeneous real-world\nconditions in which healthcare is delivered. The manual transcription process\nis time-consuming and prone to errors when transferring paper-based data to\ndigital formats. To streamline this workflow, this study presents an\nopen-source pipeline that extracts and categorizes checkbox data from scanned\ndocuments. Demonstrated on transfusion reaction reports, the design supports\nadaptation to other checkbox-rich document types. The proposed method\nintegrates checkbox detection, multilingual optical character recognition (OCR)\nand multilingual vision-language models (VLMs). The pipeline achieves high\nprecision and recall compared against annually compiled gold-standards from\n2017 to 2024. The result is a reduction in administrative workload and accurate\nregulatory reporting. The open-source availability of this pipeline encourages\nself-hosted parsing of checkbox forms."
    },
    {
        "date": "2025-04",
        "title": "Hallucinations and Key Information Extraction in Medical Texts: A Comprehensive Assessment of Open-Source Large Language Models",
        "author": "Anindya Bijoy Das, Shibbir Ahmed, and Shahnewaz Karim Sakib",
        "link": "http://arxiv.org/abs/2504.19061v2",
        "abstract": "Clinical summarization is crucial in healthcare as it distills complex\nmedical data into digestible information, enhancing patient understanding and\ncare management. Large language models (LLMs) have shown significant potential\nin automating and improving the accuracy of such summarizations due to their\nadvanced natural language understanding capabilities. These models are\nparticularly applicable in the context of summarizing medical/clinical texts,\nwhere precise and concise information transfer is essential. In this paper, we\ninvestigate the effectiveness of open-source LLMs in extracting key events from\ndischarge reports, including admission reasons, major in-hospital events, and\ncritical follow-up actions. In addition, we also assess the prevalence of\nvarious types of hallucinations in the summaries produced by these models.\nDetecting hallucinations is vital as it directly influences the reliability of\nthe information, potentially affecting patient care and treatment outcomes. We\nconduct comprehensive simulations to rigorously evaluate the performance of\nthese models, further probing the accuracy and fidelity of the extracted\ncontent in clinical summarization. Our results reveal that while the LLMs\n(e.g., Qwen2.5 and DeepSeek-v2) perform quite well in capturing admission\nreasons and hospitalization events, they are generally less consistent when it\ncomes to identifying follow-up recommendations, highlighting broader challenges\nin leveraging LLMs for comprehensive summarization."
    },
    {
        "date": "2025-04",
        "title": "EMRModel: A Large Language Model for Extracting Medical Consultation Dialogues into Structured Medical Records",
        "author": "Shuguang Zhao, Qiangzhong Feng, Zhiyang He, Peipei Sun, Yingying Wang, Xiaodong Tao, Xiaoliang Lu, Mei Cheng, Xinyue Wu, Yanyan Wang, and Wei Liang",
        "link": "http://arxiv.org/abs/2504.16448v1",
        "abstract": "Medical consultation dialogues contain critical clinical information, yet\ntheir unstructured nature hinders effective utilization in diagnosis and\ntreatment. Traditional methods, relying on rule-based or shallow machine\nlearning techniques, struggle to capture deep and implicit semantics. Recently,\nlarge pre-trained language models and Low-Rank Adaptation (LoRA), a lightweight\nfine-tuning method, have shown promise for structured information extraction.\nWe propose EMRModel, a novel approach that integrates LoRA-based fine-tuning\nwith code-style prompt design, aiming to efficiently convert medical\nconsultation dialogues into structured electronic medical records (EMRs).\nAdditionally, we construct a high-quality, realistically grounded dataset of\nmedical consultation dialogues with detailed annotations. Furthermore, we\nintroduce a fine-grained evaluation benchmark for medical consultation\ninformation extraction and provide a systematic evaluation methodology,\nadvancing the optimization of medical natural language processing (NLP) models.\nExperimental results show EMRModel achieves an F1 score of 88.1%, improving\nby49.5% over standard pre-trained models. Compared to traditional LoRA\nfine-tuning methods, our model shows superior performance, highlighting its\neffectiveness in structured medical record extraction tasks."
    },
    {
        "date": "2025-04",
        "title": "A Large-Language Model Framework for Relative Timeline Extraction from PubMed Case Reports",
        "author": "Jing Wang, and Jeremy C Weiss",
        "link": "http://arxiv.org/abs/2504.12350v1",
        "abstract": "Timing of clinical events is central to characterization of patient\ntrajectories, enabling analyses such as process tracing, forecasting, and\ncausal reasoning. However, structured electronic health records capture few\ndata elements critical to these tasks, while clinical reports lack temporal\nlocalization of events in structured form. We present a system that transforms\ncase reports into textual time series-structured pairs of textual events and\ntimestamps. We contrast manual and large language model (LLM) annotations\n(n=320 and n=390 respectively) of ten randomly-sampled PubMed open-access\n(PMOA) case reports (N=152,974) and assess inter-LLM agreement (n=3,103; N=93).\nWe find that the LLM models have moderate event recall(O1-preview: 0.80) but\nhigh temporal concordance among identified events (O1-preview: 0.95). By\nestablishing the task, annotation, and assessment systems, and by demonstrating\nhigh concordance, this work may serve as a benchmark for leveraging the PMOA\ncorpus for temporal analytics."
    },
    {
        "date": "2025-04",
        "title": "LauraTSE: Target Speaker Extraction using Auto-Regressive Decoder-Only Language Models",
        "author": "Beilong Tang, Bang Zeng, and Ming Li",
        "link": "http://arxiv.org/abs/2504.07402v3",
        "abstract": "We propose LauraTSE, an Auto-Regressive Decoder-Only Language Model for\nTarget Speaker Extraction built upon the LauraGPT backbone. LauraTSE employs a\nsmall-scale auto-regressive decoder-only language model that generates the\ninitial layers of the target speech's discrete codec representations from the\ncontinuous embeddings of both the mixture and reference speech. These outputs\nserve as coarse-grained predictions. To refine them, a one-step encoder-only\nlanguage model reconstructs the full codec representation by integrating\ninformation from both the mixture and the reference speech, adding fine-grained\ndetails. Experimental results show that our approach can achieve promising\nperformance. Additionally, we conduct ablation studies to investigate the data\nscalability and the contribution of the encoder-only model."
    },
    {
        "date": "2025-03",
        "title": "Extracting Patient History from Clinical Text: A Comparative Study of Clinical Large Language Models",
        "author": "Hieu Nghiem, Tuan-Dung Le, Suhao Chen, Thanh Thieu, Andrew Gin, Ellie Phuong Nguyen, Dursun Delen, Johnson Thomas, Jivan Lamichhane, and Zhuqi Miao",
        "link": "http://arxiv.org/abs/2503.23281v1",
        "abstract": "Extracting medical history entities (MHEs) related to a patient's chief\ncomplaint (CC), history of present illness (HPI), and past, family, and social\nhistory (PFSH) helps structure free-text clinical notes into standardized EHRs,\nstreamlining downstream tasks like continuity of care, medical coding, and\nquality metrics. Fine-tuned clinical large language models (cLLMs) can assist\nin this process while ensuring the protection of sensitive data via on-premises\ndeployment. This study evaluates the performance of cLLMs in recognizing\nCC/HPI/PFSH-related MHEs and examines how note characteristics impact model\naccuracy. We annotated 1,449 MHEs across 61 outpatient-related clinical notes\nfrom the MTSamples repository. To recognize these entities, we fine-tuned seven\nstate-of-the-art cLLMs. Additionally, we assessed the models' performance when\nenhanced by integrating, problems, tests, treatments, and other basic medical\nentities (BMEs). We compared the performance of these models against GPT-4o in\na zero-shot setting. To further understand the textual characteristics\naffecting model accuracy, we conducted an error analysis focused on note\nlength, entity length, and segmentation. The cLLMs showed potential in reducing\nthe time required for extracting MHEs by over 20%. However, detecting many\ntypes of MHEs remained challenging due to their polysemous nature and the\nfrequent involvement of non-medical vocabulary. Fine-tuned GatorTron and\nGatorTronS, two of the most extensively trained cLLMs, demonstrated the highest\nperformance. Integrating pre-identified BME information improved model\nperformance for certain entities. Regarding the impact of textual\ncharacteristics on model performance, we found that longer entities were harder\nto identify, note length did not correlate with a higher error rate, and\nwell-organized segments with headings are beneficial for the extraction."
    },
    {
        "date": "2025-03",
        "title": "ICE: Intrinsic Concept Extraction from a Single Image via Diffusion Models",
        "author": "Fernando Julio Cendra, and Kai Han",
        "link": "http://arxiv.org/abs/2503.19902v2",
        "abstract": "The inherent ambiguity in defining visual concepts poses significant\nchallenges for modern generative models, such as the diffusion-based\nText-to-Image (T2I) models, in accurately learning concepts from a single\nimage. Existing methods lack a systematic way to reliably extract the\ninterpretable underlying intrinsic concepts. To address this challenge, we\npresent ICE, short for Intrinsic Concept Extraction, a novel framework that\nexclusively utilises a T2I model to automatically and systematically extract\nintrinsic concepts from a single image. ICE consists of two pivotal stages. In\nthe first stage, ICE devises an automatic concept localization module to\npinpoint relevant text-based concepts and their corresponding masks within the\nimage. This critical stage streamlines concept initialization and provides\nprecise guidance for subsequent analysis. The second stage delves deeper into\neach identified mask, decomposing the object-level concepts into intrinsic\nconcepts and general concepts. This decomposition allows for a more granular\nand interpretable breakdown of visual elements. Our framework demonstrates\nsuperior performance on intrinsic concept extraction from a single image in an\nunsupervised manner. Project page: https://visual-ai.github.io/ice"
    },
    {
        "date": "2025-03",
        "title": "Model-Guardian: Protecting against Data-Free Model Stealing Using Gradient Representations and Deceptive Predictions",
        "author": "Yunfei Yang, Xiaojun Chen, Yuexin Xuan, and Zhendong Zhao",
        "link": "http://arxiv.org/abs/2503.18081v1",
        "abstract": "Model stealing attack is increasingly threatening the confidentiality of\nmachine learning models deployed in the cloud. Recent studies reveal that\nadversaries can exploit data synthesis techniques to steal machine learning\nmodels even in scenarios devoid of real data, leading to data-free model\nstealing attacks. Existing defenses against such attacks suffer from\nlimitations, including poor effectiveness, insufficient generalization ability,\nand low comprehensiveness. In response, this paper introduces a novel defense\nframework named Model-Guardian. Comprising two components, Data-Free Model\nStealing Detector (DFMS-Detector) and Deceptive Predictions (DPreds),\nModel-Guardian is designed to address the shortcomings of current defenses with\nthe help of the artifact properties of synthetic samples and gradient\nrepresentations of samples. Extensive experiments on seven prevalent data-free\nmodel stealing attacks showcase the effectiveness and superior generalization\nability of Model-Guardian, outperforming eleven defense methods and\nestablishing a new state-of-the-art performance. Notably, this work pioneers\nthe utilization of various GANs and diffusion models for generating highly\nrealistic query samples in attacks, with Model-Guardian demonstrating accurate\ndetection capabilities."
    },
    {
        "date": "2025-03",
        "title": "Feature-Based Dual Visual Feature Extraction Model for Compound Multimodal Emotion Recognition",
        "author": "Ran Liu, Fengyu Zhang, Cong Yu, Longjiang Yang, Zhuofan Wen, Siyuan Zhang, Hailiang Yao, Shun Chen, Zheng Lian, and Bin Liu",
        "link": "http://arxiv.org/abs/2503.17453v1",
        "abstract": "This article presents our results for the eighth Affective Behavior Analysis\nin-the-wild (ABAW) competition.Multimodal emotion recognition (ER) has\nimportant applications in affective computing and human-computer interaction.\nHowever, in the real world, compound emotion recognition faces greater issues\nof uncertainty and modal conflicts. For the Compound Expression (CE)\nRecognition Challenge,this paper proposes a multimodal emotion recognition\nmethod that fuses the features of Vision Transformer (ViT) and Residual Network\n(ResNet). We conducted experiments on the C-EXPR-DB and MELD datasets. The\nresults show that in scenarios with complex visual and audio cues (such as\nC-EXPR-DB), the model that fuses the features of ViT and ResNet exhibits\nsuperior performance.Our code are avalible on\nhttps://github.com/MyGitHub-ax/8th_ABAW"
    },
    {
        "date": "2025-03",
        "title": "ATOM: A Framework of Detecting Query-Based Model Extraction Attacks for Graph Neural Networks",
        "author": "Zhan Cheng, Bolin Shen, Tianming Sha, Yuan Gao, Shibo Li, and Yushun Dong",
        "link": "http://arxiv.org/abs/2503.16693v1",
        "abstract": "Graph Neural Networks (GNNs) have gained traction in Graph-based Machine\nLearning as a Service (GMLaaS) platforms, yet they remain vulnerable to\ngraph-based model extraction attacks (MEAs), where adversaries reconstruct\nsurrogate models by querying the victim model. Existing defense mechanisms,\nsuch as watermarking and fingerprinting, suffer from poor real-time\nperformance, susceptibility to evasion, or reliance on post-attack\nverification, making them inadequate for handling the dynamic characteristics\nof graph-based MEA variants. To address these limitations, we propose ATOM, a\nnovel real-time MEA detection framework tailored for GNNs. ATOM integrates\nsequential modeling and reinforcement learning to dynamically detect evolving\nattack patterns, while leveraging $k$-core embedding to capture the structural\nproperties, enhancing detection precision. Furthermore, we provide theoretical\nanalysis to characterize query behaviors and optimize detection strategies.\nExtensive experiments on multiple real-world datasets demonstrate that ATOM\noutperforms existing approaches in detection performance, maintaining stable\nacross different time steps, thereby offering a more effective defense\nmechanism for GMLaaS environments."
    },
    {
        "date": "2025-03",
        "title": "BI-RADS prediction of mammographic masses using uncertainty information extracted from a Bayesian Deep Learning model",
        "author": "Mohaddeseh Chegini, and Ali Mahloojifar",
        "link": "http://arxiv.org/abs/2503.13999v2",
        "abstract": "The BI_RADS score is a probabilistic reporting tool used by radiologists to\nexpress the level of uncertainty in predicting breast cancer based on some\nmorphological features in mammography images. There is a significant\nvariability in describing masses which sometimes leads to BI_RADS\nmisclassification. Using a BI_RADS prediction system is required to support the\nfinal radiologist decisions. In this study, the uncertainty information\nextracted by a Bayesian deep learning model is utilized to predict the BI_RADS\nscore. The investigation results based on the pathology information demonstrate\nthat the f1-scores of the predictions of the radiologist are 42.86%, 48.33% and\n48.28%, meanwhile, the f1-scores of the model performance are 73.33%, 59.60%\nand 59.26% in the BI_RADS 2, 3 and 5 dataset samples, respectively. Also, the\nmodel can distinguish malignant from benign samples in the BI_RADS 0 category\nof the used dataset with an accuracy of 75.86% and correctly identify all\nmalignant samples as BI_RADS 5. The Grad-CAM visualization shows the model pays\nattention to the morphological features of the lesions. Therefore, this study\nshows the uncertainty-aware Bayesian Deep Learning model can report his\nuncertainty about the malignancy of a lesion based on morphological features,\nlike a radiologist."
    },
    {
        "date": "2025-03",
        "title": "ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction",
        "author": "Tong Zhou, Shijin Duan, Gaowen Liu, Charles Fleming, Ramana Rao Kompella, Shaolei Ren, and Xiaolin Xu",
        "link": "http://arxiv.org/abs/2503.13224v1",
        "abstract": "Pre-trained models are valuable intellectual property, capturing both\ndomain-specific and domain-invariant features within their weight spaces.\nHowever, model extraction attacks threaten these assets by enabling\nunauthorized source-domain inference and facilitating cross-domain transfer via\nthe exploitation of domain-invariant features. In this work, we introduce\n**ProDiF**, a novel framework that leverages targeted weight space manipulation\nto secure pre-trained models against extraction attacks. **ProDiF** quantifies\nthe transferability of filters and perturbs the weights of critical filters in\nunsecured memory, while preserving actual critical weights in a Trusted\nExecution Environment (TEE) for authorized users. A bi-level optimization\nfurther ensures resilience against adaptive fine-tuning attacks. Experimental\nresults show that **ProDiF** reduces source-domain accuracy to near-random\nlevels and decreases cross-domain transferability by 74.65\\%, providing robust\nprotection for pre-trained models. This work offers comprehensive protection\nfor pre-trained DNN models and highlights the potential of weight space\nmanipulation as a novel approach to model security."
    },
    {
        "date": "2025-03",
        "title": "Defense Against Model Stealing Based on Account-Aware Distribution Discrepancy",
        "author": "Jian-Ping Mei, Weibin Zhang, Jie Chen, Xuyun Zhang, and Tiantian Zhu",
        "link": "http://arxiv.org/abs/2503.12497v1",
        "abstract": "Malicious users attempt to replicate commercial models functionally at low\ncost by training a clone model with query responses. It is challenging to\ntimely prevent such model-stealing attacks to achieve strong protection and\nmaintain utility. In this paper, we propose a novel non-parametric detector\ncalled Account-aware Distribution Discrepancy (ADD) to recognize queries from\nmalicious users by leveraging account-wise local dependency. We formulate each\nclass as a Multivariate Normal distribution (MVN) in the feature space and\nmeasure the malicious score as the sum of weighted class-wise distribution\ndiscrepancy. The ADD detector is combined with random-based prediction\npoisoning to yield a plug-and-play defense module named D-ADD for image\nclassification models. Results of extensive experimental studies show that\nD-ADD achieves strong defense against different types of attacks with little\ninterference in serving benign users for both soft and hard-label settings."
    },
    {
        "date": "2025-03",
        "title": "Review GIDE -- Restaurant Review Gastrointestinal Illness Detection and Extraction with Large Language Models",
        "author": "Timothy Laurence, Joshua Harris, Leo Loman, Amy Douglas, Yung-Wai Chan, Luke Hounsome, Lesley Larkin, and Michael Borowitz",
        "link": "http://arxiv.org/abs/2503.09743v1",
        "abstract": "Foodborne gastrointestinal (GI) illness is a common cause of ill health in\nthe UK. However, many cases do not interact with the healthcare system, posing\nsignificant challenges for traditional surveillance methods. The growth of\npublicly available online restaurant reviews and advancements in large language\nmodels (LLMs) present potential opportunities to extend disease surveillance by\nidentifying public reports of GI illness. In this study, we introduce a novel\nannotation schema, developed with experts in GI illness, applied to the Yelp\nOpen Dataset of reviews. Our annotations extend beyond binary disease\ndetection, to include detailed extraction of information on symptoms and foods.\nWe evaluate the performance of open-weight LLMs across these three tasks: GI\nillness detection, symptom extraction, and food extraction. We compare this\nperformance to RoBERTa-based classification models fine-tuned specifically for\nthese tasks. Our results show that using prompt-based approaches, LLMs achieve\nmicro-F1 scores of over 90% for all three of our tasks. Using prompting alone,\nwe achieve micro-F1 scores that exceed those of smaller fine-tuned models. We\nfurther demonstrate the robustness of LLMs in GI illness detection across three\nbias-focused experiments. Our results suggest that publicly available review\ntext and LLMs offer substantial potential for public health surveillance of GI\nillness by enabling highly effective extraction of key information. While LLMs\nappear to exhibit minimal bias in processing, the inherent limitations of\nrestaurant review data highlight the need for cautious interpretation of\nresults."
    },
    {
        "date": "2025-03",
        "title": "Attackers Can Do Better: Over- and Understated Factors of Model Stealing Attacks",
        "author": "Daryna Oliynyk, Rudolf Mayer, and Andreas Rauber",
        "link": "http://arxiv.org/abs/2503.06188v1",
        "abstract": "Machine learning models were shown to be vulnerable to model stealing\nattacks, which lead to intellectual property infringement. Among other methods,\nsubstitute model training is an all-encompassing attack applicable to any\nmachine learning model whose behaviour can be approximated from input-output\nqueries. Whereas prior works mainly focused on improving the performance of\nsubstitute models by, e.g. developing a new substitute training method, there\nhave been only limited ablation studies on the impact the attacker's strength\nhas on the substitute model's performance. As a result, different authors came\nto diverse, sometimes contradicting, conclusions. In this work, we exhaustively\nexamine the ambivalent influence of different factors resulting from varying\nthe attacker's capabilities and knowledge on a substitute training attack. Our\nfindings suggest that some of the factors that have been considered important\nin the past are, in fact, not that influential; instead, we discover new\ncorrelations between attack conditions and success rate. In particular, we\ndemonstrate that better-performing target models enable higher-fidelity attacks\nand explain the intuition behind this phenomenon. Further, we propose to shift\nthe focus from the complexity of target models toward the complexity of their\nlearning tasks. Therefore, for the substitute model, rather than aiming for a\nhigher architecture complexity, we suggest focusing on getting data of higher\ncomplexity and an appropriate architecture. Finally, we demonstrate that even\nin the most limited data-free scenario, there is no need to overcompensate weak\nknowledge with millions of queries. Our results often exceed or match the\nperformance of previous attacks that assume a stronger attacker, suggesting\nthat these stronger attacks are likely endangering a model owner's intellectual\nproperty to a significantly higher degree than shown until now."
    },
    {
        "date": "2025-03",
        "title": "EVE: Towards End-to-End Video Subtitle Extraction with Vision-Language Models",
        "author": "Haiyang Yu, Jinghui Lu, Yanjie Wang, Yang Li, Han Wang, Can Huang, and Bin Li",
        "link": "http://arxiv.org/abs/2503.04058v1",
        "abstract": "The advent of Large Vision-Language Models (LVLMs) has advanced the\nvideo-based tasks, such as video captioning and video understanding. Some\nprevious research indicates that taking texts in videos as input can further\nimprove the performance of video understanding. As a type of indispensable\ninformation in short videos or movies, subtitles can assist LVLMs to better\nunderstand videos. Most existing methods for video subtitle extraction are\nbased on a multi-stage framework, handling each frame independently. They can\nhardly exploit the temporal information of videos. Although some LVLMs exhibit\nthe robust OCR capability, predicting accurate timestamps for subtitle texts is\nstill challenging. In this paper, we propose an End-to-end Video Subtitle\nExtraction method, called EVE, which consists of three modules: a vision\nencoder, an adapter module, and a large language model. To effectively compress\nthe visual tokens from the vision encoder, we propose a novel adapter\nInterleavedVT to interleave two modalities. It contains a visual compressor and\na textual region compressor. The proposed InterleavedVT exploits both the\nmerits of average pooling and Q-Former in token compression. Taking the\ntemporal information of videos into account, we introduce a sliding-window\nmechanism in the textual region compressor. To benchmark the video subtitle\nextraction task, we propose a large dataset ViSa including 2.5M videos.\nExtensive experiments on ViSa demonstrate that the proposed EVE can outperform\nexisting open-sourced tools and LVLMs."
    },
    {
        "date": "2025-03",
        "title": "OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature Extraction",
        "author": "Huang Huang, Fangchen Liu, Letian Fu, Tingfan Wu, Mustafa Mukadam, Jitendra Malik, Ken Goldberg, and Pieter Abbeel",
        "link": "http://arxiv.org/abs/2503.03734v3",
        "abstract": "Vision-Language-Action (VLA) models aim to predict robotic actions based on\nvisual observations and language instructions. Existing approaches require\nfine-tuning pre-trained visionlanguage models (VLMs) as visual and language\nfeatures are independently fed into downstream policies, degrading the\npre-trained semantic alignments. We propose OTTER, a novel VLA architecture\nthat leverages these existing alignments through explicit, text-aware visual\nfeature extraction. Instead of processing all visual features, OTTER\nselectively extracts and passes only task-relevant visual features that are\nsemantically aligned with the language instruction to the policy transformer.\nThis allows OTTER to keep the pre-trained vision-language encoders frozen.\nThereby, OTTER preserves and utilizes the rich semantic understanding learned\nfrom large-scale pre-training, enabling strong zero-shot generalization\ncapabilities. In simulation and real-world experiments, OTTER significantly\noutperforms existing VLA models, demonstrating strong zeroshot generalization\nto novel objects and environments. Video, code, checkpoints, and dataset:\nhttps://ottervla.github.io/."
    },
    {
        "date": "2025-03",
        "title": "An Aspect Extraction Framework using Different Embedding Types, Learning Models, and Dependency Structure",
        "author": "Ali Erkan, and Tunga G\u00fcng\u00f6r",
        "link": "http://arxiv.org/abs/2503.03512v1",
        "abstract": "Aspect-based sentiment analysis has gained significant attention in recent\nyears due to its ability to provide fine-grained insights for sentiment\nexpressions related to specific features of entities. An important component of\naspect-based sentiment analysis is aspect extraction, which involves\nidentifying and extracting aspect terms from text. Effective aspect extraction\nserves as the foundation for accurate sentiment analysis at the aspect level.\nIn this paper, we propose aspect extraction models that use different types of\nembeddings for words and part-of-speech tags and that combine several learning\nmodels. We also propose tree positional encoding that is based on dependency\nparsing output to capture better the aspect positions in sentences. In\naddition, a new aspect extraction dataset is built for Turkish by machine\ntranslating an English dataset in a controlled setting. The experiments\nconducted on two Turkish datasets showed that the proposed models mostly\noutperform the studies that use the same datasets, and incorporating tree\npositional encoding increases the performance of the models."
    },
    {
        "date": "2025-03",
        "title": "Computer-aided shape features extraction and regression models for predicting the ascending aortic aneurysm growth rate",
        "author": "Leonardo Geronzi, Antonio Martinez, Michel Rochette, Kexin Yan, Aline Bel-Brunon, Pascal Haigron, Pierre Escrig, Jacques Tomasi, Morgan Daniel, Alain Lalande, Siyu Lin, Diana Marcela Marin-Castrillon, Olivier Bouchot, Jean Porterie, Pier Paolo Valentini, and Marco Evangelos Biancolini",
        "link": "http://arxiv.org/abs/2503.02915v1",
        "abstract": "Objective: ascending aortic aneurysm growth prediction is still challenging\nin clinics. In this study, we evaluate and compare the ability of local and\nglobal shape features to predict ascending aortic aneurysm growth.\n  Material and methods: 70 patients with aneurysm, for which two 3D\nacquisitions were available, are included. Following segmentation, three local\nshape features are computed: (1) the ratio between maximum diameter and length\nof the ascending aorta centerline, (2) the ratio between the length of external\nand internal lines on the ascending aorta and (3) the tortuosity of the\nascending tract. By exploiting longitudinal data, the aneurysm growth rate is\nderived. Using radial basis function mesh morphing, iso-topological surface\nmeshes are created. Statistical shape analysis is performed through\nunsupervised principal component analysis (PCA) and supervised partial least\nsquares (PLS). Two types of global shape features are identified: three\nPCA-derived and three PLS-based shape modes. Three regression models are set\nfor growth prediction: two based on gaussian support vector machine using local\nand PCA-derived global shape features; the third is a PLS linear regression\nmodel based on the related global shape features. The prediction results are\nassessed and the aortic shapes most prone to growth are identified.\n  Results: the prediction root mean square error from leave-one-out\ncross-validation is: 0.112 mm/month, 0.083 mm/month and 0.066 mm/month for\nlocal, PCA-based and PLS-derived shape features, respectively. Aneurysms close\nto the root with a large initial diameter report faster growth.\n  Conclusion: global shape features might provide an important contribution for\npredicting the aneurysm growth."
    },
    {
        "date": "2025-02",
        "title": "PolyPrompt: Automating Knowledge Extraction from Multilingual Language Models with Dynamic Prompt Generation",
        "author": "Nathan Roll",
        "link": "http://arxiv.org/abs/2502.19756v2",
        "abstract": "Large language models (LLMs) showcase increasingly impressive English\nbenchmark scores, however their performance profiles remain inconsistent across\nmultilingual settings. To address this gap, we introduce PolyPrompt, a novel,\nparameter-efficient framework for enhancing the multilingual capabilities of\nLLMs. Our method learns a set of trigger tokens for each language through a\ngradient-based search, identifying the input query's language and selecting the\ncorresponding trigger tokens which are prepended to the prompt during\ninference. We perform experiments on two ~1 billion parameter models, with\nevaluations on the global MMLU benchmark across fifteen typologically and\nresource diverse languages, demonstrating accuracy gains of 3.7%-19.9% compared\nto naive and translation-pipeline baselines."
    },
    {
        "date": "2025-02",
        "title": "Can Large Language Models Extract Customer Needs as well as Professional Analysts?",
        "author": "Artem Timoshenko, Chengfeng Mao, and John R. Hauser",
        "link": "http://arxiv.org/abs/2503.01870v1",
        "abstract": "Identifying customer needs (CNs) is important for product management, product\ndevelopment, and marketing. Applications rely on professional analysts\ninterpreting textual data (e.g., interview transcripts, online reviews) to\nunderstand the nuances of customer experience and concisely formulate \"jobs to\nbe done.\" The task is cognitively complex and time-consuming. Current practice\nfacilitates the process with keyword search and machine learning but relies on\nhuman judgment to formulate CNs. We examine whether Large Language Models\n(LLMs) can automatically extract CNs. Because evaluating CNs requires\nprofessional judgment, we partnered with a marketing consulting firm to conduct\na blind study of CNs extracted by: (1) a foundational LLM with prompt\nengineering only (Base LLM), (2) an LLM fine-tuned with professionally\nidentified CNs (SFT LLM), and (3) professional analysts. The SFT LLM performs\nas well as or better than professional analysts when extracting CNs. The\nextracted CNs are well-formulated, sufficiently specific to identify\nopportunities, and justified by source content (no hallucinations). The SFT LLM\nis efficient and provides more complete coverage of CNs. The Base LLM was not\nsufficiently accurate or specific. Organizations can rely on SFT LLMs to reduce\nmanual effort, enhance the precision of CN articulation, and provide improved\ninsight for innovation and marketing strategy."
    },
    {
        "date": "2025-02",
        "title": "Examining the Threat Landscape: Foundation Models and Model Stealing",
        "author": "Ankita Raj, Deepankar Varma, and Chetan Arora",
        "link": "http://arxiv.org/abs/2502.18077v1",
        "abstract": "Foundation models (FMs) for computer vision learn rich and robust\nrepresentations, enabling their adaptation to task/domain-specific deployments\nwith little to no fine-tuning. However, we posit that the very same strength\ncan make applications based on FMs vulnerable to model stealing attacks.\nThrough empirical analysis, we reveal that models fine-tuned from FMs harbor\nheightened susceptibility to model stealing, compared to conventional vision\narchitectures like ResNets. We hypothesize that this behavior is due to the\ncomprehensive encoding of visual patterns and features learned by FMs during\npre-training, which are accessible to both the attacker and the victim. We\nreport that an attacker is able to obtain 94.28% agreement (matched predictions\nwith victim) for a Vision Transformer based victim model (ViT-L/16) trained on\nCIFAR-10 dataset, compared to only 73.20% agreement for a ResNet-18 victim,\nwhen using ViT-L/16 as the thief model. We arguably show, for the first time,\nthat utilizing FMs for downstream tasks may not be the best choice for\ndeployment in commercial APIs due to their susceptibility to model theft. We\nthereby alert model owners towards the associated security risks, and highlight\nthe need for robust security measures to safeguard such models against theft.\nCode is available at https://github.com/rajankita/foundation_model_stealing."
    },
    {
        "date": "2025-02",
        "title": "FedBM: Stealing Knowledge from Pre-trained Language Models for Heterogeneous Federated Learning",
        "author": "Meilu Zhu, Qiushi Yang, Zhifan Gao, Yixuan Yuan, and Jun Liu",
        "link": "http://arxiv.org/abs/2502.16832v1",
        "abstract": "Federated learning (FL) has shown great potential in medical image computing\nsince it provides a decentralized learning paradigm that allows multiple\nclients to train a model collaboratively without privacy leakage. However,\ncurrent studies have shown that data heterogeneity incurs local learning bias\nin classifiers and feature extractors of client models during local training,\nleading to the performance degradation of a federation system. To address these\nissues, we propose a novel framework called Federated Bias eliMinating (FedBM)\nto get rid of local learning bias in heterogeneous federated learning (FL),\nwhich mainly consists of two modules, i.e., Linguistic Knowledge-based\nClassifier Construction (LKCC) and Concept-guided Global Distribution\nEstimation (CGDE). Specifically, LKCC exploits class concepts, prompts and\npre-trained language models (PLMs) to obtain concept embeddings. These\nembeddings are used to estimate the latent concept distribution of each class\nin the linguistic space. Based on the theoretical derivation, we can rely on\nthese distributions to pre-construct a high-quality classifier for clients to\nachieve classification optimization, which is frozen to avoid classifier bias\nduring local training. CGDE samples probabilistic concept embeddings from the\nlatent concept distributions to learn a conditional generator to capture the\ninput space of the global model. Three regularization terms are introduced to\nimprove the quality and utility of the generator. The generator is shared by\nall clients and produces pseudo data to calibrate updates of local feature\nextractors. Extensive comparison experiments and ablation studies on public\ndatasets demonstrate the superior performance of FedBM over state-of-the-arts\nand confirm the effectiveness of each module, respectively. The code is\navailable at https://github.com/CUHK-AIM-Group/FedBM."
    },
    {
        "date": "2025-02",
        "title": "D2S-FLOW: Automated Parameter Extraction from Datasheets for SPICE Model Generation Using Large Language Models",
        "author": "Hong Cai Chen, Yi Pin Xu, and Yang Zhang",
        "link": "http://arxiv.org/abs/2502.16540v2",
        "abstract": "In electronic design, engineers often manually search through extensive\ndocuments to retrieve component parameters required for constructing SPICE\nmodels, a process that is both labor-intensive and time-consuming. To address\nthis challenge, we present an automated framework called D2S-FLOW that\nleverages large language models (LLMs) to extract electrical parameters from\ndatasheets and generate SPICE models with high precision and efficiency,\nsignificantly reducing the need for manual intervention. Unlike traditional RAG\nsystems, D2S-FLOW employs a workflow to enhance precision in handling\nunstructured documents and inconsistent naming conventions through three\ninnovative mechanisms: Attention-Guided Document Focusing (AGDF), Hierarchical\nDocument-Enhanced Retrieval (HDER), and Heterogeneous Named Entity\nNormalization (HNEN). AGDF narrows retrieval to user-selected documents, HDER\nutilizes document structure for precise parameter localization, and HNEN\nstandardizes terminology via semantic inference. Experimental results\ndemonstrate that the framework achieves an Exact Match (EM) of 0.86, an F1\nscore of 0.92, and an Exact Correctness (EC) of 0.96, outperforming the\nstrongest baseline by 19.4%, 5.7%, and 13.1%, respectively. Additionally, it\nreduces API token consumption by 38% and minimizes the irrelevant information\nratio to 4%, showcasing substantial improvements in resource efficiency. This\nresearch provides an effective automated solution for circuit design."
    },
    {
        "date": "2025-02",
        "title": "Merger-as-a-Stealer: Stealing Targeted PII from Aligned LLMs with Model Merging",
        "author": "Lin Lu, Zhigang Zuo, Ziji Sheng, and Pan Zhou",
        "link": "http://arxiv.org/abs/2502.16094v1",
        "abstract": "Model merging has emerged as a promising approach for updating large language\nmodels (LLMs) by integrating multiple domain-specific models into a\ncross-domain merged model. Despite its utility and plug-and-play nature,\nunmonitored mergers can introduce significant security vulnerabilities, such as\nbackdoor attacks and model merging abuse. In this paper, we identify a novel\nand more realistic attack surface where a malicious merger can extract targeted\npersonally identifiable information (PII) from an aligned model with model\nmerging. Specifically, we propose \\texttt{Merger-as-a-Stealer}, a two-stage\nframework to achieve this attack: First, the attacker fine-tunes a malicious\nmodel to force it to respond to any PII-related queries. The attacker then\nuploads this malicious model to the model merging conductor and obtains the\nmerged model. Second, the attacker inputs direct PII-related queries to the\nmerged model to extract targeted PII. Extensive experiments demonstrate that\n\\texttt{Merger-as-a-Stealer} successfully executes attacks against various LLMs\nand model merging methods across diverse settings, highlighting the\neffectiveness of the proposed framework. Given that this attack enables\ncharacter-level extraction for targeted PII without requiring any additional\nknowledge from the attacker, we stress the necessity for improved model\nalignment and more robust defense mechanisms to mitigate such threats."
    },
    {
        "date": "2025-02",
        "title": "Stealing Training Data from Large Language Models in Decentralized Training through Activation Inversion Attack",
        "author": "Chenxi Dai, Lin Lu, and Pan Zhou",
        "link": "http://arxiv.org/abs/2502.16086v1",
        "abstract": "Decentralized training has become a resource-efficient framework to\ndemocratize the training of large language models (LLMs). However, the privacy\nrisks associated with this framework, particularly due to the potential\ninclusion of sensitive data in training datasets, remain unexplored. This paper\nidentifies a novel and realistic attack surface: the privacy leakage from\ntraining data in decentralized training, and proposes \\textit{activation\ninversion attack} (AIA) for the first time. AIA first constructs a shadow\ndataset comprising text labels and corresponding activations using public\ndatasets. Leveraging this dataset, an attack model can be trained to\nreconstruct the training data from activations in victim decentralized\ntraining. We conduct extensive experiments on various LLMs and publicly\navailable datasets to demonstrate the susceptibility of decentralized training\nto AIA. These findings highlight the urgent need to enhance security measures\nin decentralized training to mitigate privacy risks in training LLMs."
    },
    {
        "date": "2025-02",
        "title": "A Survey of Model Extraction Attacks and Defenses in Distributed Computing Environments",
        "author": "Kaixiang Zhao, Lincan Li, Kaize Ding, Neil Zhenqiang Gong, Yue Zhao, and Yushun Dong",
        "link": "http://arxiv.org/abs/2502.16065v1",
        "abstract": "Model Extraction Attacks (MEAs) threaten modern machine learning systems by\nenabling adversaries to steal models, exposing intellectual property and\ntraining data. With the increasing deployment of machine learning models in\ndistributed computing environments, including cloud, edge, and federated\nlearning settings, each paradigm introduces distinct vulnerabilities and\nchallenges. Without a unified perspective on MEAs across these distributed\nenvironments, organizations risk fragmented defenses, inadequate risk\nassessments, and substantial economic and privacy losses. This survey is\nmotivated by the urgent need to understand how the unique characteristics of\ncloud, edge, and federated deployments shape attack vectors and defense\nrequirements. We systematically examine the evolution of attack methodologies\nand defense mechanisms across these environments, demonstrating how\nenvironmental factors influence security strategies in critical sectors such as\nautonomous vehicles, healthcare, and financial services. By synthesizing recent\nadvances in MEAs research and discussing the limitations of current evaluation\npractices, this survey provides essential insights for developing robust and\nadaptive defense strategies. Our comprehensive approach highlights the\nimportance of integrating protective measures across the entire distributed\ncomputing landscape to ensure the secure deployment of machine learning models."
    },
    {
        "date": "2025-02",
        "title": "Med-gte-hybrid: A contextual embedding transformer model for extracting actionable information from clinical texts",
        "author": "Aditya Kumar, Simon Rauch, Mario Cypko, and Oliver Amft",
        "link": "http://arxiv.org/abs/2502.15996v2",
        "abstract": "We introduce a novel contextual embedding model med-gte-hybrid that was\nderived from the gte-large sentence transformer to extract information from\nunstructured clinical narratives. Our model tuning strategy for med-gte-hybrid\ncombines contrastive learning and a denoising autoencoder. To evaluate the\nperformance of med-gte-hybrid, we investigate several clinical prediction tasks\nin large patient cohorts extracted from the MIMIC-IV dataset, including Chronic\nKidney Disease (CKD) patient prognosis, estimated glomerular filtration rate\n(eGFR) prediction, and patient mortality prediction. Furthermore, we\ndemonstrate that the med-gte-hybrid model improves patient stratification,\nclustering, and text retrieval, thus outperforms current state-of-the-art\nmodels on the Massive Text Embedding Benchmark (MTEB). While some of our\nevaluations focus on CKD, our hybrid tuning of sentence transformers could be\ntransferred to other medical domains and has the potential to improve clinical\ndecision-making and personalised treatment pathways in various healthcare\napplications."
    },
    {
        "date": "2025-02",
        "title": "Model Privacy: A Unified Framework to Understand Model Stealing Attacks and Defenses",
        "author": "Ganghua Wang, Yuhong Yang, and Jie Ding",
        "link": "http://arxiv.org/abs/2502.15567v1",
        "abstract": "The use of machine learning (ML) has become increasingly prevalent in various\ndomains, highlighting the importance of understanding and ensuring its safety.\nOne pressing concern is the vulnerability of ML applications to model stealing\nattacks. These attacks involve adversaries attempting to recover a learned\nmodel through limited query-response interactions, such as those found in\ncloud-based services or on-chip artificial intelligence interfaces. While\nexisting literature proposes various attack and defense strategies, these often\nlack a theoretical foundation and standardized evaluation criteria. In\nresponse, this work presents a framework called ``Model Privacy'', providing a\nfoundation for comprehensively analyzing model stealing attacks and defenses.\nWe establish a rigorous formulation for the threat model and objectives,\npropose methods to quantify the goodness of attack and defense strategies, and\nanalyze the fundamental tradeoffs between utility and privacy in ML models. Our\ndeveloped theory offers valuable insights into enhancing the security of ML\nmodels, especially highlighting the importance of the attack-specific structure\nof perturbations for effective defenses. We demonstrate the application of\nmodel privacy from the defender's perspective through various learning\nscenarios. Extensive experiments corroborate the insights and the effectiveness\nof defense mechanisms developed under the proposed framework."
    },
    {
        "date": "2025-02",
        "title": "MACPruning: Dynamic Operation Pruning to Mitigate Side-Channel DNN Model Extraction",
        "author": "Ruyi Ding, Cheng Gongye, Davis Ranney, Aidong Adam Ding, and Yunsi Fei",
        "link": "http://arxiv.org/abs/2502.15020v1",
        "abstract": "As deep learning gains popularity, edge IoT devices have seen proliferating\ndeployment of pre-trained Deep Neural Network (DNN) models. These DNNs\nrepresent valuable intellectual property and face significant confidentiality\nthreats from side-channel analysis (SCA), particularly non-invasive\nDifferential Electromagnetic (EM) Analysis (DEMA), which retrieves individual\nmodel parameters from EM traces collected during model inference. Traditional\nSCA mitigation methods, such as masking and shuffling, can still be applied to\nDNN inference, but will incur significant performance degradation due to the\nlarge volume of operations and parameters. Based on the insight that DNN models\nhave high redundancy and are robust to input variation, we introduce\nMACPruning, a novel lightweight defense against DEMA-based parameter extraction\nattacks, exploiting specific characteristics of DNN execution. The design\nprinciple of MACPruning is to randomly deactivate input pixels and prune the\noperations (typically multiply-accumulate-MAC) on those pixels. The technique\nremoves certain leakages and overall redistributes weight-dependent EM leakages\ntemporally, and thus effectively mitigates DEMA. To maintain DNN performance,\nwe propose an importance-aware pixel map that preserves critical input pixels,\nkeeping randomness in the defense while minimizing its impact on DNN\nperformance due to operation pruning. We conduct a comprehensive security\nanalysis of MACPruning on various datasets for DNNs on edge devices. Our\nevaluations demonstrate that MACPruning effectively reduces EM leakages with\nminimal impact on the model accuracy and negligible computational overhead."
    },
    {
        "date": "2025-02",
        "title": "Keep what you need : extracting efficient subnetworks from large audio representation models",
        "author": "David Genova, Philippe Esling, and Tom Hurlin",
        "link": "http://arxiv.org/abs/2502.12925v1",
        "abstract": "Recently, research on audio foundation models has witnessed notable advances,\nas illustrated by the ever improving results on complex downstream tasks.\nSubsequently, those pretrained networks have quickly been used for various\naudio applications. These improvements have however resulted in a considerable\nincrease both in size and complexity of these models. Along the environmental\nconcerns this issue raises, this prevents the deployment of such networks on\nconsumer-level devices, and precludes their use for real-time applications.\nMoreover, this appears contradictory with the specificity of the tasks for\nwhich these models are used, which are often simpler compared to extracting a\nrich, multi-purpose representation from any type of audio data. In this paper,\nwe address this issue with a simple, yet effective method to extract\nlightweight specialist subnetworks from large foundation models. Specifically,\nwe introduce learnable binary masks in-between the layers of a pretrained\nrepresentation model. When training the end-to-end model on a downstream task,\nwe add a sparsity-inducing loss to the overall objective, hence learning a\ncompact subnetwork specialized on a single task. Importantly, the weights of\nthe foundation model are kept frozen, resulting into low additional training\ncosts. Once trained, the masked computational units can then be removed from\nthe network, implying significant performance gains. We assess our method on\nthree widespread audio foundation models, each based on a different backbone\narchitecture, and illustrate its effectiveness on common audio representation\nevaluation tasks, as well as its versatility on both speech, music, and general\naudio. Code for reproducing the results and supporting webpage are available at\nhttps://github.com/gnvIRCAM/Audio-representation-trimming"
    },
    {
        "date": "2025-02",
        "title": "Archetypal SAE: Adaptive and Stable Dictionary Learning for Concept Extraction in Large Vision Models",
        "author": "Thomas Fel, Ekdeep Singh Lubana, Jacob S. Prince, Matthew Kowal, Victor Boutin, Isabel Papadimitriou, Binxu Wang, Martin Wattenberg, Demba Ba, and Talia Konkle",
        "link": "http://arxiv.org/abs/2502.12892v2",
        "abstract": "Sparse Autoencoders (SAEs) have emerged as a powerful framework for machine\nlearning interpretability, enabling the unsupervised decomposition of model\nrepresentations into a dictionary of abstract, human-interpretable concepts.\nHowever, we reveal a fundamental limitation: existing SAEs exhibit severe\ninstability, as identical models trained on similar datasets can produce\nsharply different dictionaries, undermining their reliability as an\ninterpretability tool. To address this issue, we draw inspiration from the\nArchetypal Analysis framework introduced by Cutler & Breiman (1994) and present\nArchetypal SAEs (A-SAE), wherein dictionary atoms are constrained to the convex\nhull of data. This geometric anchoring significantly enhances the stability of\ninferred dictionaries, and their mildly relaxed variants RA-SAEs further match\nstate-of-the-art reconstruction abilities. To rigorously assess dictionary\nquality learned by SAEs, we introduce two new benchmarks that test (i)\nplausibility, if dictionaries recover \"true\" classification directions and (ii)\nidentifiability, if dictionaries disentangle synthetic concept mixtures. Across\nall evaluations, RA-SAEs consistently yield more structured representations\nwhile uncovering novel, semantically meaningful concepts in large-scale vision\nmodels."
    },
    {
        "date": "2025-02",
        "title": "Label Drop for Multi-Aspect Relation Modeling in Universal Information Extraction",
        "author": "Lu Yang, Jiajia Li, En Ci, Lefei Zhang, Zuchao Li, and Ping Wang",
        "link": "http://arxiv.org/abs/2502.12614v1",
        "abstract": "Universal Information Extraction (UIE) has garnered significant attention due\nto its ability to address model explosion problems effectively. Extractive UIE\ncan achieve strong performance using a relatively small model, making it widely\nadopted. Extractive UIEs generally rely on task instructions for different\ntasks, including single-target instructions and multiple-target instructions.\nSingle-target instruction UIE enables the extraction of only one type of\nrelation at a time, limiting its ability to model correlations between\nrelations and thus restricting its capability to extract complex relations.\nWhile multiple-target instruction UIE allows for the extraction of multiple\nrelations simultaneously, the inclusion of irrelevant relations introduces\ndecision complexity and impacts extraction accuracy. Therefore, for\nmulti-relation extraction, we propose LDNet, which incorporates multi-aspect\nrelation modeling and a label drop mechanism. By assigning different relations\nto different levels for understanding and decision-making, we reduce decision\nconfusion. Additionally, the label drop mechanism effectively mitigates the\nimpact of irrelevant relations. Experiments show that LDNet outperforms or\nachieves competitive performance with state-of-the-art systems on 9 tasks, 33\ndatasets, in both single-modal and multi-modal, few-shot and zero-shot\nsettings.\\footnote{https://github.com/Lu-Yang666/LDNet}"
    },
    {
        "date": "2025-02",
        "title": "Evaluating improvements on using Large Language Models (LLMs) for property extraction in the Open Research Knowledge Graph (ORKG)",
        "author": "Sandra Schaftner",
        "link": "http://arxiv.org/abs/2502.10768v1",
        "abstract": "Current research highlights the great potential of Large Language Models\n(LLMs) for constructing Scholarly Knowledge Graphs (SKGs). One particularly\ncomplex step in this process is relation extraction, aimed at identifying\nsuitable properties to describe the content of research. This study builds\ndirectly on previous research of three Open Research Knowledge Graph (ORKG)\nteam members who assessed the readiness of LLMs such as GPT-3.5, Llama 2, and\nMistral for property extraction in scientific literature. Given the moderate\nperformance observed, the previous work concluded that fine-tuning is needed to\nimprove these models' alignment with scientific tasks and their emulation of\nhuman expertise. Expanding on this prior experiment, this study evaluates the\nimpact of advanced prompt engineering techniques and demonstrates that these\ntechniques can highly significantly enhance the results. Additionally, this\nstudy extends the property extraction process to include property matching to\nexisting ORKG properties, which are retrieved via the API. The evaluation\nreveals that results generated through advanced prompt engineering achieve a\nhigher proportion of matches with ORKG properties, further emphasizing the\nenhanced alignment achieved. Moreover, this lays the groundwork for addressing\nchallenges such as the inconsistency of ORKG properties, an issue highlighted\nin prior studies. By assigning unique URIs and using standardized terminology,\nthis work increases the consistency of the properties, fulfilling a crucial\naspect of Linked Data and FAIR principles - core commitments of ORKG. This, in\nturn, significantly enhances the applicability of ORKG content for subsequent\ntasks such as comparisons of research publications. Finally, the study\nconcludes with recommendations for future improvements in the overall property\nextraction process."
    },
    {
        "date": "2025-02",
        "title": "Leveraging large language models for structured information extraction from pathology reports",
        "author": "Jeya Balaji Balasubramanian, Daniel Adams, Ioannis Roxanis, Amy Berrington de Gonzalez, Penny Coulson, Jonas S. Almeida, and Montserrat Garc\u00eda-Closas",
        "link": "http://arxiv.org/abs/2502.12183v1",
        "abstract": "Background: Structured information extraction from unstructured\nhistopathology reports facilitates data accessibility for clinical research.\nManual extraction by experts is time-consuming and expensive, limiting\nscalability. Large language models (LLMs) offer efficient automated extraction\nthrough zero-shot prompting, requiring only natural language instructions\nwithout labeled data or training. We evaluate LLMs' accuracy in extracting\nstructured information from breast cancer histopathology reports, compared to\nmanual extraction by a trained human annotator.\n  Methods: We developed the Medical Report Information Extractor, a web\napplication leveraging LLMs for automated extraction. We developed a gold\nstandard extraction dataset to evaluate the human annotator alongside five LLMs\nincluding GPT-4o, a leading proprietary model, and the Llama 3 model family,\nwhich allows self-hosting for data privacy. Our assessment involved 111\nhistopathology reports from the Breast Cancer Now (BCN) Generations Study,\nextracting 51 pathology features specified in the study's data dictionary.\n  Results: Evaluation against the gold standard dataset showed that both Llama\n3.1 405B (94.7% accuracy) and GPT-4o (96.1%) achieved extraction accuracy\ncomparable to the human annotator (95.4%; p = 0.146 and p = 0.106,\nrespectively). While Llama 3.1 70B (91.6%) performed below human accuracy (p\n<0.001), its reduced computational requirements make it a viable option for\nself-hosting.\n  Conclusion: We developed an open-source tool for structured information\nextraction that can be customized by non-programmers using natural language.\nIts modular design enables reuse for various extraction tasks, producing\nstandardized, structured data from unstructured text reports to facilitate\nanalytics through improved accessibility and interoperability."
    },
    {
        "date": "2025-02",
        "title": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models",
        "author": "Belinda Mo, Kyssen Yu, Joshua Kazdan, Proud Mpala, Lisa Yu, Chris Cundy, Charilaos Kanatsoulis, and Sanmi Koyejo",
        "link": "http://arxiv.org/abs/2502.09956v1",
        "abstract": "Recent interest in building foundation models for KGs has highlighted a\nfundamental challenge: knowledge-graph data is relatively scarce. The\nbest-known KGs are primarily human-labeled, created by pattern-matching, or\nextracted using early NLP techniques. While human-generated KGs are in short\nsupply, automatically extracted KGs are of questionable quality. We present a\nsolution to this data scarcity problem in the form of a text-to-KG generator\n(KGGen), a package that uses language models to create high-quality graphs from\nplaintext. Unlike other KG extractors, KGGen clusters related entities to\nreduce sparsity in extracted KGs. KGGen is available as a Python library\n(\\texttt{pip install kg-gen}), making it accessible to everyone. Along with\nKGGen, we release the first benchmark, Measure of of Information in Nodes and\nEdges (MINE), that tests an extractor's ability to produce a useful KG from\nplain text. We benchmark our new tool against existing extractors and\ndemonstrate far superior performance."
    },
    {
        "date": "2025-02",
        "title": "The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics",
        "author": "Danni Feng, Runzhi Li, Jing Wang, Siyu Yan, Lihong Ma, and Yunli Xing",
        "link": "http://arxiv.org/abs/2502.09247v1",
        "abstract": "Joint entity-relation extraction is a critical task in transforming\nunstructured or semi-structured text into triplets, facilitating the\nconstruction of large-scale knowledge graphs, and supporting various downstream\napplications. Despite its importance, research on Chinese text, particularly\nwith complex semantics in specialized domains like medicine, remains limited.\nTo address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions\ndataset designed to capture the intricacies of medical text. Leveraging the\nstrengths of attention mechanisms in capturing long-range dependencies, we\npropose the SEA module, which enhances the extraction of complex contextual\nsemantic information, thereby improving entity recognition and relation\nextraction. Additionally, to address the inefficiencies of existing methods in\nfacilitating information exchange between entity recognition and relation\nextraction, we present an interactive fusion representation module. This module\nemploys Cross Attention for bidirectional information exchange between the\ntasks and further refines feature extraction through BiLSTM. Experimental\nresults on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that\nour model exhibits strong generalization capabilities. On the CH-DDI dataset,\nour model achieves an F1-score of 96.73% for entity recognition and 78.43% for\nrelation extraction. On the CoNLL04 dataset, it attains an entity recognition\nprecision of 89.54% and a relation extraction accuracy of 71.64%."
    },
    {
        "date": "2025-02",
        "title": "ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports",
        "author": "Aynur Guluzade, Naguib Heiba, Zeyd Boukhers, Florim Hamiti, Jahid Hasan Polash, Yehya Mohamad, and Carlos A Velasco",
        "link": "http://arxiv.org/abs/2502.05638v1",
        "abstract": "Europe's healthcare systems require enhanced interoperability and\ndigitalization, driving a demand for innovative solutions to process legacy\nclinical data. This paper presents the results of our project, which aims to\nleverage Large Language Models (LLMs) to extract structured information from\nunstructured clinical reports, focusing on patient history, diagnoses,\ntreatments, and other predefined categories. We developed a workflow with a\nuser interface and evaluated LLMs of varying sizes through prompting strategies\nand fine-tuning. Our results show that fine-tuned smaller models match or\nsurpass larger counterparts in performance, offering efficiency for\nresource-limited settings. A new dataset of 60,000 annotated English clinical\nsummaries and 24,000 German translations was validated with automated and\nmanual checks. The evaluations used ROUGE, BERTScore, and entity-level metrics.\nThe work highlights the approach's viability and outlines future improvements."
    },
    {
        "date": "2025-02",
        "title": "From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks",
        "author": "Awa Khouna, Julien Ferry, and Thibaut Vidal",
        "link": "http://arxiv.org/abs/2502.05325v2",
        "abstract": "The advent of Machine Learning as a Service (MLaaS) has heightened the\ntrade-off between model explainability and security. In particular,\nexplainability techniques, such as counterfactual explanations, inadvertently\nincrease the risk of model extraction attacks, enabling unauthorized\nreplication of proprietary models. In this paper, we formalize and characterize\nthe risks and inherent complexity of model reconstruction, focusing on the\n\"oracle'' queries required for faithfully inferring the underlying prediction\nfunction. We present the first formal analysis of model extraction attacks\nthrough the lens of competitive analysis, establishing a foundational framework\nto evaluate their efficiency. Focusing on models based on additive decision\ntrees (e.g., decision trees, gradient boosting, and random forests), we\nintroduce novel reconstruction algorithms that achieve provably perfect\nfidelity while demonstrating strong anytime performance. Our framework provides\ntheoretical bounds on the query complexity for extracting tree-based model,\noffering new insights into the security vulnerabilities of their deployment."
    },
    {
        "date": "2025-02",
        "title": "QExplorer: Large Language Model Based Query Extraction for Toxic Content Exploration",
        "author": "Shaola Ren, Li Ke, Longtao Huang, Dehong Gao, and Hui Xue",
        "link": "http://arxiv.org/abs/2502.18480v1",
        "abstract": "Automatically extracting effective queries is challenging in information\nretrieval, especially in toxic content exploration, as such content is likely\nto be disguised. With the recent achievements in generative Large Language\nModel (LLM), we are able to leverage the capabilities of LLMs to extract\neffective queries for similar content exploration directly. This study proposes\nQExplorer, an approach of large language model based Query Extraction for toxic\ncontent Exploration. The QExplorer approach involves a 2-stage training\nprocess: instruction Supervised FineTuning (SFT) and preference alignment using\nDirect Preference Optimization (DPO), as well as the datasets construction with\nfeedback of search system. To verify the effectiveness of QExplorer, a series\nof offline and online experiments are conducted on our real-world system. The\noffline empirical results demonstrate that the performance of our automatic\nquery extraction outperforms that of several LLMs and humans. The online\ndeployment shows a significant increase in the detection of toxic items."
    },
    {
        "date": "2025-02",
        "title": "MARAGE: Transferable Multi-Model Adversarial Attack for Retrieval-Augmented Generation Data Extraction",
        "author": "Xiao Hu, Eric Liu, Weizhou Wang, Xiangyu Guo, and David Lie",
        "link": "http://arxiv.org/abs/2502.04360v1",
        "abstract": "Retrieval-Augmented Generation (RAG) offers a solution to mitigate\nhallucinations in Large Language Models (LLMs) by grounding their outputs to\nknowledge retrieved from external sources. The use of private resources and\ndata in constructing these external data stores can expose them to risks of\nextraction attacks, in which attackers attempt to steal data from these private\ndatabases. Existing RAG extraction attacks often rely on manually crafted\nprompts, which limit their effectiveness. In this paper, we introduce a\nframework called MARAGE for optimizing an adversarial string that, when\nappended to user queries submitted to a target RAG system, causes outputs\ncontaining the retrieved RAG data verbatim. MARAGE leverages a continuous\noptimization scheme that integrates gradients from multiple models with\ndifferent architectures simultaneously to enhance the transferability of the\noptimized string to unseen models. Additionally, we propose a strategy that\nemphasizes the initial tokens in the target RAG data, further improving the\nattack's generalizability. Evaluations show that MARAGE consistently\noutperforms both manual and optimization-based baselines across multiple LLMs\nand RAG datasets, while maintaining robust transferability to previously unseen\nmodels. Moreover, we conduct probing tasks to shed light on the reasons why\nMARAGE is more effective compared to the baselines and to analyze the impact of\nour approach on the model's internal state."
    },
    {
        "date": "2025-02",
        "title": "Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment",
        "author": "Yaling Shen, Zhixiong Zhuang, Kun Yuan, Maria-Irina Nicolae, Nassir Navab, Nicolas Padoy, and Mario Fritz",
        "link": "http://arxiv.org/abs/2502.02438v1",
        "abstract": "Medical multimodal large language models (MLLMs) are becoming an instrumental\npart of healthcare systems, assisting medical personnel with decision making\nand results analysis. Models for radiology report generation are able to\ninterpret medical imagery, thus reducing the workload of radiologists. As\nmedical data is scarce and protected by privacy regulations, medical MLLMs\nrepresent valuable intellectual property. However, these assets are potentially\nvulnerable to model stealing, where attackers aim to replicate their\nfunctionality via black-box access. So far, model stealing for the medical\ndomain has focused on classification; however, existing attacks are not\neffective against MLLMs. In this paper, we introduce Adversarial Domain\nAlignment (ADA-STEAL), the first stealing attack against medical MLLMs.\nADA-STEAL relies on natural images, which are public and widely available, as\nopposed to their medical counterparts. We show that data augmentation with\nadversarial noise is sufficient to overcome the data distribution gap between\nnatural images and the domain-specific distribution of the victim MLLM.\nExperiments on the IU X-RAY and MIMIC-CXR radiology datasets demonstrate that\nAdversarial Domain Alignment enables attackers to steal the medical MLLM\nwithout any access to medical data."
    },
    {
        "date": "2025-01",
        "title": "How Much Do Code Language Models Remember? An Investigation on Data Extraction Attacks before and after Fine-tuning",
        "author": "Fabio Salerno, Ali Al-Kaswan, and Maliheh Izadi",
        "link": "http://arxiv.org/abs/2501.17501v2",
        "abstract": "Code language models, while widely popular, are often trained on unsanitized\nsource code gathered from across the Internet. Previous work revealed that\npre-trained models can remember the content of their training data and\nregurgitate them through data extraction attacks. Due to the large size of\ncurrent models, only a few entities have the resources for pre-training such\nmodels. However, fine-tuning requires fewer resources and is increasingly used\nby both small and large entities for its effectiveness on specialized data.\nSuch small curated data for fine-tuning might contain sensitive information or\nproprietary assets. In this study, we attack both pre-trained and fine-tuned\ncode language models to investigate the extent of data extractability. We first\ndevelop a custom benchmark to assess the vulnerability of both pre-training and\nfine-tuning samples to extraction attacks. Our findings reveal that 54.9% of\nextractable pre-training data could be retrieved from StarCoder2-15B, whereas\nthis number decreased to 23.5% after fine-tuning. This indicates that\nfine-tuning reduces the extractability of pre-training data. However, compared\nto larger models, fine-tuning smaller models increases their vulnerability to\ndata extraction attacks on fine-tuning data. Given the potential sensitivity of\nfine-tuning data, this can lead to more severe consequences. Lastly, we also\nmanually analyzed 2000 extractable samples before and after fine-tuning. We\nalso found that data carriers and licensing information are the most likely\ndata categories to be memorized from pre-trained and fine-tuned models, while\nthe latter is the most likely to be forgotten after fine-tuning."
    },
    {
        "date": "2025-01",
        "title": "A Floating Normalization Scheme for Deep Learning-Based Custom-Range Parameter Extraction in BSIM-CMG Compact Models",
        "author": "Aasim Ashai, Aakash Jadhav, and Biplab Sarkar",
        "link": "http://arxiv.org/abs/2501.15190v1",
        "abstract": "A deep-learning (DL) based methodology for automated extraction of BSIM-CMG\ncompact model parameters from experimental gate capacitance vs gate voltage\n(Cgg-Vg) and drain current vs gate voltage (Id-Vg) measurements is proposed in\nthis paper. The proposed method introduces a floating normalization scheme\nwithin a cascaded forward and inverse ANN architecture enabling user-defined\nparameter extraction ranges. Unlike conventional DL-based extraction\ntechniques, which are often constrained by fixed normalization ranges, the\nfloating normalization approach adapts dynamically to user-specified ranges,\nallowing for fine-tuned control over the extracted parameters. Experimental\nvalidation, using a TCAD calibrated 14 nm FinFET process, demonstrates high\naccuracy for both Cgg-Vg and Id-Vg parameter extraction. The proposed framework\noffers enhanced flexibility, making it applicable to various compact models\nbeyond BSIM-CMG."
    },
    {
        "date": "2025-01",
        "title": "State Space Models for Extractive Summarization in Low Resource Scenarios",
        "author": "Nisrine Ait Khayi",
        "link": "http://arxiv.org/abs/2501.14673v1",
        "abstract": "Extractive summarization involves selecting the most relevant sentences from\na text. Recently, researchers have focused on advancing methods to improve\nstate-of-the-art results in low-resource settings. Motivated by these\nadvancements, we propose the MPoincareSum method. This method applies the Mamba\nstate space model to generate the semantics of reviews and sentences, which are\nthen concatenated. A Poincare compression is used to select the most meaningful\nfeatures, followed by the application of a linear layer to predict sentence\nrelevance based on the corresponding review. Finally, we paraphrase the\nrelevant sentences to create the final summary. To evaluate the effectiveness\nof MPoincareSum, we conducted extensive experiments using the Amazon review\ndataset. The performance of the method was assessed using ROUGE scores. The\nexperimental results demonstrate that MPoincareSum outperforms several existing\napproaches in the literature"
    },
    {
        "date": "2025-01",
        "title": "GRID: Protecting Training Graph from Link Stealing Attacks on GNN Models",
        "author": "Jiadong Lou, Xu Yuan, Rui Zhang, Xingliang Yuan, Neil Gong, and Nian-Feng Tzeng",
        "link": "http://arxiv.org/abs/2501.10985v2",
        "abstract": "Graph neural networks (GNNs) have exhibited superior performance in various\nclassification tasks on graph-structured data. However, they encounter the\npotential vulnerability from the link stealing attacks, which can infer the\npresence of a link between two nodes via measuring the similarity of its\nincident nodes' prediction vectors produced by a GNN model. Such attacks pose\nsevere security and privacy threats to the training graph used in GNN models.\nIn this work, we propose a novel solution, called Graph Link Disguise (GRID),\nto defend against link stealing attacks with the formal guarantee of GNN model\nutility for retaining prediction accuracy. The key idea of GRID is to add\ncarefully crafted noises to the nodes' prediction vectors for disguising\nadjacent nodes as n-hop indirect neighboring nodes. We take into account the\ngraph topology and select only a subset of nodes (called core nodes) covering\nall links for adding noises, which can avert the noises offset and have the\nfurther advantages of reducing both the distortion loss and the computation\ncost. Our crafted noises can ensure 1) the noisy prediction vectors of any two\nadjacent nodes have their similarity level like that of two non-adjacent nodes\nand 2) the model prediction is unchanged to ensure zero utility loss. Extensive\nexperiments on five datasets are conducted to show the effectiveness of our\nproposed GRID solution against different representative link-stealing attacks\nunder transductive settings and inductive settings respectively, as well as two\ninfluence-based attacks. Meanwhile, it achieves a much better privacy-utility\ntrade-off than existing methods when extended to GNNs."
    },
    {
        "date": "2025-01",
        "title": "Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide",
        "author": "Elena Albu, Shan Gao, Pieter Stijnen, Frank E. Rademakers, Bas C T van Bussel, Taya Collyer, Tina Hernandez-Boussard, Laure Wynants, and Ben Van Calster",
        "link": "http://arxiv.org/abs/2501.10240v2",
        "abstract": "Dynamic predictive modelling using electronic health record (EHR) data has\ngained significant attention in recent years. The reliability and\ntrustworthiness of such models depend heavily on the quality of the underlying\ndata, which is, in part, determined by the stages preceding the model\ndevelopment: data extraction from EHR systems and data preparation. In this\narticle, we identified over forty challenges encountered during these stages\nand provide actionable recommendations for addressing them. These challenges\nare organized into four categories: cohort definition, outcome definition,\nfeature engineering, and data cleaning. This comprehensive list serves as a\npractical guide for data extraction engineers and researchers, promoting best\npractices and improving the quality and real-world applicability of dynamic\nprediction models in clinical settings."
    },
    {
        "date": "2025-01",
        "title": "Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against Model Extraction Attacks",
        "author": "Yixiao Xu, Binxing Fang, Rui Wang, Yinghai Zhou, Yuan Liu, Mohan Li, and Zhihong Tian",
        "link": "http://arxiv.org/abs/2501.09328v3",
        "abstract": "Developing high-performance deep learning models is resource-intensive,\nleading model owners to utilize Machine Learning as a Service (MLaaS) platforms\ninstead of publicly releasing their models. However, malicious users may\nexploit query interfaces to execute model extraction attacks, reconstructing\nthe target model's functionality locally. While prior research has investigated\ntriggerable watermarking techniques for asserting ownership, existing methods\nface significant challenges: (1) most approaches require additional training,\nresulting in high overhead and limited flexibility, and (2) they often fail to\naccount for advanced attackers, leaving them vulnerable to adaptive attacks.\n  In this paper, we propose Neural Honeytrace, a robust plug-and-play\nwatermarking framework against model extraction attacks. We first formulate a\nwatermark transmission model from an information-theoretic perspective,\nproviding an interpretable account of the principles and limitations of\nexisting triggerable watermarking. Guided by the model, we further introduce:\n(1) a similarity-based training-free watermarking method for plug-and-play and\nflexible watermarking, and (2) a distribution-based multi-step watermark\ninformation transmission strategy for robust watermarking. Comprehensive\nexperiments on four datasets demonstrate that Neural Honeytrace outperforms\nprevious methods in efficiency and resisting adaptive attacks. Neural\nHoneytrace reduces the average number of samples required for a worst-case\nt-Test-based copyright claim from 193,252 to 1,857 with zero training cost. The\ncode is available at https://github.com/NeurHT/NeurHT."
    },
    {
        "date": "2025-01",
        "title": "GLiREL -- Generalist Model for Zero-Shot Relation Extraction",
        "author": "Jack Boylan, Chris Hokamp, and Demian Gholipour Ghalandari",
        "link": "http://arxiv.org/abs/2501.03172v1",
        "abstract": "We introduce GLiREL (Generalist Lightweight model for zero-shot Relation\nExtraction), an efficient architecture and training paradigm for zero-shot\nrelation classification. Inspired by recent advancements in zero-shot named\nentity recognition, this work presents an approach to efficiently and\naccurately predict zero-shot relationship labels between multiple entities in a\nsingle forward pass. Experiments using the FewRel and WikiZSL benchmarks\ndemonstrate that our approach achieves state-of-the-art results on the\nzero-shot relation classification task. In addition, we contribute a protocol\nfor synthetically-generating datasets with diverse relation labels."
    },
    {
        "date": "2025-01",
        "title": "HoneypotNet: Backdoor Attacks Against Model Extraction",
        "author": "Yixu Wang, Tianle Gu, Yan Teng, Yingchun Wang, and Xingjun Ma",
        "link": "http://arxiv.org/abs/2501.01090v1",
        "abstract": "Model extraction attacks are one type of inference-time attacks that\napproximate the functionality and performance of a black-box victim model by\nlaunching a certain number of queries to the model and then leveraging the\nmodel's predictions to train a substitute model. These attacks pose severe\nsecurity threats to production models and MLaaS platforms and could cause\nsignificant monetary losses to the model owners. A body of work has proposed to\ndefend machine learning models against model extraction attacks, including both\nactive defense methods that modify the model's outputs or increase the query\noverhead to avoid extraction and passive defense methods that detect malicious\nqueries or leverage watermarks to perform post-verification. In this work, we\nintroduce a new defense paradigm called attack as defense which modifies the\nmodel's output to be poisonous such that any malicious users that attempt to\nuse the output to train a substitute model will be poisoned. To this end, we\npropose a novel lightweight backdoor attack method dubbed HoneypotNet that\nreplaces the classification layer of the victim model with a honeypot layer and\nthen fine-tunes the honeypot layer with a shadow model (to simulate model\nextraction) via bi-level optimization to modify its output to be poisonous\nwhile remaining the original performance. We empirically demonstrate on four\ncommonly used benchmark datasets that HoneypotNet can inject backdoors into\nsubstitute models with a high success rate. The injected backdoor not only\nfacilitates ownership verification but also disrupts the functionality of\nsubstitute models, serving as a significant deterrent to model extraction\nattacks."
    },
    {
        "date": "2024-12",
        "title": "Extracting effective solutions hidden in large language models via generated comprehensive specialists: case studies in developing electronic devices",
        "author": "Hikari Tomita, Nobuhiro Nakamura, Shoichi Ishida, Toshio Kamiya, and Kei Terayama",
        "link": "http://arxiv.org/abs/2501.00224v1",
        "abstract": "Recently, many studies have increasingly explored the use of large language\nmodels (LLMs) to generate research ideas and scientific hypotheses. However,\nreal-world research and development often require solving complex,\ninterdisciplinary challenges where solutions may not be readily found through\nexisting knowledge related to the problem. Therefore, it is desirable to\nleverage the vast, comprehensive knowledge of LLMs to generate effective,\nbreakthrough solutions by integrating various perspectives from other\ndisciplines. Here, we propose SELLM (Solution Enumeration via comprehensive\nList and LLM), a framework leveraging LLMs and structured guidance using MECE\n(Mutually Exclusive, Collectively Exhaustive) principles, such as International\nPatent Classification (IPC) and the periodic table of elements. SELLM\nsystematically constructs comprehensive expert agents from the list to generate\ncross-disciplinary and effective solutions. To evaluate SELLM's practicality,\nwe applied it to two challenges: improving light extraction in organic\nlight-emitting diode (OLED) lighting and developing electrodes for\nnext-generation memory materials. The results demonstrate that SELLM\nsignificantly facilitates the generation of effective solutions compared to\ncases without specific customization or effort, showcasing the potential of\nSELLM to enable LLMs to generate effective solutions even for challenging\nproblems."
    },
    {
        "date": "2024-12",
        "title": "Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models",
        "author": "Zihan Zhou, Ziyi Zeng, Wenhao Jiang, Yihui Zhu, Jiaxin Mao, Yonggui Yuan, Min Xia, Shubin Zhao, Mengyu Yao, and Yunqian Chen",
        "link": "http://arxiv.org/abs/2412.18419v1",
        "abstract": "As social changes accelerate, the incidence of psychosomatic disorders has\nsignificantly increased, becoming a major challenge in global health issues.\nThis necessitates an innovative knowledge system and analytical methods to aid\nin diagnosis and treatment. Here, we establish the ontology model and entity\ntypes, using the BERT model and LoRA-tuned LLM for named entity recognition,\nconstructing the knowledge graph with 9668 triples. Next, by analyzing the\nnetwork distances between disease, symptom, and drug modules, it was found that\ncloser network distances among diseases can predict greater similarities in\ntheir clinical manifestations, treatment approaches, and psychological\nmechanisms, and closer distances between symptoms indicate that they are more\nlikely to co-occur. Lastly, by comparing the proximity d and proximity z score,\nit was shown that symptom-disease pairs in primary diagnostic relationships\nhave a stronger association and are of higher referential value than those in\ndiagnostic relationships. The research results revealed the potential\nconnections between diseases, co-occurring symptoms, and similarities in\ntreatment strategies, providing new perspectives for the diagnosis and\ntreatment of psychosomatic disorders and valuable information for future mental\nhealth research and practice."
    },
    {
        "date": "2024-12",
        "title": "GeneSUM: Large Language Model-based Gene Summary Extraction",
        "author": "Zhijian Chen, Chuan Hu, Min Wu, Qingqing Long, Xuezhi Wang, Yuanchun Zhou, and Meng Xiao",
        "link": "http://arxiv.org/abs/2412.18154v1",
        "abstract": "Emerging topics in biomedical research are continuously expanding, providing\na wealth of information about genes and their function. This rapid\nproliferation of knowledge presents unprecedented opportunities for scientific\ndiscovery and formidable challenges for researchers striving to keep abreast of\nthe latest advancements. One significant challenge is navigating the vast\ncorpus of literature to extract vital gene-related information, a\ntime-consuming and cumbersome task. To enhance the efficiency of this process,\nit is crucial to address several key challenges: (1) the overwhelming volume of\nliterature, (2) the complexity of gene functions, and (3) the automated\nintegration and generation. In response, we propose GeneSUM, a two-stage\nautomated gene summary extractor utilizing a large language model (LLM). Our\napproach retrieves and eliminates redundancy of target gene literature and then\nfine-tunes the LLM to refine and streamline the summarization process. We\nconducted extensive experiments to validate the efficacy of our proposed\nframework. The results demonstrate that LLM significantly enhances the\nintegration of gene-specific information, allowing more efficient\ndecision-making in ongoing research."
    },
    {
        "date": "2024-12",
        "title": "Automated CVE Analysis: Harnessing Machine Learning In Designing Question-Answering Models For Cybersecurity Information Extraction",
        "author": "Tanjim Bin Faruk",
        "link": "http://arxiv.org/abs/2412.16484v1",
        "abstract": "The vast majority of cybersecurity information is unstructured text,\nincluding critical data within databases such as CVE, NVD, CWE, CAPEC, and the\nMITRE ATT&CK Framework. These databases are invaluable for analyzing attack\npatterns and understanding attacker behaviors. Creating a knowledge graph by\nintegrating this information could unlock significant insights. However,\nprocessing this large amount of data requires advanced deep-learning\ntechniques. A crucial step towards building such a knowledge graph is\ndeveloping a robust mechanism for automating the extraction of answers to\nspecific questions from the unstructured text. Question Answering (QA) systems\nplay a pivotal role in this process by pinpointing and extracting precise\ninformation, facilitating the mapping of relationships between various data\npoints. In the cybersecurity context, QA systems encounter unique challenges\ndue to the need to interpret and answer questions based on a wide array of\ndomain-specific information. To tackle these challenges, it is necessary to\ndevelop a cybersecurity-specific dataset and train a machine learning model on\nit, aimed at enhancing the understanding and retrieval of domain-specific\ninformation. This paper presents a novel dataset and describes a machine\nlearning model trained on this dataset for the QA task. It also discusses the\nmodel's performance and key findings in a manner that maintains a balance\nbetween formality and accessibility."
    },
    {
        "date": "2024-12",
        "title": "Extracting Interpretable Task-Specific Circuits from Large Language Models for Faster Inference",
        "author": "Jorge Garc\u00eda-Carrasco, Alejandro Mat\u00e9, and Juan Trujillo",
        "link": "http://arxiv.org/abs/2412.15750v1",
        "abstract": "Large Language Models (LLMs) have shown impressive performance across a wide\nrange of tasks. However, the size of LLMs is steadily increasing, hindering\ntheir application on computationally constrained environments. On the other\nhand, despite their general capabilities, there are many situations where only\none specific task is performed, rendering all other capabilities unnecessary\nand wasteful. This leads us to the following question: Is it possible to\nextract the minimal subset from an LLM that is able to perform a specific task\nin a faster, standalone manner? Recent works on Mechanistic Interpretability\n(MI) have shown that specific tasks are performed by a localized subset of\ncomponents, or circuit. However, current techniques used to identify the\ncircuit cannot be used to extract it for its standalone usage. In this work, we\npropose a novel approach to automatically extract the subset of the LLM that\nproperly performs a targeted task requiring no additional training and a small\namount of data samples. We evaluate our approach on different tasks and show\nthat the resulting models are (i) considerably smaller, reducing the number of\nparameters up to 82.77% and (ii) more interpretable, as they focus on the\ncircuit that is used to carry out the specific task, and can therefore be\nunderstood using MI techniques."
    },
    {
        "date": "2024-12",
        "title": "Towards scientific discovery with dictionary learning: Extracting biological concepts from microscopy foundation models",
        "author": "Konstantin Donhauser, Kristina Ulicna, Gemma Elyse Moran, Aditya Ravuri, Kian Kenyon-Dean, Cian Eastwood, and Jason Hartford",
        "link": "http://arxiv.org/abs/2412.16247v3",
        "abstract": "Sparse dictionary learning (DL) has emerged as a powerful approach to extract\nsemantically meaningful concepts from the internals of large language models\n(LLMs) trained mainly in the text domain. In this work, we explore whether DL\ncan extract meaningful concepts from less human-interpretable scientific data,\nsuch as vision foundation models trained on cell microscopy images, where\nlimited prior knowledge exists about which high-level concepts should arise. We\npropose a novel combination of a sparse DL algorithm, Iterative Codebook\nFeature Learning (ICFL), with a PCA whitening pre-processing step derived from\ncontrol data. Using this combined approach, we successfully retrieve\nbiologically meaningful concepts, such as cell types and genetic perturbations.\nMoreover, we demonstrate how our method reveals subtle morphological changes\narising from human-interpretable interventions, offering a promising new\ndirection for scientific discovery via mechanistic interpretability in\nbioimaging."
    },
    {
        "date": "2024-12",
        "title": "Exploring Query Efficient Data Generation towards Data-free Model Stealing in Hard Label Setting",
        "author": "Gaozheng Pei, Shaojie lyu, Ke Ma, Pinci Yang, Qianqian Xu, and Yingfei Sun",
        "link": "http://arxiv.org/abs/2412.15276v1",
        "abstract": "Data-free model stealing involves replicating the functionality of a target\nmodel into a substitute model without accessing the target model's structure,\nparameters, or training data. The adversary can only access the target model's\npredictions for generated samples. Once the substitute model closely\napproximates the behavior of the target model, attackers can exploit its\nwhite-box characteristics for subsequent malicious activities, such as\nadversarial attacks. Existing methods within cooperative game frameworks often\nproduce samples with high confidence for the prediction of the substitute\nmodel, which makes it difficult for the substitute model to replicate the\nbehavior of the target model. This paper presents a new data-free model\nstealing approach called Query Efficient Data Generation (\\textbf{QEDG}). We\nintroduce two distinct loss functions to ensure the generation of sufficient\nsamples that closely and uniformly align with the target model's decision\nboundary across multiple classes. Building on the limitation of current\nmethods, which typically yield only one piece of supervised information per\nquery, we propose the query-free sample augmentation that enables the\nacquisition of additional supervised information without increasing the number\nof queries. Motivated by theoretical analysis, we adopt the consistency rate\nmetric, which more accurately evaluates the similarity between the substitute\nand target models. We conducted extensive experiments to verify the\neffectiveness of our proposed method, which achieved better performance with\nfewer queries compared to the state-of-the-art methods on the real\n\\textbf{MLaaS} scenario and five datasets."
    },
    {
        "date": "2024-12",
        "title": "Leveraging Foundation Language Models (FLMs) for Automated Cohort Extraction from Large EHR Databases",
        "author": "Purity Mugambi, Alexandra Meliou, and Madalina Fiterau",
        "link": "http://arxiv.org/abs/2412.11472v1",
        "abstract": "A crucial step in cohort studies is to extract the required cohort from one\nor more study datasets. This step is time-consuming, especially when a\nresearcher is presented with a dataset that they have not previously worked\nwith. When the cohort has to be extracted from multiple datasets, cohort\nextraction can be extremely laborious. In this study, we present an approach\nfor partially automating cohort extraction from multiple electronic health\nrecord (EHR) databases. We formulate the guided multi-dataset cohort extraction\nproblem in which selection criteria are first converted into queries,\ntranslating them from natural language text to language that maps to database\nentities. Then, using FLMs, columns of interest identified from the queries are\nautomatically matched between the study databases. Finally, the generated\nqueries are run across all databases to extract the study cohort. We propose\nand evaluate an algorithm for automating column matching on two large, popular\nand publicly-accessible EHR databases -- MIMIC-III and eICU. Our approach\nachieves a high top-three accuracy of $92\\%$, correctly matching $12$ out of\nthe $13$ columns of interest, when using a small, pre-trained general purpose\nlanguage model. Furthermore, this accuracy is maintained even as the search\nspace (i.e., size of the database) increases."
    },
    {
        "date": "2024-12",
        "title": "Extracting PAC Decision Trees from Black Box Binary Classifiers: The Gender Bias Study Case on BERT-based Language Models",
        "author": "Ana Ozaki, Roberto Confalonieri, Ricardo Guimar\u00e3es, and Anders Imenes",
        "link": "http://arxiv.org/abs/2412.10513v1",
        "abstract": "Decision trees are a popular machine learning method, known for their\ninherent explainability. In Explainable AI, decision trees can be used as\nsurrogate models for complex black box AI models or as approximations of parts\nof such models. A key challenge of this approach is determining how accurately\nthe extracted decision tree represents the original model and to what extent it\ncan be trusted as an approximation of their behavior. In this work, we\ninvestigate the use of the Probably Approximately Correct (PAC) framework to\nprovide a theoretical guarantee of fidelity for decision trees extracted from\nAI models. Based on theoretical results from the PAC framework, we adapt a\ndecision tree algorithm to ensure a PAC guarantee under certain conditions. We\nfocus on binary classification and conduct experiments where we extract\ndecision trees from BERT-based language models with PAC guarantees. Our results\nindicate occupational gender bias in these models."
    },
    {
        "date": "2024-12",
        "title": "Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Pathology Analysis",
        "author": "Shengxuming Zhang, Weihan Li, Tianhong Gao, Jiacong Hu, Haoming Luo, Xiuming Zhang, Jing Zhang, Mingli Song, and Zunlei Feng",
        "link": "http://arxiv.org/abs/2412.09521v3",
        "abstract": "Pathological diagnosis is vital for determining disease characteristics,\nguiding treatment, and assessing prognosis, relying heavily on detailed,\nmulti-scale analysis of high-resolution whole slide images (WSI). However,\nexisting large vision-language models (LVLMs) are limited by input resolution\nconstraints, hindering their efficiency and accuracy in pathology image\nanalysis. To overcome these issues, we propose two innovative strategies: the\nmixed task-guided feature enhancement, which directs feature extraction toward\nlesion-related details across scales, and the prompt-guided detail feature\ncompletion, which integrates coarse- and fine-grained features from WSI based\non specific prompts without compromising inference speed. Leveraging a\ncomprehensive dataset of 490K samples from diverse pathology tasks, we trained\nthe pathology-specialized LVLM, OmniPath. Extensive experiments demonstrate\nthat this model significantly outperforms existing methods in diagnostic\naccuracy and efficiency, providing an interactive, clinically aligned approach\nfor auxiliary diagnosis in a wide range of pathology applications."
    },
    {
        "date": "2024-12",
        "title": "Kajal: Extracting Grammar of a Source Code Using Large Language Models",
        "author": "Mohammad Jalili Torkamani",
        "link": "http://arxiv.org/abs/2412.08842v1",
        "abstract": "Understanding and extracting the grammar of a domain-specific language (DSL)\nis crucial for various software engineering tasks; however, manually creating\nthese grammars is time-intensive and error-prone. This paper presents Kajal, a\nnovel approach that automatically infers grammar from DSL code snippets by\nleveraging Large Language Models (LLMs) through prompt engineering and few-shot\nlearning. Kajal dynamically constructs input prompts, using contextual\ninformation to guide the LLM in generating the corresponding grammars, which\nare iteratively refined through a feedback-driven approach. Our experiments\nshow that Kajal achieves 60% accuracy with few-shot learning and 45% without\nit, demonstrating the significant impact of few-shot learning on the tool's\neffectiveness. This approach offers a promising solution for automating DSL\ngrammar extraction, and future work will explore using smaller, open-source\nLLMs and testing on larger datasets to further validate Kajal's performance."
    },
    {
        "date": "2024-12",
        "title": "A Unified Model For Voice and Accent Conversion In Speech and Singing using Self-Supervised Learning and Feature Extraction",
        "author": "Sowmya Cheripally",
        "link": "http://arxiv.org/abs/2412.08312v1",
        "abstract": "This paper presents a new voice conversion model capable of transforming both\nspeaking and singing voices. It addresses key challenges in current systems,\nsuch as conveying emotions, managing pronunciation and accent changes, and\nreproducing non-verbal sounds. One of the model's standout features is its\nability to perform accent conversion on hybrid voice samples that encompass\nboth speech and singing, allowing it to change the speaker's accent while\npreserving the original content and prosody. The proposed model uses an\nencoder-decoder architecture: the encoder is based on HuBERT to process the\nspeech's acoustic and linguistic content, while the HiFi-GAN decoder audio\nmatches the target speaker's voice. The model incorporates fundamental\nfrequency (f0) features and singer embeddings to enhance performance while\nensuring the pitch & tone accuracy and vocal identity are preserved during\ntransformation. This approach improves how naturally and flexibly voice style\ncan be transformed, showing strong potential for applications in voice dubbing,\ncontent creation, and technologies like Text-to-Speech (TTS) and Interactive\nVoice Response (IVR) systems."
    },
    {
        "date": "2024-12",
        "title": "Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks",
        "author": "Faqian Guan, Tianqing Zhu, Wenhan Chang, Wei Ren, and Wanlei Zhou",
        "link": "http://arxiv.org/abs/2412.05830v1",
        "abstract": "Graph Neural Networks (GNNs), specifically designed to process the graph\ndata, have achieved remarkable success in various applications. Link stealing\nattacks on graph data pose a significant privacy threat, as attackers aim to\nextract sensitive relationships between nodes (entities), potentially leading\nto academic misconduct, fraudulent transactions, or other malicious activities.\nPrevious studies have primarily focused on single datasets and did not explore\ncross-dataset attacks, let alone attacks that leverage the combined knowledge\nof multiple attackers. However, we find that an attacker can combine the data\nknowledge of multiple attackers to create a more effective attack model, which\ncan be referred to cross-dataset attacks. Moreover, if knowledge can be\nextracted with the help of Large Language Models (LLMs), the attack capability\nwill be more significant. In this paper, we propose a novel link stealing\nattack method that takes advantage of cross-dataset and Large Language Models\n(LLMs). The LLM is applied to process datasets with different data structures\nin cross-dataset attacks. Each attacker fine-tunes the LLM on their specific\ndataset to generate a tailored attack model. We then introduce a novel model\nmerging method to integrate the parameters of these attacker-specific models\neffectively. The result is a merged attack model with superior generalization\ncapabilities, enabling effective attacks not only on the attackers' datasets\nbut also on previously unseen (out-of-domain) datasets. We conducted extensive\nexperiments in four datasets to demonstrate the effectiveness of our method.\nAdditional experiments with three different GNN and LLM architectures further\nillustrate the generality of our approach."
    },
    {
        "date": "2024-12",
        "title": "Espresso: High Compression For Rich Extraction From Videos for Your Vision-Language Model",
        "author": "Keunwoo Peter Yu, Achal Dave, Rares Ambrus, and Jean Mercat",
        "link": "http://arxiv.org/abs/2412.04729v3",
        "abstract": "Recent advances in vision-language models (VLMs) have shown great promise in\nconnecting images and text, but extending these models to long videos remains\nchallenging due to the rapid growth in token counts. Models that compress\nvideos by local aggregation in time or space have become popular for handling\nlong-form inputs; however, these pooling-based projectors sacrifice the\nbenefits of fixed-length representations that are crucial for streaming and\nefficient video understanding. We introduce $\\texttt{Espresso}$, a new\narchitecture that separately compresses spatial and temporal features into\nfixed-length sequences. $\\texttt{Espresso}$ enables efficient video encoding\nwhile maintaining strong long-form reasoning capabilities. Experiments show\nthat fixed-length compression combined with segment-wise processing offers a\nscalable and competitive alternative to pooling-based approaches. Our results\ndemonstrate that fixed-length projectors, when properly designed and trained,\nremain a viable foundation for video-language modeling."
    },
    {
        "date": "2024-12",
        "title": "Prompting Large Language Models for Clinical Temporal Relation Extraction",
        "author": "Jianping He, Laila Rasmy, Haifang Li, Jianfu Li, Zenan Sun, Evan Yu, Degui Zhi, and Cui Tao",
        "link": "http://arxiv.org/abs/2412.04512v1",
        "abstract": "Objective: This paper aims to prompt large language models (LLMs) for\nclinical temporal relation extraction (CTRE) in both few-shot and fully\nsupervised settings. Materials and Methods: This study utilizes four LLMs:\nEncoder-based GatorTron-Base (345M)/Large (8.9B); Decoder-based\nLLaMA3-8B/MeLLaMA-13B. We developed full (FFT) and parameter-efficient (PEFT)\nfine-tuning strategies and evaluated these strategies on the 2012 i2b2 CTRE\ntask. We explored four fine-tuning strategies for GatorTron-Base: (1) Standard\nFine-Tuning, (2) Hard-Prompting with Unfrozen LLMs, (3) Soft-Prompting with\nFrozen LLMs, and (4) Low-Rank Adaptation (LoRA) with Frozen LLMs. For\nGatorTron-Large, we assessed two PEFT strategies-Soft-Prompting and LoRA with\nFrozen LLMs-leveraging Quantization techniques. Additionally, LLaMA3-8B and\nMeLLaMA-13B employed two PEFT strategies: LoRA strategy with Quantization\n(QLoRA) applied to Frozen LLMs using instruction tuning and standard\nfine-tuning. Results: Under fully supervised settings, Hard-Prompting with\nUnfrozen GatorTron-Base achieved the highest F1 score (89.54%), surpassing the\nSOTA model (85.70%) by 3.74%. Additionally, two variants of QLoRA adapted to\nGatorTron-Large and Standard Fine-Tuning of GatorTron-Base exceeded the SOTA\nmodel by 2.36%, 1.88%, and 0.25%, respectively. Decoder-based models with\nfrozen parameters outperformed their Encoder-based counterparts in this\nsetting; however, the trend reversed in few-shot scenarios. Discussions and\nConclusions: This study presented new methods that significantly improved CTRE\nperformance, benefiting downstream tasks reliant on CTRE systems. The findings\nunderscore the importance of selecting appropriate models and fine-tuning\nstrategies based on task requirements and data availability. Future work will\nexplore larger models and broader CTRE applications."
    },
    {
        "date": "2024-12",
        "title": "A Review on Scientific Knowledge Extraction using Large Language Models in Biomedical Sciences",
        "author": "Gabriel Lino Garcia, Jo\u00e3o Renato Ribeiro Manesco, Pedro Henrique Paiola, Lucas Miranda, Maria Paola de Salvo, and Jo\u00e3o Paulo Papa",
        "link": "http://arxiv.org/abs/2412.03531v1",
        "abstract": "The rapid advancement of large language models (LLMs) has opened new\nboundaries in the extraction and synthesis of medical knowledge, particularly\nwithin evidence synthesis. This paper reviews the state-of-the-art applications\nof LLMs in the biomedical domain, exploring their effectiveness in automating\ncomplex tasks such as evidence synthesis and data extraction from a biomedical\ncorpus of documents. While LLMs demonstrate remarkable potential, significant\nchallenges remain, including issues related to hallucinations, contextual\nunderstanding, and the ability to generalize across diverse medical tasks. We\nhighlight critical gaps in the current research literature, particularly the\nneed for unified benchmarks to standardize evaluations and ensure reliability\nin real-world applications. In addition, we propose directions for future\nresearch, emphasizing the integration of state-of-the-art techniques such as\nretrieval-augmented generation (RAG) to enhance LLM performance in evidence\nsynthesis. By addressing these challenges and utilizing the strengths of LLMs,\nwe aim to improve access to medical literature and facilitate meaningful\ndiscoveries in healthcare."
    },
    {
        "date": "2024-11",
        "title": "Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models",
        "author": "Valentina Anita Carriero, Antonia Azzini, Ilaria Baroni, Mario Scrocca, and Irene Celino",
        "link": "http://arxiv.org/abs/2412.03589v1",
        "abstract": "Procedural Knowledge is the know-how expressed in the form of sequences of\nsteps needed to perform some tasks. Procedures are usually described by means\nof natural language texts, such as recipes or maintenance manuals, possibly\nspread across different documents and systems, and their interpretation and\nsubsequent execution is often left to the reader. Representing such procedures\nin a Knowledge Graph (KG) can be the basis to build digital tools to support\nthose users who need to apply or execute them. In this paper, we leverage Large\nLanguage Model (LLM) capabilities and propose a prompt engineering approach to\nextract steps, actions, objects, equipment and temporal information from a\ntextual procedure, in order to populate a Procedural KG according to a\npre-defined ontology. We evaluate the KG extraction results by means of a user\nstudy, in order to qualitatively and quantitatively assess the perceived\nquality and usefulness of the LLM-extracted procedural knowledge. We show that\nLLMs can produce outputs of acceptable quality and we assess the subjective\nperception of AI by human evaluators."
    },
    {
        "date": "2024-11",
        "title": "A survey on cutting-edge relation extraction techniques based on language models",
        "author": "Jose A. Diaz-Garcia, and Julio Amador Diaz Lopez",
        "link": "http://arxiv.org/abs/2411.18157v1",
        "abstract": "This comprehensive survey delves into the latest advancements in Relation\nExtraction (RE), a pivotal task in natural language processing essential for\napplications across biomedical, financial, and legal sectors. This study\nhighlights the evolution and current state of RE techniques by analyzing 137\npapers presented at the Association for Computational Linguistics (ACL)\nconferences over the past four years, focusing on models that leverage language\nmodels. Our findings underscore the dominance of BERT-based methods in\nachieving state-of-the-art results for RE while also noting the promising\ncapabilities of emerging large language models (LLMs) like T5, especially in\nfew-shot relation extraction scenarios where they excel in identifying\npreviously unseen relations."
    },
    {
        "date": "2024-11",
        "title": "DocEDA: Automated Extraction and Design of Analog Circuits from Documents with Large Language Model",
        "author": "Hong Cai Chen, Longchang Wu, Ming Gao, Lingrui Shen, Jiarui Zhong, and Yipin Xu",
        "link": "http://arxiv.org/abs/2412.05301v1",
        "abstract": "Efficient and accurate extraction of electrical parameters from circuit\ndatasheets and design documents is critical for accelerating circuit design in\nElectronic Design Automation (EDA). Traditional workflows often rely on\nengineers manually searching and extracting these parameters, which is\ntime-consuming, and prone to human error. To address these challenges, we\nintroduce DocEDA, an automated system that leverages advanced computer vision\ntechniques and Large Language Models (LLMs) to extract electrical parameters\nseamlessly from documents. The layout analysis model specifically designed for\ndatasheet is proposed to classify documents into circuit-related parts.\nUtilizing the inherent Chain-of-Thought reasoning capabilities of LLMs, DocEDA\nautomates the extraction of electronic component parameters from documents. For\ncircuit diagrams parsing, an improved GAM-YOLO model is hybrid with topology\nidentification to transform diagrams into circuit netlists. Then, a space\nmapping enhanced optimization framework is evoked for optimization the layout\nin the document. Experimental evaluations demonstrate that DocEDA significantly\nenhances the efficiency of processing circuit design documents and the accuracy\nof electrical parameter extraction. It exhibits adaptability to various circuit\ndesign scenarios and document formats, offering a novel solution for EDA with\nthe potential to transform traditional methodologies."
    },
    {
        "date": "2024-11",
        "title": "RAMIE: Retrieval-Augmented Multi-task Information Extraction with Large Language Models on Dietary Supplements",
        "author": "Zaifu Zhan, Shuang Zhou, Mingchen Li, and Rui Zhang",
        "link": "http://arxiv.org/abs/2411.15700v1",
        "abstract": "\\textbf{Objective:} We aimed to develop an advanced multi-task large language\nmodel (LLM) framework to extract multiple types of information about dietary\nsupplements (DS) from clinical records.\n  \\textbf{Methods:} We used four core DS information extraction tasks - namely,\nnamed entity recognition (NER: 2,949 clinical sentences), relation extraction\n(RE: 4,892 sentences), triple extraction (TE: 2,949 sentences), and usage\nclassification (UC: 2,460 sentences) as our multitasks. We introduced a novel\nRetrieval-Augmented Multi-task Information Extraction (RAMIE) Framework,\nincluding: 1) employed instruction fine-tuning techniques with task-specific\nprompts, 2) trained LLMs for multiple tasks with improved storage efficiency\nand lower training costs, and 3) incorporated retrieval augmentation generation\n(RAG) techniques by retrieving similar examples from the training set. We\ncompared RAMIE's performance to LLMs with instruction fine-tuning alone and\nconducted an ablation study to assess the contributions of multi-task learning\nand RAG to improved multitasking performance.\n  \\textbf{Results:} With the aid of the RAMIE framework, Llama2-13B achieved an\nF1 score of 87.39 (3.51\\% improvement) on the NER task and demonstrated\noutstanding performance on the RE task with an F1 score of 93.74 (1.15\\%\nimprovement). For the TE task, Llama2-7B scored 79.45 (14.26\\% improvement),\nand MedAlpaca-7B achieved the highest F1 score of 93.45 (0.94\\% improvement) on\nthe UC task. The ablation study revealed that while MTL increased efficiency\nwith a slight trade-off in performance, RAG significantly boosted overall\naccuracy.\n  \\textbf{Conclusion:} This study presents a novel RAMIE framework that\ndemonstrates substantial improvements in multi-task information extraction for\nDS-related data from clinical records. Our framework can potentially be applied\nto other domains."
    },
    {
        "date": "2024-11",
        "title": "Variable Extraction for Model Recovery in Scientific Literature",
        "author": "Chunwei Liu, Enrique Noriega-Atala, Adarsh Pyarelal, Clayton T Morrison, and Mike Cafarella",
        "link": "http://arxiv.org/abs/2411.14569v1",
        "abstract": "The global output of academic publications exceeds 5 million articles per\nyear, making it difficult for humans to keep up with even a tiny fraction of\nscientific output. We need methods to navigate and interpret the artifacts --\ntexts, graphs, charts, code, models, and datasets -- that make up the\nliterature. This paper evaluates various methods for extracting mathematical\nmodel variables from epidemiological studies, such as ``infection rate\n($\\alpha$),'' ``recovery rate ($\\gamma$),'' and ``mortality rate ($\\mu$).''\nVariable extraction appears to be a basic task, but plays a pivotal role in\nrecovering models from scientific literature. Once extracted, we can use these\nvariables for automatic mathematical modeling, simulation, and replication of\npublished results.\n  We introduce a benchmark dataset comprising manually-annotated variable\ndescriptions and variable values extracted from scientific papers. Based on\nthis dataset, we present several baseline methods for variable extraction based\non Large Language Models (LLMs) and rule-based information extraction systems.\nOur analysis shows that LLM-based solutions perform the best. Despite the\nincremental benefits of combining rule-based extraction outputs with LLMs, the\nleap in performance attributed to the transfer-learning and instruction-tuning\ncapabilities of LLMs themselves is far more significant. This investigation\ndemonstrates the potential of LLMs to enhance automatic comprehension of\nscientific artifacts and for automatic model recovery and simulation."
    },
    {
        "date": "2024-11",
        "title": "Bounding-box Watermarking: Defense against Model Extraction Attacks on Object Detectors",
        "author": "Satoru Koda, and Ikuya Morikawa",
        "link": "http://arxiv.org/abs/2411.13047v2",
        "abstract": "Deep neural networks (DNNs) deployed in a cloud often allow users to query\nmodels via the APIs. However, these APIs expose the models to model extraction\nattacks (MEAs). In this attack, the attacker attempts to duplicate the target\nmodel by abusing the responses from the API. Backdoor-based DNN watermarking is\nknown as a promising defense against MEAs, wherein the defender injects a\nbackdoor into extracted models via API responses. The backdoor is used as a\nwatermark of the model; if a suspicious model has the watermark (i.e.,\nbackdoor), it is verified as an extracted model. This work focuses on object\ndetection (OD) models. Existing backdoor attacks on OD models are not\napplicable for model watermarking as the defense against MEAs on a realistic\nthreat model. Our proposed approach involves inserting a backdoor into\nextracted models via APIs by stealthily modifying the bounding-boxes (BBs) of\nobjects detected in queries while keeping the OD capability. In our experiments\non three OD datasets, the proposed approach succeeded in identifying the\nextracted models with 100% accuracy in a wide variety of experimental\nscenarios."
    },
    {
        "date": "2024-11",
        "title": "StreetviewLLM: Extracting Geographic Information Using a Chain-of-Thought Multimodal Large Language Model",
        "author": "Zongrong Li, Junhao Xu, Siqin Wang, Yifan Wu, and Haiyang Li",
        "link": "http://arxiv.org/abs/2411.14476v1",
        "abstract": "Geospatial predictions are crucial for diverse fields such as disaster\nmanagement, urban planning, and public health. Traditional machine learning\nmethods often face limitations when handling unstructured or multi-modal data\nlike street view imagery. To address these challenges, we propose\nStreetViewLLM, a novel framework that integrates a large language model with\nthe chain-of-thought reasoning and multimodal data sources. By combining street\nview imagery with geographic coordinates and textual data, StreetViewLLM\nimproves the precision and granularity of geospatial predictions. Using\nretrieval-augmented generation techniques, our approach enhances geographic\ninformation extraction, enabling a detailed analysis of urban environments. The\nmodel has been applied to seven global cities, including Hong Kong, Tokyo,\nSingapore, Los Angeles, New York, London, and Paris, demonstrating superior\nperformance in predicting urban indicators, including population density,\naccessibility to healthcare, normalized difference vegetation index, building\nheight, and impervious surface. The results show that StreetViewLLM\nconsistently outperforms baseline models, offering improved predictive accuracy\nand deeper insights into the built environment. This research opens new\nopportunities for integrating the large language model into urban analytics,\ndecision-making in urban planning, infrastructure management, and environmental\nmonitoring."
    },
    {
        "date": "2024-11",
        "title": "LLM-IE: A Python Package for Generative Information Extraction with Large Language Models",
        "author": "Enshuo Hsu, and Kirk Roberts",
        "link": "http://arxiv.org/abs/2411.11779v1",
        "abstract": "Objectives: Despite the recent adoption of large language models (LLMs) for\nbiomedical information extraction, challenges in prompt engineering and\nalgorithms persist, with no dedicated software available. To address this, we\ndeveloped LLM-IE: a Python package for building complete information extraction\npipelines. Our key innovation is an interactive LLM agent to support schema\ndefinition and prompt design.\n  Materials and Methods: The LLM-IE supports named entity recognition, entity\nattribute extraction, and relation extraction tasks. We benchmarked on the i2b2\ndatasets and conducted a system evaluation.\n  Results: The sentence-based prompting algorithm resulted in the best\nperformance while requiring a longer inference time. System evaluation provided\nintuitive visualization.\n  Discussion: LLM-IE was designed from practical NLP experience in healthcare\nand has been adopted in internal projects. It should hold great value to the\nbiomedical NLP community.\n  Conclusion: We developed a Python package, LLM-IE, that provides building\nblocks for robust information extraction pipeline construction."
    },
    {
        "date": "2024-11",
        "title": "Few-shot Model Extraction Attacks against Sequential Recommender Systems",
        "author": "Hui Zhang, and Fu Liu",
        "link": "http://arxiv.org/abs/2411.11677v2",
        "abstract": "Among adversarial attacks against sequential recommender systems, model\nextraction attacks represent a method to attack sequential recommendation\nmodels without prior knowledge. Existing research has primarily concentrated on\nthe adversary's execution of black-box attacks through data-free model\nextraction. However, a significant gap remains in the literature concerning the\ndevelopment of surrogate models by adversaries with access to few-shot raw data\n(10\\% even less). That is, the challenge of how to construct a surrogate model\nwith high functional similarity within the context of few-shot data scenarios\nremains an issue that requires resolution.This study addresses this gap by\nintroducing a novel few-shot model extraction framework against sequential\nrecommenders, which is designed to construct a superior surrogate model with\nthe utilization of few-shot data. The proposed few-shot model extraction\nframework is comprised of two components: an autoregressive augmentation\ngeneration strategy and a bidirectional repair loss-facilitated model\ndistillation procedure. Specifically, to generate synthetic data that closely\napproximate the distribution of raw data, autoregressive augmentation\ngeneration strategy integrates a probabilistic interaction sampler to extract\ninherent dependencies and a synthesis determinant signal module to characterize\nuser behavioral patterns. Subsequently, bidirectional repair loss, which target\nthe discrepancies between the recommendation lists, is designed as auxiliary\nloss to rectify erroneous predictions from surrogate models, transferring\nknowledge from the victim model to the surrogate model effectively. Experiments\non three datasets show that the proposed few-shot model extraction framework\nyields superior surrogate models."
    },
    {
        "date": "2024-11",
        "title": "Chapter 7 Review of Data-Driven Generative AI Models for Knowledge Extraction from Scientific Literature in Healthcare",
        "author": "Leon Kopitar, Primoz Kocbek, Lucija Gosak, and Gregor Stiglic",
        "link": "http://arxiv.org/abs/2411.11635v1",
        "abstract": "This review examines the development of abstractive NLP-based text\nsummarization approaches and compares them to existing techniques for\nextractive summarization. A brief history of text summarization from the 1950s\nto the introduction of pre-trained language models such as Bidirectional\nEncoder Representations from Transformer (BERT) and Generative Pre-training\nTransformers (GPT) are presented. In total, 60 studies were identified in\nPubMed and Web of Science, of which 29 were excluded and 24 were read and\nevaluated for eligibility, resulting in the use of seven studies for further\nanalysis. This chapter also includes a section with examples including an\nexample of a comparison between GPT-3 and state-of-the-art GPT-4 solutions in\nscientific text summarisation. Natural language processing has not yet reached\nits full potential in the generation of brief textual summaries. As there are\nacknowledged concerns that must be addressed, we can expect gradual\nintroduction of such models in practise."
    },
    {
        "date": "2024-11",
        "title": "A Hard-Label Cryptanalytic Extraction of Non-Fully Connected Deep Neural Networks using Side-Channel Attacks",
        "author": "Benoit Coqueret, Mathieu Carbone, Olivier Sentieys, and Gabriel Zaid",
        "link": "http://arxiv.org/abs/2411.10174v1",
        "abstract": "During the past decade, Deep Neural Networks (DNNs) proved their value on a\nlarge variety of subjects. However despite their high value and public\naccessibility, the protection of the intellectual property of DNNs is still an\nissue and an emerging research field. Recent works have successfully extracted\nfully-connected DNNs using cryptanalytic methods in hard-label settings,\nproving that it was possible to copy a DNN with high fidelity, i.e., high\nsimilitude in the output predictions. However, the current cryptanalytic\nattacks cannot target complex, i.e., not fully connected, DNNs and are limited\nto special cases of neurons present in deep networks.\n  In this work, we introduce a new end-to-end attack framework designed for\nmodel extraction of embedded DNNs with high fidelity. We describe a new\nblack-box side-channel attack which splits the DNN in several linear parts for\nwhich we can perform cryptanalytic extraction and retrieve the weights in\nhard-label settings. With this method, we are able to adapt cryptanalytic\nextraction, for the first time, to non-fully connected DNNs, while maintaining\na high fidelity. We validate our contributions by targeting several\narchitectures implemented on a microcontroller unit, including a Multi-Layer\nPerceptron (MLP) of 1.7 million parameters and a shortened MobileNetv1. Our\nframework successfully extracts all of these DNNs with high fidelity (88.4% for\nthe MobileNetv1 and 93.2% for the MLP). Furthermore, we use the stolen model to\ngenerate adversarial examples and achieve close to white-box performance on the\nvictim's model (95.8% and 96.7% transfer rate)."
    },
    {
        "date": "2024-11",
        "title": "Model Stealing for Any Low-Rank Language Model",
        "author": "Allen Liu, and Ankur Moitra",
        "link": "http://arxiv.org/abs/2411.07536v1",
        "abstract": "Model stealing, where a learner tries to recover an unknown model via\ncarefully chosen queries, is a critical problem in machine learning, as it\nthreatens the security of proprietary models and the privacy of data they are\ntrained on. In recent years, there has been particular interest in stealing\nlarge language models (LLMs). In this paper, we aim to build a theoretical\nunderstanding of stealing language models by studying a simple and\nmathematically tractable setting. We study model stealing for Hidden Markov\nModels (HMMs), and more generally low-rank language models.\n  We assume that the learner works in the conditional query model, introduced\nby Kakade, Krishnamurthy, Mahajan and Zhang. Our main result is an efficient\nalgorithm in the conditional query model, for learning any low-rank\ndistribution. In other words, our algorithm succeeds at stealing any language\nmodel whose output distribution is low-rank. This improves upon the previous\nresult by Kakade, Krishnamurthy, Mahajan and Zhang, which also requires the\nunknown distribution to have high \"fidelity\", a property that holds only in\nrestricted cases. There are two key insights behind our algorithm: First, we\nrepresent the conditional distributions at each timestep by constructing\nbarycentric spanners among a collection of vectors of exponentially large\ndimension. Second, for sampling from our representation, we iteratively solve a\nsequence of convex optimization problems that involve projection in relative\nentropy to prevent compounding of errors over the length of the sequence. This\nis an interesting example where, at least theoretically, allowing a machine\nlearning model to solve more complex problems at inference time can lead to\ndrastic improvements in its performance."
    },
    {
        "date": "2024-11",
        "title": "AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data",
        "author": "Tianyi Zhang, Miu Kojima, and Simon D'Alfonso",
        "link": "http://arxiv.org/abs/2411.04691v1",
        "abstract": "Smartphones, equipped with an array of sensors, have become valuable tools\nfor personal sensing. Particularly in digital health, smartphones facilitate\nthe tracking of health-related behaviors and contexts, contributing\nsignificantly to digital phenotyping, a process where data from digital\ninteractions is analyzed to infer behaviors and assess mental health.\nTraditional methods process raw sensor data into information features for\nstatistical and machine learning analyses. In this paper, we introduce a novel\napproach that systematically converts smartphone-collected data into\nstructured, chronological narratives. The AWARE Narrator translates\nquantitative smartphone sensing data into English language descriptions,\nforming comprehensive narratives of an individual's activities. We apply the\nframework to the data collected from university students over a week,\ndemonstrating the potential of utilizing the narratives to summarize individual\nbehavior, and analyzing psychological states by leveraging large language\nmodels."
    },
    {
        "date": "2024-11",
        "title": "Fine-Tuning Vision-Language Model for Automated Engineering Drawing Information Extraction",
        "author": "Muhammad Tayyab Khan, Lequn Chen, Ye Han Ng, Wenhe Feng, Nicholas Yew Jin Tan, and Seung Ki Moon",
        "link": "http://arxiv.org/abs/2411.03707v1",
        "abstract": "Geometric Dimensioning and Tolerancing (GD&T) plays a critical role in\nmanufacturing by defining acceptable variations in part features to ensure\ncomponent quality and functionality. However, extracting GD&T information from\n2D engineering drawings is a time-consuming and labor-intensive task, often\nrelying on manual efforts or semi-automated tools. To address these challenges,\nthis study proposes an automated and computationally efficient GD&T extraction\nmethod by fine-tuning Florence-2, an open-source vision-language model (VLM).\nThe model is trained on a dataset of 400 drawings with ground truth annotations\nprovided by domain experts. For comparison, two state-of-the-art closed-source\nVLMs, GPT-4o and Claude-3.5-Sonnet, are evaluated on the same dataset. All\nmodels are assessed using precision, recall, F1-score, and hallucination\nmetrics. Due to the computational cost and impracticality of fine-tuning large\nclosed-source VLMs for domain-specific tasks, GPT-4o and Claude-3.5-Sonnet are\nevaluated in a zero-shot setting. In contrast, Florence-2, a smaller model with\n0.23 billion parameters, is optimized through full-parameter fine-tuning across\nthree distinct experiments, each utilizing datasets augmented to different\nlevels. The results show that Florence-2 achieves a 29.95% increase in\nprecision, a 37.75% increase in recall, a 52.40% improvement in F1-score, and a\n43.15% reduction in hallucination rate compared to the best-performing\nclosed-source model. These findings highlight the effectiveness of fine-tuning\nsmaller, open-source VLMs like Florence-2, offering a practical and efficient\nsolution for automated GD&T extraction to support downstream manufacturing\ntasks."
    },
    {
        "date": "2024-11",
        "title": "Speaker Emotion Recognition: Leveraging Self-Supervised Models for Feature Extraction Using Wav2Vec2 and HuBERT",
        "author": "Pourya Jafarzadeh, Amir Mohammad Rostami, and Padideh Choobdar",
        "link": "http://arxiv.org/abs/2411.02964v2",
        "abstract": "Speech is the most natural way of expressing ourselves as humans. Identifying\nemotion from speech is a nontrivial task due to the ambiguous definition of\nemotion itself. Speaker Emotion Recognition (SER) is essential for\nunderstanding human emotional behavior. The SER task is challenging due to the\nvariety of speakers, background noise, complexity of emotions, and speaking\nstyles. It has many applications in education, healthcare, customer service,\nand Human-Computer Interaction (HCI). Previously, conventional machine learning\nmethods such as SVM, HMM, and KNN have been used for the SER task. In recent\nyears, deep learning methods have become popular, with convolutional neural\nnetworks and recurrent neural networks being used for SER tasks. The input of\nthese methods is mostly spectrograms and hand-crafted features. In this work,\nwe study the use of self-supervised transformer-based models, Wav2Vec2 and\nHuBERT, to determine the emotion of speakers from their voice. The models\nautomatically extract features from raw audio signals, which are then used for\nthe classification task. The proposed solution is evaluated on reputable\ndatasets, including RAVDESS, SHEMO, SAVEE, AESDD, and Emo-DB. The results show\nthe effectiveness of the proposed method on different datasets. Moreover, the\nmodel has been used for real-world applications like call center conversations,\nand the results demonstrate that the model accurately predicts emotions."
    },
    {
        "date": "2024-11",
        "title": "DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural Networks",
        "author": "Jinyin Chen, Haonan Ma, and Haibin Zheng",
        "link": "http://arxiv.org/abs/2411.03364v2",
        "abstract": "Graph has become increasingly integral to the advancement of recommendation\nsystems, particularly with the fast development of graph neural network(GNN).\nBy exploring the virtue of rich node features and link information, GNN is\ndesigned to provide personalized and accurate suggestions. Meanwhile, the\nprivacy leakage of GNN in such contexts has also captured special attention.\nPrior work has revealed that a malicious user can utilize auxiliary knowledge\nto extract sensitive link data of the target graph, integral to recommendation\nsystems, via the decision made by the target GNN model. This poses a\nsignificant risk to the integrity and confidentiality of data used in\nrecommendation system. Though important, previous works on GNN's privacy\nleakage are still challenged in three aspects, i.e., limited stealing attack\nscenarios, sub-optimal attack performance, and adaptation against defense. To\naddress these issues, we propose a diffusion model based link stealing attack,\nnamed DM4Steal. It differs previous work from three critical aspects. (i)\nGenerality: aiming at six attack scenarios with limited auxiliary knowledge, we\npropose a novel training strategy for diffusion models so that DM4Steal is\ntransferable to diverse attack scenarios. (ii) Effectiveness: benefiting from\nthe retention of semantic structure in the diffusion model during the training\nprocess, DM4Steal is capable to learn the precise topology of the target graph\nthrough the GNN decision process. (iii) Adaptation: when GNN is defensive\n(e.g., DP, Dropout), DM4Steal relies on the stability that comes from sampling\nthe score model multiple times to keep performance degradation to a minimum,\nthus DM4Steal implements successful adaptive attack on defensive GNN."
    },
    {
        "date": "2024-11",
        "title": "HIP: Hierarchical Point Modeling and Pre-training for Visual Information Extraction",
        "author": "Rujiao Long, Pengfei Wang, Zhibo Yang, and Cong Yao",
        "link": "http://arxiv.org/abs/2411.01139v1",
        "abstract": "End-to-end visual information extraction (VIE) aims at integrating the\nhierarchical subtasks of VIE, including text spotting, word grouping, and\nentity labeling, into a unified framework. Dealing with the gaps among the\nthree subtasks plays a pivotal role in designing an effective VIE model.\nOCR-dependent methods heavily rely on offline OCR engines and inevitably suffer\nfrom OCR errors, while OCR-free methods, particularly those employing a\nblack-box model, might produce outputs that lack interpretability or contain\nhallucinated content. Inspired by CenterNet, DeepSolo, and ESP, we propose HIP,\nwhich models entities as HIerarchical Points to better conform to the\nhierarchical nature of the end-to-end VIE task. Specifically, such hierarchical\npoints can be flexibly encoded and subsequently decoded into desired text\ntranscripts, centers of various regions, and categories of entities.\nFurthermore, we devise corresponding hierarchical pre-training strategies,\ncategorized as image reconstruction, layout learning, and language enhancement,\nto reinforce the cross-modality representation of the hierarchical encoders.\nQuantitative experiments on public benchmarks demonstrate that HIP outperforms\nprevious state-of-the-art methods, while qualitative results show its excellent\ninterpretability."
    },
    {
        "date": "2024-10",
        "title": "Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document",
        "author": "Vicky Dong, Hao Yu, and Yao Chen",
        "link": "http://arxiv.org/abs/2410.23452v1",
        "abstract": "This study introduces a novel approach to sentence-level relation extraction\n(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models\n(LLMs) to generate contextually enriched support documents. By harnessing the\npower of LLMs to generate auxiliary information, our approach crafts an\nintricate graph representation of textual data. This graph is subsequently\nprocessed through a Graph Neural Network (GNN) to refine and enrich the\nembeddings associated with each entity ensuring a more nuanced and\ninterconnected understanding of the data. This methodology addresses the\nlimitations of traditional sentence-level RE models by incorporating broader\ncontexts and leveraging inter-entity interactions, thereby improving the\nmodel's ability to capture complex relationships across sentences. Our\nexperiments, conducted on the CrossRE dataset, demonstrate the effectiveness of\nour approach, with notable improvements in performance across various domains.\nThe results underscore the potential of combining GNNs with LLM-generated\ncontext to advance the field of relation extraction."
    },
    {
        "date": "2024-10",
        "title": "Image2Struct: Benchmarking Structure Extraction for Vision-Language Models",
        "author": "Josselin Somerville Roberts, Tony Lee, Chi Heem Wong, Michihiro Yasunaga, Yifan Mai, and Percy Liang",
        "link": "http://arxiv.org/abs/2410.22456v1",
        "abstract": "We introduce Image2Struct, a benchmark to evaluate vision-language models\n(VLMs) on extracting structure from images. Our benchmark 1) captures\nreal-world use cases, 2) is fully automatic and does not require human\njudgment, and 3) is based on a renewable stream of fresh data. In Image2Struct,\nVLMs are prompted to generate the underlying structure (e.g., LaTeX code or\nHTML) from an input image (e.g., webpage screenshot). The structure is then\nrendered to produce an output image (e.g., rendered webpage), which is compared\nagainst the input image to produce a similarity score. This round-trip\nevaluation allows us to quantitatively evaluate VLMs on tasks with multiple\nvalid structures. We create a pipeline that downloads fresh data from active\nonline communities upon execution and evaluates the VLMs without human\nintervention. We introduce three domains (Webpages, LaTeX, and Musical Scores)\nand use five image metrics (pixel similarity, cosine similarity between the\nInception vectors, learned perceptual image patch similarity, structural\nsimilarity index measure, and earth mover similarity) that allow efficient and\nautomatic comparison between pairs of images. We evaluate Image2Struct on 14\nprominent VLMs and find that scores vary widely, indicating that Image2Struct\ncan differentiate between the performances of different VLMs. Additionally, the\nbest score varies considerably across domains (e.g., 0.402 on sheet music vs.\n0.830 on LaTeX equations), indicating that Image2Struct contains tasks of\nvarying difficulty. For transparency, we release the full results at\nhttps://crfm.stanford.edu/helm/image2struct/v1.0.1/."
    },
    {
        "date": "2024-10",
        "title": "Measuring memorization in language models via probabilistic extraction",
        "author": "Jamie Hayes, Marika Swanberg, Harsh Chaudhari, Itay Yona, Ilia Shumailov, Milad Nasr, Christopher A. Choquette-Choo, Katherine Lee, and A. Feder Cooper",
        "link": "http://arxiv.org/abs/2410.19482v3",
        "abstract": "Large language models (LLMs) are susceptible to memorizing training data,\nraising concerns about the potential extraction of sensitive information at\ngeneration time. Discoverable extraction is the most common method for\nmeasuring this issue: split a training example into a prefix and suffix, then\nprompt the LLM with the prefix, and deem the example extractable if the LLM\ngenerates the matching suffix using greedy sampling. This definition yields a\nyes-or-no determination of whether extraction was successful with respect to a\nsingle query. Though efficient to compute, we show that this definition is\nunreliable because it does not account for non-determinism present in more\nrealistic (non-greedy) sampling schemes, for which LLMs produce a range of\noutputs for the same prompt. We introduce probabilistic discoverable\nextraction, which, without additional cost, relaxes discoverable extraction by\nconsidering multiple queries to quantify the probability of extracting a target\nsequence. We evaluate our probabilistic measure across different models,\nsampling schemes, and training-data repetitions, and find that this measure\nprovides more nuanced information about extraction risk compared to traditional\ndiscoverable extraction."
    },
    {
        "date": "2024-10",
        "title": "Integrating Deep Feature Extraction and Hybrid ResNet-DenseNet Model for Multi-Class Abnormality Detection in Endoscopic Images",
        "author": "Aman Sagar, Preeti Mehta, Monika Shrivastva, and Suchi Kumari",
        "link": "http://arxiv.org/abs/2410.18457v1",
        "abstract": "This paper presents a deep learning framework for the multi-class\nclassification of gastrointestinal abnormalities in Video Capsule Endoscopy\n(VCE) frames. The aim is to automate the identification of ten GI abnormality\nclasses, including angioectasia, bleeding, and ulcers, thereby reducing the\ndiagnostic burden on gastroenterologists. Utilizing an ensemble of DenseNet and\nResNet architectures, the proposed model achieves an overall accuracy of 94\\%\nacross a well-structured dataset. Precision scores range from 0.56 for erythema\nto 1.00 for worms, with recall rates peaking at 98% for normal findings. This\nstudy emphasizes the importance of robust data preprocessing techniques,\nincluding normalization and augmentation, in enhancing model performance. The\ncontributions of this work lie in developing an effective AI-driven tool that\nstreamlines the diagnostic process in gastroenterology, ultimately improving\npatient care and clinical outcomes."
    },
    {
        "date": "2024-10",
        "title": "Extracting Spatiotemporal Data from Gradients with Large Language Models",
        "author": "Lele Zheng, Yang Cao, Renhe Jiang, Kenjiro Taura, Yulong Shen, Sheng Li, and Masatoshi Yoshikawa",
        "link": "http://arxiv.org/abs/2410.16121v1",
        "abstract": "Recent works show that sensitive user data can be reconstructed from gradient\nupdates, breaking the key privacy promise of federated learning. While success\nwas demonstrated primarily on image data, these methods do not directly\ntransfer to other domains, such as spatiotemporal data. To understand privacy\nrisks in spatiotemporal federated learning, we first propose Spatiotemporal\nGradient Inversion Attack (ST-GIA), a gradient attack algorithm tailored to\nspatiotemporal data that successfully reconstructs the original location from\ngradients. Furthermore, the absence of priors in attacks on spatiotemporal data\nhas hindered the accurate reconstruction of real client data. To address this\nlimitation, we propose ST-GIA+, which utilizes an auxiliary language model to\nguide the search for potential locations, thereby successfully reconstructing\nthe original data from gradients. In addition, we design an adaptive defense\nstrategy to mitigate gradient inversion attacks in spatiotemporal federated\nlearning. By dynamically adjusting the perturbation levels, we can offer\ntailored protection for varying rounds of training data, thereby achieving a\nbetter trade-off between privacy and utility than current state-of-the-art\nmethods. Through intensive experimental analysis on three real-world datasets,\nwe reveal that the proposed defense strategy can well preserve the utility of\nspatiotemporal federated learning with effective security protection."
    },
    {
        "date": "2024-10",
        "title": "Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based on Nonlinear Feature Extraction and Intrinsic Correlation",
        "author": "Pei Liu, Nanfang Zheng, Yiqun Li, Junlan Chen, and Ziyuan Pu",
        "link": "http://arxiv.org/abs/2410.15814v1",
        "abstract": "With the development of AI-assisted driving, numerous methods have emerged\nfor ego-vehicle 3D perception tasks, but there has been limited research on\nroadside perception. With its ability to provide a global view and a broader\nsensing range, the roadside perspective is worth developing. LiDAR provides\nprecise three-dimensional spatial information, while cameras offer semantic\ninformation. These two modalities are complementary in 3D detection. However,\nadding camera data does not increase accuracy in some studies since the\ninformation extraction and fusion procedure is not sufficiently reliable.\nRecently, Kolmogorov-Arnold Networks (KANs) have been proposed as replacements\nfor MLPs, which are better suited for high-dimensional, complex data. Both the\ncamera and the LiDAR provide high-dimensional information, and employing KANs\nshould enhance the extraction of valuable features to produce better fusion\noutcomes. This paper proposes Kaninfradet3D, which optimizes the feature\nextraction and fusion modules. To extract features from complex\nhigh-dimensional data, the model's encoder and fuser modules were improved\nusing KAN Layers. Cross-attention was applied to enhance feature fusion, and\nvisual comparisons verified that camera features were more evenly integrated.\nThis addressed the issue of camera features being abnormally concentrated,\nnegatively impacting fusion. Compared to the benchmark, our approach shows\nimprovements of +9.87 mAP and +10.64 mAP in the two viewpoints of the TUMTraf\nIntersection Dataset and an improvement of +1.40 mAP in the roadside end of the\nTUMTraf V2X Cooperative Perception Dataset. The results indicate that\nKaninfradet3D can effectively fuse features, demonstrating the potential of\napplying KANs in roadside perception tasks."
    },
    {
        "date": "2024-10",
        "title": "Efficient Model Extraction via Boundary Sampling",
        "author": "Maor Biton Dor, and Yisroel Mirsky",
        "link": "http://arxiv.org/abs/2410.15429v1",
        "abstract": "This paper introduces a novel data-free model extraction attack that\nsignificantly advances the current state-of-the-art in terms of efficiency,\naccuracy, and effectiveness. Traditional black-box methods rely on using the\nvictim's model as an oracle to label a vast number of samples within\nhigh-confidence areas. This approach not only requires an extensive number of\nqueries but also results in a less accurate and less transferable model. In\ncontrast, our method innovates by focusing on sampling low-confidence areas\n(along the decision boundaries) and employing an evolutionary algorithm to\noptimize the sampling process. These novel contributions allow for a dramatic\nreduction in the number of queries needed by the attacker by a factor of 10x to\n600x while simultaneously improving the accuracy of the stolen model. Moreover,\nour approach improves boundary alignment, resulting in better transferability\nof adversarial examples from the stolen model to the victim's model (increasing\nthe attack success rate from 60\\% to 82\\% on average). Finally, we accomplish\nall of this with a strict black-box assumption on the victim, with no knowledge\nof the target's architecture or dataset.\n  We demonstrate our attack on three datasets with increasingly larger\nresolutions and compare our performance to four state-of-the-art model\nextraction attacks."
    },
    {
        "date": "2024-10",
        "title": "Transit Pulse: Utilizing Social Media as a Source for Customer Feedback and Information Extraction with Large Language Model",
        "author": "Jiahao Wang, and Amer Shalaby",
        "link": "http://arxiv.org/abs/2410.15016v1",
        "abstract": "Users of the transit system flood social networks daily with messages that\ncontain valuable insights crucial for improving service quality. These posts\nhelp transit agencies quickly identify emerging issues. Parsing topics and\nsentiments is key to gaining comprehensive insights to foster service\nexcellence. However, the volume of messages makes manual analysis impractical,\nand standard NLP techniques like Term Frequency-Inverse Document Frequency\n(TF-IDF) fall short in nuanced interpretation. Traditional sentiment analysis\nseparates topics and sentiments before integrating them, often missing the\ninteraction between them. This incremental approach complicates classification\nand reduces analytical productivity. To address these challenges, we propose a\nnovel approach to extracting and analyzing transit-related information,\nincluding sentiment and sarcasm detection, identification of unusual system\nproblems, and location data from social media. Our method employs Large\nLanguage Models (LLM), specifically Llama 3, for a streamlined analysis free\nfrom pre-established topic labels. To enhance the model's domain-specific\nknowledge, we utilize Retrieval-Augmented Generation (RAG), integrating\nexternal knowledge sources into the information extraction pipeline. We\nvalidated our method through extensive experiments comparing its performance\nwith traditional NLP approaches on user tweet data from the real world transit\nsystem. Our results demonstrate the potential of LLMs to transform social media\ndata analysis in the public transit domain, providing actionable insights and\nenhancing transit agencies' responsiveness by extracting a broader range of\ninformation."
    },
    {
        "date": "2024-10",
        "title": "Few-Shot Joint Multimodal Entity-Relation Extraction via Knowledge-Enhanced Cross-modal Prompt Model",
        "author": "Li Yuan, Yi Cai, and Junsheng Huang",
        "link": "http://arxiv.org/abs/2410.14225v2",
        "abstract": "Joint Multimodal Entity-Relation Extraction (JMERE) is a challenging task\nthat aims to extract entities and their relations from text-image pairs in\nsocial media posts. Existing methods for JMERE require large amounts of labeled\ndata. However, gathering and annotating fine-grained multimodal data for JMERE\nposes significant challenges. Initially, we construct diverse and comprehensive\nmultimodal few-shot datasets fitted to the original data distribution. To\naddress the insufficient information in the few-shot setting, we introduce the\n\\textbf{K}nowledge-\\textbf{E}nhanced \\textbf{C}ross-modal \\textbf{P}rompt\n\\textbf{M}odel (KECPM) for JMERE. This method can effectively address the\nproblem of insufficient information in the few-shot setting by guiding a large\nlanguage model to generate supplementary background knowledge. Our proposed\nmethod comprises two stages: (1) a knowledge ingestion stage that dynamically\nformulates prompts based on semantic similarity guide ChatGPT generating\nrelevant knowledge and employs self-reflection to refine the knowledge; (2) a\nknowledge-enhanced language model stage that merges the auxiliary knowledge\nwith the original input and utilizes a transformer-based model to align with\nJMERE's required output format. We extensively evaluate our approach on a\nfew-shot dataset derived from the JMERE dataset, demonstrating its superiority\nover strong baselines in terms of both micro and macro F$_1$ scores.\nAdditionally, we present qualitative analyses and case studies to elucidate the\neffectiveness of our model."
    },
    {
        "date": "2024-10",
        "title": "Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models",
        "author": "Tong Liu, and Hadi Meidani",
        "link": "http://arxiv.org/abs/2410.13051v1",
        "abstract": "Supply chain networks are critical to the operational efficiency of\nindustries, yet their increasing complexity presents significant challenges in\nmapping relationships and identifying the roles of various entities.\nTraditional methods for constructing supply chain networks rely heavily on\nstructured datasets and manual data collection, limiting their scope and\nefficiency. In contrast, recent advancements in Natural Language Processing\n(NLP) and large language models (LLMs) offer new opportunities for discovering\nand analyzing supply chain networks using unstructured text data. This paper\nproposes a novel approach that leverages LLMs to extract and process raw\ntextual information from publicly available sources to construct a\ncomprehensive supply chain graph. We focus on the civil engineering sector as a\ncase study, demonstrating how LLMs can uncover hidden relationships among\ncompanies, projects, and other entities. Additionally, we fine-tune an LLM to\nclassify entities within the supply chain graph, providing detailed insights\ninto their roles and relationships. The results show that domain-specific\nfine-tuning improves classification accuracy, highlighting the potential of\nLLMs for industry-specific supply chain analysis. Our contributions include the\ndevelopment of a supply chain graph for the civil engineering sector, as well\nas a fine-tuned LLM model that enhances entity classification and understanding\nof supply chain networks."
    },
    {
        "date": "2024-10",
        "title": "CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment",
        "author": "Qinfeng Li, Yangfan Xie, Tianyu Du, Zhiqiang Shen, Zhenghan Qin, Hao Peng, Xinkui Zhao, Xianwei Zhu, Jianwei Yin, and Xuhong Zhang",
        "link": "http://arxiv.org/abs/2410.13903v1",
        "abstract": "Proprietary large language models (LLMs) demonstrate exceptional\ngeneralization ability across various tasks. Additionally, deploying LLMs on\nedge devices is trending for efficiency and privacy reasons. However, edge\ndeployment of proprietary LLMs introduces new security threats: attackers who\nobtain an edge-deployed LLM can easily use it as a base model for various tasks\ndue to its high generalization ability, which we call foundational capability\nstealing. Unfortunately, existing model protection mechanisms are often\ntask-specific and fail to protect general-purpose LLMs, as they mainly focus on\nprotecting task-related parameters using trusted execution environments (TEEs).\nAlthough some recent TEE-based methods are able to protect the overall model\nparameters in a computation-efficient way, they still suffer from prohibitive\ncommunication costs between TEE and CPU/GPU, making it impractical to deploy\nfor edge LLMs. To protect the foundational capabilities of edge LLMs, we\npropose CoreGuard, a computation- and communication-efficient model protection\napproach against model stealing on edge devices. The core component of\nCoreGuard is a lightweight and propagative authorization module residing in\nTEE. Extensive experiments show that CoreGuard achieves the same security\nprotection as the black-box security guarantees with negligible overhead."
    },
    {
        "date": "2024-10",
        "title": "Identity-Focused Inference and Extraction Attacks on Diffusion Models",
        "author": "Jayneel Vora, Aditya Krishnan, Nader Bouacida, Prabhu RV Shankar, and Prasant Mohapatra",
        "link": "http://arxiv.org/abs/2410.10177v1",
        "abstract": "The increasing reliance on diffusion models for generating synthetic images\nhas amplified concerns about the unauthorized use of personal data,\nparticularly facial images, in model training. In this paper, we introduce a\nnovel identity inference framework to hold model owners accountable for\nincluding individuals' identities in their training data. Our approach moves\nbeyond traditional membership inference attacks by focusing on identity-level\ninference, providing a new perspective on data privacy violations. Through\ncomprehensive evaluations on two facial image datasets, Labeled Faces in the\nWild (LFW) and CelebA, our experiments demonstrate that the proposed membership\ninference attack surpasses baseline methods, achieving an attack success rate\nof up to 89% and an AUC-ROC of 0.91, while the identity inference attack\nattains 92% on LDM models trained on LFW, and the data extraction attack\nachieves 91.6% accuracy on DDPMs, validating the effectiveness of our approach\nacross diffusion models."
    },
    {
        "date": "2024-10",
        "title": "Enabling Advanced Land Cover Analytics: An Integrated Data Extraction Pipeline for Predictive Modeling with the Dynamic World Dataset",
        "author": "Victor Radermecker, Andrea Zanon, Nancy Thomas, Annita Vapsi, Saba Rahimi, Rama Ramakrishnan, and Daniel Borrajo",
        "link": "http://arxiv.org/abs/2410.09135v2",
        "abstract": "Understanding land cover holds considerable potential for a myriad of\npractical applications, particularly as data accessibility transitions from\nbeing exclusive to governmental and commercial entities to now including the\nbroader research community. Nevertheless, although the data is accessible to\nany community member interested in exploration, there exists a formidable\nlearning curve and no standardized process for accessing, pre-processing, and\nleveraging the data for subsequent tasks. In this study, we democratize this\ndata by presenting a flexible and efficient end to end pipeline for working\nwith the Dynamic World dataset, a cutting-edge near-real-time land use/land\ncover (LULC) dataset. This includes a pre-processing and representation\nframework which tackles noise removal, efficient extraction of large amounts of\ndata, and re-representation of LULC data in a format well suited for several\ndownstream tasks. To demonstrate the power of our pipeline, we use it to\nextract data for an urbanization prediction problem and build a suite of\nmachine learning models with excellent performance. This task is easily\ngeneralizable to the prediction of any type of land cover and our pipeline is\nalso compatible with a series of other downstream tasks."
    },
    {
        "date": "2024-10",
        "title": "Contrastive Learning to Fine-Tune Feature Extraction Models for the Visual Cortex",
        "author": "Alex Mulrooney, and Austin J. Brockmeier",
        "link": "http://arxiv.org/abs/2410.06067v1",
        "abstract": "Predicting the neural response to natural images in the visual cortex\nrequires extracting relevant features from the images and relating those\nfeature to the observed responses. In this work, we optimize the feature\nextraction in order to maximize the information shared between the image\nfeatures and the neural response across voxels in a given region of interest\n(ROI) extracted from the BOLD signal measured by fMRI. We adapt contrastive\nlearning (CL) to fine-tune a convolutional neural network, which was pretrained\nfor image classification, such that a mapping of a given image's features are\nmore similar to the corresponding fMRI response than to the responses to other\nimages. We exploit the recently released Natural Scenes Dataset (Allen et al.,\n2022) as organized for the Algonauts Project (Gifford et al., 2023), which\ncontains the high-resolution fMRI responses of eight subjects to tens of\nthousands of naturalistic images. We show that CL fine-tuning creates feature\nextraction models that enable higher encoding accuracy in early visual ROIs as\ncompared to both the pretrained network and a baseline approach that uses a\nregression loss at the output of the network to tune it for fMRI response\nencoding. We investigate inter-subject transfer of the CL fine-tuned models,\nincluding subjects from another, lower-resolution dataset (Gong et al., 2023).\nWe also pool subjects for fine-tuning to further improve the encoding\nperformance. Finally, we examine the performance of the fine-tuned models on\ncommon image classification tasks, explore the landscape of ROI-specific models\nby applying dimensionality reduction on the Bhattacharya dissimilarity matrix\ncreated using the predictions on those tasks (Mao et al., 2024), and\ninvestigate lateralization of the processing for early visual ROIs using\nsalience maps of the classifiers built on the CL-tuned models."
    },
    {
        "date": "2024-10",
        "title": "Polynomial Time Cryptanalytic Extraction of Deep Neural Networks in the Hard-Label Setting",
        "author": "Nicholas Carlini, Jorge Ch\u00e1vez-Saab, Anna Hambitzer, Francisco Rodr\u00edguez-Henr\u00edquez, and Adi Shamir",
        "link": "http://arxiv.org/abs/2410.05750v1",
        "abstract": "Deep neural networks (DNNs) are valuable assets, yet their public\naccessibility raises security concerns about parameter extraction by malicious\nactors. Recent work by Carlini et al. (crypto'20) and Canales-Mart\\'inez et al.\n(eurocrypt'24) has drawn parallels between this issue and block cipher key\nextraction via chosen plaintext attacks. Leveraging differential cryptanalysis,\nthey demonstrated that all the weights and biases of black-box ReLU-based DNNs\ncould be inferred using a polynomial number of queries and computational time.\nHowever, their attacks relied on the availability of the exact numeric value of\noutput logits, which allowed the calculation of their derivatives. To overcome\nthis limitation, Chen et al. (asiacrypt'24) tackled the more realistic\nhard-label scenario, where only the final classification label (e.g., \"dog\" or\n\"car\") is accessible to the attacker. They proposed an extraction method\nrequiring a polynomial number of queries but an exponential execution time. In\naddition, their approach was applicable only to a restricted set of\narchitectures, could deal only with binary classifiers, and was demonstrated\nonly on tiny neural networks with up to four neurons split among up to two\nhidden layers. This paper introduces new techniques that, for the first time,\nachieve cryptanalytic extraction of DNN parameters in the most challenging\nhard-label setting, using both a polynomial number of queries and polynomial\ntime. We validate our approach by extracting nearly one million parameters from\na DNN trained on the CIFAR-10 dataset, comprising 832 neurons in four hidden\nlayers. Our results reveal the surprising fact that all the weights of a\nReLU-based DNN can be efficiently determined by analyzing only the geometric\nshape of its decision boundaries."
    },
    {
        "date": "2024-10",
        "title": "Multiscale Latent Diffusion Model for Enhanced Feature Extraction from Medical Images",
        "author": "Rabeya Tus Sadia, Jie Zhang, and Jin Chen",
        "link": "http://arxiv.org/abs/2410.04000v3",
        "abstract": "Various imaging modalities are used in patient diagnosis, each offering\nunique advantages and valuable insights into anatomy and pathology. Computed\nTomography (CT) is crucial in diagnostics, providing high-resolution images for\nprecise internal organ visualization. CT's ability to detect subtle tissue\nvariations is vital for diagnosing diseases like lung cancer, enabling early\ndetection and accurate tumor assessment. However, variations in CT scanner\nmodels and acquisition protocols introduce significant variability in the\nextracted radiomic features, even when imaging the same patient. This\nvariability poses considerable challenges for downstream research and clinical\nanalysis, which depend on consistent and reliable feature extraction. Current\nmethods for medical image feature extraction, often based on supervised\nlearning approaches, including GAN-based models, face limitations in\ngeneralizing across different imaging environments. In response to these\nchallenges, we propose LTDiff++, a multiscale latent diffusion model designed\nto enhance feature extraction in medical imaging. The model addresses\nvariability by standardizing non-uniform distributions in the latent space,\nimproving feature consistency. LTDiff++ utilizes a UNet++ encoder-decoder\narchitecture coupled with a conditional Denoising Diffusion Probabilistic Model\n(DDPM) at the latent bottleneck to achieve robust feature extraction and\nstandardization. Extensive empirical evaluations on both patient and phantom CT\ndatasets demonstrate significant improvements in image standardization, with\nhigher Concordance Correlation Coefficients (CCC) across multiple radiomic\nfeature categories. Through these advancements, LTDiff++ represents a promising\nsolution for overcoming the inherent variability in medical imaging data,\noffering improved reliability and accuracy in feature extraction processes."
    },
    {
        "date": "2024-10",
        "title": "Leveraging Model Guidance to Extract Training Data from Personalized Diffusion Models",
        "author": "Xiaoyu Wu, Jiaru Zhang, and Zhiwei Steven Wu",
        "link": "http://arxiv.org/abs/2410.03039v2",
        "abstract": "Diffusion Models (DMs) have become powerful image generation tools,\nespecially for few-shot fine-tuning where a pretrained DM is fine-tuned on a\nsmall image set to capture specific styles or objects. Many people upload these\npersonalized checkpoints online, fostering communities such as Civitai and\nHuggingFace. However, model owners may overlook the data leakage risks when\nreleasing fine-tuned checkpoints. Moreover, concerns regarding copyright\nviolations arise when unauthorized data is used during fine-tuning. In this\npaper, we ask: \"Can training data be extracted from these fine-tuned DMs shared\nonline?\" A successful extraction would present not only data leakage threats\nbut also offer tangible evidence of copyright infringement. To answer this, we\npropose FineXtract, a framework for extracting fine-tuning data. Our method\napproximates fine-tuning as a gradual shift in the model's learned distribution\n-- from the original pretrained DM toward the fine-tuning data. By\nextrapolating the models before and after fine-tuning, we guide the generation\ntoward high-probability regions within the fine-tuned data distribution. We\nthen apply a clustering algorithm to extract the most probable images from\nthose generated using this extrapolated guidance. Experiments on DMs fine-tuned\nwith datasets including WikiArt, DreamBooth, and real-world checkpoints posted\nonline validate the effectiveness of our method, extracting about 20% of\nfine-tuning data in most cases. The code is available\nhttps://github.com/Nicholas0228/FineXtract."
    },
    {
        "date": "2024-10",
        "title": "SIDE: Surrogate Conditional Data Extraction from Diffusion Models",
        "author": "Yunhao Chen, Shujie Wang, Difan Zou, and Xingjun Ma",
        "link": "http://arxiv.org/abs/2410.02467v7",
        "abstract": "As diffusion probabilistic models (DPMs) become central to Generative AI\n(GenAI), understanding their memorization behavior is essential for evaluating\nrisks such as data leakage, copyright infringement, and trustworthiness. While\nprior research finds conditional DPMs highly susceptible to data extraction\nattacks using explicit prompts, unconditional models are often assumed to be\nsafe. We challenge this view by introducing \\textbf{Surrogate condItional Data\nExtraction (SIDE)}, a general framework that constructs data-driven surrogate\nconditions to enable targeted extraction from any DPM. Through extensive\nexperiments on CIFAR-10, CelebA, ImageNet, and LAION-5B, we show that SIDE can\nsuccessfully extract training data from so-called safe unconditional models,\noutperforming baseline attacks even on conditional models. Complementing these\nfindings, we present a unified theoretical framework based on informative\nlabels, demonstrating that all forms of conditioning, explicit or surrogate,\namplify memorization. Our work redefines the threat landscape for DPMs,\nestablishing precise conditioning as a fundamental vulnerability and setting a\nnew, stronger benchmark for model privacy evaluation."
    },
    {
        "date": "2024-10",
        "title": "A Novel Feature Extraction Model for the Detection of Plant Disease from Leaf Images in Low Computational Devices",
        "author": "Rikathi Pal, Anik Basu Bhaumik, Arpan Murmu, Sanoar Hossain, Biswajit Maity, and Soumya Sen",
        "link": "http://arxiv.org/abs/2410.01854v1",
        "abstract": "Diseases in plants cause significant danger to productive and secure\nagriculture. Plant diseases can be detected early and accurately, reducing crop\nlosses and pesticide use. Traditional methods of plant disease identification,\non the other hand, are generally time-consuming and require professional\nexpertise. It would be beneficial to the farmers if they could detect the\ndisease quickly by taking images of the leaf directly. This will be a\ntime-saving process and they can take remedial actions immediately. To achieve\nthis a novel feature extraction approach for detecting tomato plant illnesses\nfrom leaf photos using low-cost computing systems such as mobile phones is\nproposed in this study. The proposed approach integrates various types of Deep\nLearning techniques to extract robust and discriminative features from leaf\nimages. After the proposed feature extraction comparisons have been made on\nfive cutting-edge deep learning models: AlexNet, ResNet50, VGG16, VGG19, and\nMobileNet. The dataset contains 10,000 leaf photos from ten classes of tomato\nillnesses and one class of healthy leaves. Experimental findings demonstrate\nthat AlexNet has an accuracy score of 87%, with the benefit of being quick and\nlightweight, making it appropriate for use on embedded systems and other\nlow-processing devices like smartphones."
    },
    {
        "date": "2024-10",
        "title": "Preserving Generalization of Language models in Few-shot Continual Relation Extraction",
        "author": "Quyen Tran, Nguyen Xuan Thanh, Nguyen Hoang Anh, Nam Le Hai, Trung Le, Linh Van Ngo, and Thien Huu Nguyen",
        "link": "http://arxiv.org/abs/2410.00334v1",
        "abstract": "Few-shot Continual Relations Extraction (FCRE) is an emerging and dynamic\narea of study where models can sequentially integrate knowledge from new\nrelations with limited labeled data while circumventing catastrophic forgetting\nand preserving prior knowledge from pre-trained backbones. In this work, we\nintroduce a novel method that leverages often-discarded language model heads.\nBy employing these components via a mutual information maximization strategy,\nour approach helps maintain prior knowledge from the pre-trained backbone and\nstrategically aligns the primary classification head, thereby enhancing model\nperformance. Furthermore, we explore the potential of Large Language Models\n(LLMs), renowned for their wealth of knowledge, in addressing FCRE challenges.\nOur comprehensive experimental results underscore the efficacy of the proposed\nmethod and offer valuable insights for future work."
    },
    {
        "date": "2024-09",
        "title": "Towards Robust Extractive Question Answering Models: Rethinking the Training Methodology",
        "author": "Son Quoc Tran, and Matt Kretchmar",
        "link": "http://arxiv.org/abs/2409.19766v1",
        "abstract": "This paper proposes a novel training method to improve the robustness of\nExtractive Question Answering (EQA) models. Previous research has shown that\nexisting models, when trained on EQA datasets that include unanswerable\nquestions, demonstrate a significant lack of robustness against distribution\nshifts and adversarial attacks. Despite this, the inclusion of unanswerable\nquestions in EQA training datasets is essential for ensuring real-world\nreliability. Our proposed training method includes a novel loss function for\nthe EQA problem and challenges an implicit assumption present in numerous EQA\ndatasets. Models trained with our method maintain in-domain performance while\nachieving a notable improvement on out-of-domain datasets. This results in an\noverall F1 score improvement of 5.7 across all testing sets. Furthermore, our\nmodels exhibit significantly enhanced robustness against two types of\nadversarial attacks, with a performance decrease of only about a third compared\nto the default models."
    },
    {
        "date": "2024-09",
        "title": "INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning",
        "author": "Pablo Romero, Lifeng Han, and Goran Nenadic",
        "link": "http://arxiv.org/abs/2409.19467v2",
        "abstract": "Medication Extraction and Mining play an important role in healthcare NLP\nresearch due to its practical applications in hospital settings, such as their\nmapping into standard clinical knowledge bases (SNOMED-CT, BNF, etc.). In this\nwork, we investigate state-of-the-art LLMs in text mining tasks on medications\nand their related attributes such as dosage, route, strength, and adverse\neffects. In addition, we explore different ensemble learning methods\n(\\textsc{Stack-Ensemble} and \\textsc{Voting-Ensemble}) to augment the model\nperformances from individual LLMs. Our ensemble learning result demonstrated\nbetter performances than individually fine-tuned base models BERT, RoBERTa,\nRoBERTa-L, BioBERT, BioClinicalBERT, BioMedRoBERTa, ClinicalBERT, and\nPubMedBERT across general and specific domains. Finally, we build up an entity\nlinking function to map extracted medical terminologies into the SNOMED-CT\ncodes and the British National Formulary (BNF) codes, which are further mapped\nto the Dictionary of Medicines and Devices (dm+d), and ICD. Our model's toolkit\nand desktop applications are publicly available (at\n\\url{https://github.com/HECTA-UoM/ensemble-NER})."
    },
    {
        "date": "2024-09",
        "title": "Feature-to-Image Data Augmentation: Improving Model Feature Extraction with Cluster-Guided Synthetic Samples",
        "author": "Yasaman Haghbin, Hadi Moradi, and Reshad Hosseini",
        "link": "http://arxiv.org/abs/2409.17685v2",
        "abstract": "One of the growing trends in machine learning is the use of data generation\ntechniques, since the performance of machine learning models is dependent on\nthe quantity of the training dataset. However, in many real-world applications,\nparticularly in medical and low-resource domains, collecting large datasets is\nchallenging due to resource constraints, which leads to overfitting and poor\ngeneralization. This study introduces FICAug, a novel feature-to-image data\naugmentation framework designed to improve model generalization under limited\ndata conditions by generating structured synthetic samples.\n  FICAug first operates in the feature space, where original data are clustered\nusing the k-means algorithm. Within pure-label clusters, synthetic data are\ngenerated through Gaussian sampling to increase diversity while maintaining\nlabel consistency. These synthetic features are then projected back into the\nimage domain using a generative neural network, and a convolutional neural\nnetwork is trained on the reconstructed images to learn enhanced\nrepresentations.\n  Experimental results demonstrate that FICAug significantly improves\nclassification accuracy. In feature space, it achieved a cross-validation\naccuracy of 84.09%, while training a ResNet-18 model on the reconstructed\nimages further boosted performance to 88.63%, illustrating the effectiveness of\nthe proposed framework in extracting new and task-relevant features."
    },
    {
        "date": "2024-09",
        "title": "Semi-strong Efficient Market of Bitcoin and Twitter: an Analysis of Semantic Vector Spaces of Extracted Keywords and Light Gradient Boosting Machine Models",
        "author": "Fang Wang, and Marko Gacesa",
        "link": "http://arxiv.org/abs/2409.15988v1",
        "abstract": "This study extends the examination of the Efficient-Market Hypothesis in\nBitcoin market during a five year fluctuation period, from September 1 2017 to\nSeptember 1 2022, by analyzing 28,739,514 qualified tweets containing the\ntargeted topic \"Bitcoin\". Unlike previous studies, we extracted fundamental\nkeywords as an informative proxy for carrying out the study of the EMH in the\nBitcoin market rather than focusing on sentiment analysis, information volume,\nor price data. We tested market efficiency in hourly, 4-hourly, and daily time\nperiods to understand the speed and accuracy of market reactions towards the\ninformation within different thresholds. A sequence of machine learning methods\nand textual analyses were used, including measurements of distances of semantic\nvector spaces of information, keywords extraction and encoding model, and Light\nGradient Boosting Machine (LGBM) classifiers. Our results suggest that 78.06%\n(83.08%), 84.63% (87.77%), and 94.03% (94.60%) of hourly, 4-hourly, and daily\nbullish (bearish) market movements can be attributed to public information\nwithin organic tweets."
    },
    {
        "date": "2024-09",
        "title": "ASTE Transformer Modelling Dependencies in Aspect-Sentiment Triplet Extraction",
        "author": "Iwo Naglik, and Mateusz Lango",
        "link": "http://arxiv.org/abs/2409.15202v2",
        "abstract": "Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of\naspect-based sentiment analysis that consists in extracting (aspect phrase,\nopinion phrase, sentiment polarity) triples from a given sentence. Recent\nstate-of-the-art methods approach this task by first extracting all possible\ntext spans from a given text, then filtering the potential aspect and opinion\nphrases with a classifier, and finally considering all their pairs with another\nclassifier that additionally assigns sentiment polarity to them. Although\nseveral variations of the above scheme have been proposed, the common feature\nis that the final result is constructed by a sequence of independent classifier\ndecisions. This hinders the exploitation of dependencies between extracted\nphrases and prevents the use of knowledge about the interrelationships between\nclassifier predictions to improve performance. In this paper, we propose a new\nASTE approach consisting of three transformer-inspired layers, which enables\nthe modelling of dependencies both between phrases and between the final\nclassifier decisions. Experimental results show that the method achieves higher\nperformance in terms of F1 measure than other methods studied on popular\nbenchmarks. In addition, we show that a simple pre-training technique further\nimproves the performance of the model."
    },
    {
        "date": "2024-09",
        "title": "Efficient and Effective Model Extraction",
        "author": "Hongyu Zhu, Wentao Hu, Sichu Liang, Fangqi Li, Wenwen Wang, and Shilin Wang",
        "link": "http://arxiv.org/abs/2409.14122v2",
        "abstract": "Model extraction aims to create a functionally similar copy from a machine\nlearning as a service (MLaaS) API with minimal overhead, typically for illicit\nprofit or as a precursor to further attacks, posing a significant threat to the\nMLaaS ecosystem. However, recent studies have shown that model extraction is\nhighly inefficient, particularly when the target task distribution is\nunavailable. In such cases, even substantially increasing the attack budget\nfails to produce a sufficiently similar replica, reducing the adversary's\nmotivation to pursue extraction attacks. In this paper, we revisit the\nelementary design choices throughout the extraction lifecycle. We propose an\nembarrassingly simple yet dramatically effective algorithm, Efficient and\nEffective Model Extraction (E3), focusing on both query preparation and\ntraining routine. E3 achieves superior generalization compared to\nstate-of-the-art methods while minimizing computational costs. For instance,\nwith only 0.005 times the query budget and less than 0.2 times the runtime, E3\noutperforms classical generative model based data-free model extraction by an\nabsolute accuracy improvement of over 50% on CIFAR-10. Our findings underscore\nthe persistent threat posed by model extraction and suggest that it could serve\nas a valuable benchmarking algorithm for future security evaluations."
    },
    {
        "date": "2024-09",
        "title": "Hard-Label Cryptanalytic Extraction of Neural Network Models",
        "author": "Yi Chen, Xiaoyang Dong, Jian Guo, Yantian Shen, Anyu Wang, and Xiaoyun Wang",
        "link": "http://arxiv.org/abs/2409.11646v1",
        "abstract": "The machine learning problem of extracting neural network parameters has been\nproposed for nearly three decades. Functionally equivalent extraction is a\ncrucial goal for research on this problem. When the adversary has access to the\nraw output of neural networks, various attacks, including those presented at\nCRYPTO 2020 and EUROCRYPT 2024, have successfully achieved this goal. However,\nthis goal is not achieved when neural networks operate under a hard-label\nsetting where the raw output is inaccessible.\n  In this paper, we propose the first attack that theoretically achieves\nfunctionally equivalent extraction under the hard-label setting, which applies\nto ReLU neural networks. The effectiveness of our attack is validated through\npractical experiments on a wide range of ReLU neural networks, including neural\nnetworks trained on two real benchmarking datasets (MNIST, CIFAR10) widely used\nin computer vision. For a neural network consisting of $10^5$ parameters, our\nattack only requires several hours on a single core."
    },
    {
        "date": "2024-09",
        "title": "CaBaGe: Data-Free Model Extraction using ClAss BAlanced Generator Ensemble",
        "author": "Jonathan Rosenthal, Shanchao Liang, Kevin Zhang, and Lin Tan",
        "link": "http://arxiv.org/abs/2409.10643v1",
        "abstract": "Machine Learning as a Service (MLaaS) is often provided as a pay-per-query,\nblack-box system to clients. Such a black-box approach not only hinders open\nreplication, validation, and interpretation of model results, but also makes it\nharder for white-hat researchers to identify vulnerabilities in the MLaaS\nsystems. Model extraction is a promising technique to address these challenges\nby reverse-engineering black-box models. Since training data is typically\nunavailable for MLaaS models, this paper focuses on the realistic version of\nit: data-free model extraction. We propose a data-free model extraction\napproach, CaBaGe, to achieve higher model extraction accuracy with a small\nnumber of queries. Our innovations include (1) a novel experience replay for\nfocusing on difficult training samples; (2) an ensemble of generators for\nsteadily producing diverse synthetic data; and (3) a selective filtering\nprocess for querying the victim model with harder, more balanced samples. In\naddition, we create a more realistic setting, for the first time, where the\nattacker has no knowledge of the number of classes in the victim training data,\nand create a solution to learn the number of classes on the fly. Our evaluation\nshows that CaBaGe outperforms existing techniques on seven datasets -- MNIST,\nFMNIST, SVHN, CIFAR-10, CIFAR-100, ImageNet-subset, and Tiny ImageNet -- with\nan accuracy improvement of the extracted models by up to 43.13%. Furthermore,\nthe number of queries required to extract a clone model matching the final\naccuracy of prior work is reduced by up to 75.7%."
    },
    {
        "date": "2024-09",
        "title": "Language Models and Retrieval Augmented Generation for Automated Structured Data Extraction from Diagnostic Reports",
        "author": "Mohamed Sobhi Jabal, Pranav Warman, Jikai Zhang, Kartikeye Gupta, Ayush Jain, Maciej Mazurowski, Walter Wiggins, Kirti Magudia, and Evan Calabrese",
        "link": "http://arxiv.org/abs/2409.10576v2",
        "abstract": "Purpose: To develop and evaluate an automated system for extracting\nstructured clinical information from unstructured radiology and pathology\nreports using open-weights large language models (LMs) and retrieval augmented\ngeneration (RAG), and to assess the effects of model configuration variables on\nextraction performance. Methods and Materials: The study utilized two datasets:\n7,294 radiology reports annotated for Brain Tumor Reporting and Data System\n(BT-RADS) scores and 2,154 pathology reports annotated for isocitrate\ndehydrogenase (IDH) mutation status. An automated pipeline was developed to\nbenchmark the performance of various LMs and RAG configurations. The impact of\nmodel size, quantization, prompting strategies, output formatting, and\ninference parameters was systematically evaluated. Results: The best performing\nmodels achieved over 98% accuracy in extracting BT-RADS scores from radiology\nreports and over 90% for IDH mutation status extraction from pathology reports.\nThe top model being medical fine-tuned llama3. Larger, newer, and domain\nfine-tuned models consistently outperformed older and smaller models. Model\nquantization had minimal impact on performance. Few-shot prompting\nsignificantly improved accuracy. RAG improved performance for complex pathology\nreports but not for shorter radiology reports. Conclusions: Open LMs\ndemonstrate significant potential for automated extraction of structured\nclinical data from unstructured clinical reports with local privacy-preserving\napplication. Careful model selection, prompt engineering, and semi-automated\noptimization using annotated data are critical for optimal performance. These\napproaches could be reliable enough for practical use in research workflows,\nhighlighting the potential for human-machine collaboration in healthcare data\nextraction."
    },
    {
        "date": "2024-09",
        "title": "TSELM: Target Speaker Extraction using Discrete Tokens and Language Models",
        "author": "Beilong Tang, Bang Zeng, and Ming Li",
        "link": "http://arxiv.org/abs/2409.07841v3",
        "abstract": "We propose TSELM, a novel target speaker extraction network that leverages\ndiscrete tokens and language models. TSELM utilizes multiple discretized layers\nfrom WavLM as input tokens and incorporates cross-attention mechanisms to\nintegrate target speaker information. Language models are employed to capture\nthe sequence dependencies, while a scalable HiFi-GAN is used to reconstruct the\naudio from the tokens. By applying a cross-entropy loss, TSELM models the\nprobability distribution of output tokens, thus converting the complex\nregression problem of audio generation into a classification task. Experimental\nresults show that TSELM achieves excellent results in speech quality and\ncomparable results in speech intelligibility."
    },
    {
        "date": "2024-09",
        "title": "\"Yes, My LoRD.\" Guiding Language Model Extraction with Locality Reinforced Distillation",
        "author": "Zi Liang, Qingqing Ye, Yanyun Wang, Sen Zhang, Yaxin Xiao, Ronghua Li, Jianliang Xu, and Haibo Hu",
        "link": "http://arxiv.org/abs/2409.02718v3",
        "abstract": "Model extraction attacks (MEAs) on large language models (LLMs) have received\nincreasing attention in recent research. However, existing attack methods\ntypically adapt the extraction strategies originally developed for deep neural\nnetworks (DNNs). They neglect the underlying inconsistency between the training\ntasks of MEA and LLM alignment, leading to suboptimal attack performance. To\ntackle this issue, we propose Locality Reinforced Distillation (LoRD), a novel\nmodel extraction algorithm specifically designed for LLMs. In particular, LoRD\nemploys a newly defined policy-gradient-style training task that utilizes the\nresponses of victim model as the signal to guide the crafting of preference for\nthe local model. Theoretical analyses demonstrate that I) The convergence\nprocedure of LoRD in model extraction is consistent with the alignment\nprocedure of LLMs, and II) LoRD can reduce query complexity while mitigating\nwatermark protection through our exploration-based stealing. Extensive\nexperiments validate the superiority of our method in extracting various\nstate-of-the-art commercial LLMs. Our code is available at:\nhttps://github.com/liangzid/LoRD-MEA ."
    },
    {
        "date": "2024-09",
        "title": "AdaComp: Extractive Context Compression with Adaptive Predictor for Retrieval-Augmented Large Language Models",
        "author": "Qianchi Zhang, Hainan Zhang, Liang Pang, Hongwei Zheng, and Zhiming Zheng",
        "link": "http://arxiv.org/abs/2409.01579v1",
        "abstract": "Retrieved documents containing noise will hinder RAG from detecting answer\nclues and make the inference process slow and expensive. Therefore, context\ncompression is necessary to enhance its accuracy and efficiency. Existing\ncontext compression methods use extractive or generative models to retain the\nmost query-relevant sentences or apply the information bottleneck theory to\npreserve sufficient information. However, these methods may face issues such as\nover-compression or high computational costs. We observe that the retriever\noften ranks relevant documents at the top, but the exact number of documents\nneeded to answer the query is uncertain due to the impact of query complexity\nand retrieval quality: complex queries like multi-hop questions may require\nretaining more documents than simpler queries, and a low-quality retrieval may\nneed to rely on more documents to generate accurate outputs. Therefore,\ndetermining the minimum number of required documents (compression rate) is\nstill a challenge for RAG. In this paper, we introduce AdaComp, a low-cost\nextractive context compression method that adaptively determines the\ncompression rate based on both query complexity and retrieval quality.\nSpecifically, we first annotate the minimum top-k documents necessary for the\nRAG system to answer the current query as the compression rate and then\nconstruct triplets of the query, retrieved documents, and its compression rate.\nThen, we use this triplet dataset to train a compression-rate predictor.\nExperiments on three QA datasets and one conversational Muiti-doc QA dataset\nshow that AdaComp significantly reduces inference costs while maintaining\nperformance nearly identical to uncompressed models, achieving a balance\nbetween efficiency and performance."
    },
    {
        "date": "2024-08",
        "title": "Extraction of Research Objectives, Machine Learning Model Names, and Dataset Names from Academic Papers and Analysis of Their Interrelationships Using LLM and Network Analysis",
        "author": "S. Nishio, H. Nonaka, N. Tsuchiya, A. Migita, Y. Banno, T. Hayashi, H. Sakaji, T. Sakumoto, and K. Watabe",
        "link": "http://arxiv.org/abs/2408.12097v1",
        "abstract": "Machine learning is widely utilized across various industries. Identifying\nthe appropriate machine learning models and datasets for specific tasks is\ncrucial for the effective industrial application of machine learning. However,\nthis requires expertise in both machine learning and the relevant domain,\nleading to a high learning cost. Therefore, research focused on extracting\ncombinations of tasks, machine learning models, and datasets from academic\npapers is critically important, as it can facilitate the automatic\nrecommendation of suitable methods. Conventional information extraction methods\nfrom academic papers have been limited to identifying machine learning models\nand other entities as named entities. To address this issue, this study\nproposes a methodology extracting tasks, machine learning methods, and dataset\nnames from scientific papers and analyzing the relationships between these\ninformation by using LLM, embedding model, and network clustering. The proposed\nmethod's expression extraction performance, when using Llama3, achieves an\nF-score exceeding 0.8 across various categories, confirming its practical\nutility. Benchmarking results on financial domain papers have demonstrated the\neffectiveness of this method, providing insights into the use of the latest\ndatasets, including those related to ESG (Environmental, Social, and\nGovernance) data."
    },
    {
        "date": "2024-08",
        "title": "JieHua Paintings Style Feature Extracting Model using Stable Diffusion with ControlNet",
        "author": "Yujia Gu, Haofeng Li, Xinyu Fang, Zihan Peng, and Yinan Peng",
        "link": "http://arxiv.org/abs/2408.11744v1",
        "abstract": "This study proposes a novel approach to extract stylistic features of Jiehua:\nthe utilization of the Fine-tuned Stable Diffusion Model with ControlNet\n(FSDMC) to refine depiction techniques from artists' Jiehua. The training data\nfor FSDMC is based on the opensource Jiehua artist's work collected from the\nInternet, which were subsequently manually constructed in the format of\n(Original Image, Canny Edge Features, Text Prompt). By employing the optimal\nhyperparameters identified in this paper, it was observed FSDMC outperforms\nCycleGAN, another mainstream style transfer model. FSDMC achieves FID of 3.27\non the dataset and also surpasses CycleGAN in terms of expert evaluation. This\nnot only demonstrates the model's high effectiveness in extracting Jiehua's\nstyle features, but also preserves the original pre-trained semantic\ninformation. The findings of this study suggest that the application of FSDMC\nwith appropriate hyperparameters can enhance the efficacy of the Stable\nDiffusion Model in the field of traditional art style migration tasks,\nparticularly within the context of Jiehua."
    },
    {
        "date": "2024-08",
        "title": "Extracting Sentence Embeddings from Pretrained Transformer Models",
        "author": "Lukas Stankevi\u010dius, and Mantas Luko\u0161evi\u010dius",
        "link": "http://arxiv.org/abs/2408.08073v2",
        "abstract": "Pre-trained transformer models shine in many natural language processing\ntasks and therefore are expected to bear the representation of the input\nsentence or text meaning. These sentence-level embeddings are also important in\nretrieval-augmented generation. But do commonly used plain averaging or prompt\ntemplates sufficiently capture and represent the underlying meaning? After\nproviding a comprehensive review of existing sentence embedding extraction and\nrefinement methods, we thoroughly test different combinations and our original\nextensions of the most promising ones on pretrained models. Namely, given 110 M\nparameters, BERT's hidden representations from multiple layers, and many\ntokens, we try diverse ways to extract optimal sentence embeddings. We test\nvarious token aggregation and representation post-processing techniques. We\nalso test multiple ways of using a general Wikitext dataset to complement\nBERT's sentence embeddings. All methods are tested on eight Semantic Textual\nSimilarity (STS), six short text clustering, and twelve classification tasks.\nWe also evaluate our representation-shaping techniques on other static models,\nincluding random token representations. Proposed representation extraction\nmethods improve the performance on STS and clustering tasks for all models\nconsidered. Very high improvements for static token-based models, especially\nrandom embeddings for STS tasks, almost reach the performance of BERT-derived\nrepresentations. Our work shows that the representation-shaping techniques\nsignificantly improve sentence embeddings extracted from BERT-based and simple\nbaseline models."
    },
    {
        "date": "2024-08",
        "title": "Automatic Feature Recognition and Dimensional Attributes Extraction From CAD Models for Hybrid Additive-Subtractive Manufacturing",
        "author": "Muhammad Tayyab Khan, Wenhe Feng, Lequn Chen, Ye Han Ng, Nicholas Yew Jin Tan, and Seung Ki Moon",
        "link": "http://arxiv.org/abs/2408.06891v2",
        "abstract": "The integration of Computer-Aided Design (CAD), Computer-Aided Process\nPlanning (CAPP), and Computer-Aided Manufacturing (CAM) plays a crucial role in\nmodern manufacturing, facilitating seamless transitions from digital designs to\nphysical products. However, a significant challenge within this integration is\nthe Automatic Feature Recognition (AFR) of CAD models, especially in the\ncontext of hybrid manufacturing that combines subtractive and additive\nmanufacturing processes. Traditional AFR methods, focused mainly on the\nidentification of subtractive (machined) features including holes, fillets,\nchamfers, pockets, and slots, fail to recognize features pertinent to additive\nmanufacturing. Furthermore, the traditional methods fall short in accurately\nextracting geometric dimensions and orientations, which are also key factors\nfor effective manufacturing process planning. This paper presents a novel\napproach for creating a synthetic CAD dataset that encompasses features\nrelevant to both additive and subtractive machining through Python Open\nCascade. The Hierarchical Graph Convolutional Neural Network (HGCNN) model is\nimplemented to accurately identify the composite additive-subtractive features\nwithin the synthetic CAD dataset. The key novelty and contribution of the\nproposed methodology lie in its ability to recognize a wide range of\nmanufacturing features, and precisely extracting their dimensions,\norientations, and stock sizes. The proposed model demonstrates remarkable\nfeature recognition accuracy exceeding 97% and a dimension extraction accuracy\nof 100% for identified features. Therefore, the proposed methodology enhances\nthe integration of CAD, CAPP, and CAM within hybrid manufacturing by providing\nprecise feature recognition and dimension extraction. It facilitates improved\nmanufacturing process planning, by enabling more informed decision-making."
    },
    {
        "date": "2024-08",
        "title": "Target Prompting for Information Extraction with Vision Language Model",
        "author": "Dipankar Medhi",
        "link": "http://arxiv.org/abs/2408.03834v1",
        "abstract": "The recent trend in the Large Vision and Language model has brought a new\nchange in how information extraction systems are built. VLMs have set a new\nbenchmark with their State-of-the-art techniques in understanding documents and\nbuilding question-answering systems across various industries. They are\nsignificantly better at generating text from document images and providing\naccurate answers to questions. However, there are still some challenges in\neffectively utilizing these models to build a precise conversational system.\nGeneral prompting techniques used with large language models are often not\nsuitable for these specially designed vision language models. The output\ngenerated by such generic input prompts is ordinary and may contain information\ngaps when compared with the actual content of the document. To obtain more\naccurate and specific answers, a well-targeted prompt is required by the vision\nlanguage model, along with the document image. In this paper, a technique is\ndiscussed called Target prompting, which focuses on explicitly targeting parts\nof document images and generating related answers from those specific regions\nonly. The paper also covers the evaluation of response for each prompting\ntechnique using different user queries and input prompts."
    },
    {
        "date": "2024-08",
        "title": "Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction",
        "author": "Benjamin Matthias Ruppik, Michael Heck, Carel van Niekerk, Renato Vukovic, Hsien-chin Lin, Shutong Feng, Marcus Zibrowius, and Milica Ga\u0161i\u0107",
        "link": "http://arxiv.org/abs/2408.03706v1",
        "abstract": "A common approach for sequence tagging tasks based on contextual word\nrepresentations is to train a machine learning classifier directly on these\nembedding vectors. This approach has two shortcomings. First, such methods\nconsider single input sequences in isolation and are unable to put an\nindividual embedding vector in relation to vectors outside the current local\ncontext of use. Second, the high performance of these models relies on\nfine-tuning the embedding model in conjunction with the classifier, which may\nnot always be feasible due to the size or inaccessibility of the underlying\nfeature-generation model. It is thus desirable, given a collection of embedding\nvectors of a corpus, i.e., a datastore, to find features of each vector that\ndescribe its relation to other, similar vectors in the datastore. With this in\nmind, we introduce complexity measures of the local topology of the latent\nspace of a contextual language model with respect to a given datastore. The\neffectiveness of our features is demonstrated through their application to\ndialogue term extraction. Our work continues a line of research that explores\nthe manifold hypothesis for word embeddings, demonstrating that local structure\nin the space carved out by word embeddings can be exploited to infer semantic\nproperties."
    },
    {
        "date": "2024-08",
        "title": "Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection",
        "author": "Sajal Aggarwal, Ananya Pandey, and Dinesh Kumar Vishwakarma",
        "link": "http://arxiv.org/abs/2408.02595v1",
        "abstract": "Sarcasm is a type of irony, characterized by an inherent mismatch between the\nliteral interpretation and the intended connotation. Though sarcasm detection\nin text has been extensively studied, there are situations in which textual\ninput alone might be insufficient to perceive sarcasm. The inclusion of\nadditional contextual cues, such as images, is essential to recognize sarcasm\nin social media data effectively. This study presents a novel framework for\nmultimodal sarcasm detection that can process input triplets. Two components of\nthese triplets comprise the input text and its associated image, as provided in\nthe datasets. Additionally, a supplementary modality is introduced in the form\nof descriptive image captions. The motivation behind incorporating this visual\nsemantic representation is to more accurately capture the discrepancies between\nthe textual and visual content, which are fundamental to the sarcasm detection\ntask. The primary contributions of this study are: (1) a robust textual feature\nextraction branch that utilizes a cross-lingual language model; (2) a visual\nfeature extraction branch that incorporates a self-regulated residual ConvNet\nintegrated with a lightweight spatially aware attention module; (3) an\nadditional modality in the form of image captions generated using an\nencoder-decoder architecture capable of reading text embedded in images; (4)\ndistinct attention modules to effectively identify the incongruities between\nthe text and two levels of image representations; (5) multi-level cross-domain\nsemantic incongruity representation achieved through feature fusion. Compared\nwith cutting-edge baselines, the proposed model achieves the best accuracy of\n92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and\nMultiBully datasets."
    },
    {
        "date": "2024-08",
        "title": "Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models",
        "author": "Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, and Haoyang Li",
        "link": "http://arxiv.org/abs/2408.02416v2",
        "abstract": "The drastic increase of large language models' (LLMs) parameters has led to a\nnew research direction of fine-tuning-free downstream customization by prompts,\ni.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)\nplay an important role in many businesses, there has emerged growing concerns\nabout the prompt leakage, which undermines the intellectual properties of these\nservices and causes downstream attacks. In this paper, we analyze the\nunderlying mechanism of prompt leakage, which we refer to as prompt\nmemorization, and develop corresponding defending strategies. By exploring the\nscaling laws in prompt extraction, we analyze key attributes that influence\nprompt extraction, including model sizes, prompt lengths, as well as the types\nof prompts. Then we propose two hypotheses that explain how LLMs expose their\nprompts. The first is attributed to the perplexity, i.e. the familiarity of\nLLMs to texts, whereas the second is based on the straightforward token\ntranslation path in attention matrices. To defend against such threats, we\ninvestigate whether alignments can undermine the extraction of prompts. We find\nthat current LLMs, even those with safety alignments like GPT-4, are highly\nvulnerable to prompt extraction attacks, even under the most straightforward\nuser attacks. Therefore, we put forward several defense strategies with the\ninspiration of our findings, which achieve 83.8\\% and 71.0\\% drop in the prompt\nextraction rate for Llama2-7B and GPT-3.5, respectively. Source code is\navaliable at https://github.com/liangzid/PromptExtractionEval."
    },
    {
        "date": "2024-08",
        "title": "A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models",
        "author": "Vanni Zavarella, Juan Carlos Gamero-Salinas, and Sergio Consoli",
        "link": "http://arxiv.org/abs/2408.02377v1",
        "abstract": "Knowledge graphs (KGs) have been successfully applied to the analysis of\ncomplex scientific and technological domains, with automatic KG generation\nmethods typically building upon relation extraction models capturing\nfine-grained relations between domain entities in text. While these relations\nare fully applicable across scientific areas, existing models are trained on\nfew domain-specific datasets such as SciERC and do not perform well on new\ntarget domains. In this paper, we experiment with leveraging in-context\nlearning capabilities of Large Language Models to perform schema-constrained\ndata annotation, collecting in-domain training instances for a\nTransformer-based relation extraction model deployed on titles and abstracts of\nresearch papers in the Architecture, Construction, Engineering and Operations\n(AECO) domain. By assessing the performance gain with respect to a baseline\nDeep Learning architecture trained on off-domain data, we show that by using a\nfew-shot learning strategy with structured prompts and only minimal expert\nannotation the presented approach can potentially support domain adaptation of\na science KG generation model."
    },
    {
        "date": "2024-08",
        "title": "VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces",
        "author": "Somnath Sendhil Kumar, Yuvaraj Govindarajulu, Pavan Kulkarni, and Manojkumar Parmar",
        "link": "http://arxiv.org/abs/2408.02140v1",
        "abstract": "In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels."
    },
    {
        "date": "2024-08",
        "title": "Knowledge AI: Fine-tuning NLP Models for Facilitating Scientific Knowledge Extraction and Understanding",
        "author": "Balaji Muralidharan, Hayden Beadles, Reza Marzban, and Kalyan Sashank Mupparaju",
        "link": "http://arxiv.org/abs/2408.04651v1",
        "abstract": "This project investigates the efficacy of Large Language Models (LLMs) in\nunderstanding and extracting scientific knowledge across specific domains and\nto create a deep learning framework: Knowledge AI. As a part of this framework,\nwe employ pre-trained models and fine-tune them on datasets in the scientific\ndomain. The models are adapted for four key Natural Language Processing (NLP)\ntasks: summarization, text generation, question answering, and named entity\nrecognition. Our results indicate that domain-specific fine-tuning\nsignificantly enhances model performance in each of these tasks, thereby\nimproving their applicability for scientific contexts. This adaptation enables\nnon-experts to efficiently query and extract information within targeted\nscientific fields, demonstrating the potential of fine-tuned LLMs as a tool for\nknowledge discovery in the sciences."
    },
    {
        "date": "2024-08",
        "title": "Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data",
        "author": "Antonio De Santis, Marco Balduini, Federico De Santis, Andrea Proia, Arsenio Leo, Marco Brambilla, and Emanuele Della Valle",
        "link": "http://arxiv.org/abs/2408.01700v1",
        "abstract": "Aerospace manufacturing companies, such as Thales Alenia Space, design,\ndevelop, integrate, verify, and validate products characterized by high\ncomplexity and low volume. They carefully document all phases for each product\nbut analyses across products are challenging due to the heterogeneity and\nunstructured nature of the data in documents. In this paper, we propose a\nhybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with\nLarge Language Models (LLMs) to extract and validate data contained in these\ndocuments. We consider a case study focused on test data related to electronic\nboards for satellites. To do so, we extend the Semantic Sensor Network\nontology. We store the metadata of the reports in a KG, while the actual test\nresults are stored in parquet accessible via a Virtual Knowledge Graph. The\nvalidation process is managed using an LLM-based approach. We also conduct a\nbenchmarking study to evaluate the performance of state-of-the-art LLMs in\nexecuting this task. Finally, we analyze the costs and benefits of automating\npreexisting processes of manual data extraction and validation for subsequent\ncross-report analyses."
    },
    {
        "date": "2024-07",
        "title": "FIARSE: Model-Heterogeneous Federated Learning via Importance-Aware Submodel Extraction",
        "author": "Feijie Wu, Xingchen Wang, Yaqing Wang, Tianci Liu, Lu Su, and Jing Gao",
        "link": "http://arxiv.org/abs/2407.19389v3",
        "abstract": "In federated learning (FL), accommodating clients' varied computational\ncapacities poses a challenge, often limiting the participation of those with\nconstrained resources in global model training. To address this issue, the\nconcept of model heterogeneity through submodel extraction has emerged,\noffering a tailored solution that aligns the model's complexity with each\nclient's computational capacity. In this work, we propose Federated\nImportance-Aware Submodel Extraction (FIARSE), a novel approach that\ndynamically adjusts submodels based on the importance of model parameters,\nthereby overcoming the limitations of previous static and dynamic submodel\nextraction methods. Compared to existing works, the proposed method offers a\ntheoretical foundation for the submodel extraction and eliminates the need for\nadditional information beyond the model parameters themselves to determine\nparameter importance, significantly reducing the overhead on clients. Extensive\nexperiments are conducted on various datasets to showcase the superior\nperformance of the proposed FIARSE."
    },
    {
        "date": "2024-07",
        "title": "Human-artificial intelligence teaming for scientific information extraction from data-driven additive manufacturing research using large language models",
        "author": "Mutahar Safdar, Jiarui Xie, Andrei Mircea, and Yaoyao Fiona Zhao",
        "link": "http://arxiv.org/abs/2407.18827v1",
        "abstract": "Data-driven research in Additive Manufacturing (AM) has gained significant\nsuccess in recent years. This has led to a plethora of scientific literature to\nemerge. The knowledge in these works consists of AM and Artificial Intelligence\n(AI) contexts that have not been mined and formalized in an integrated way. It\nrequires substantial effort and time to extract scientific information from\nthese works. AM domain experts have contributed over two dozen review papers to\nsummarize these works. However, information specific to AM and AI contexts\nstill requires manual effort to extract. The recent success of foundation\nmodels such as BERT (Bidirectional Encoder Representations for Transformers) or\nGPT (Generative Pre-trained Transformers) on textual data has opened the\npossibility of expediting scientific information extraction. We propose a\nframework that enables collaboration between AM and AI experts to continuously\nextract scientific information from data-driven AM literature. A demonstration\ntool is implemented based on the proposed framework and a case study is\nconducted to extract information relevant to the datasets, modeling, sensing,\nand AM system categories. We show the ability of LLMs (Large Language Models)\nto expedite the extraction of relevant information from data-driven AM\nliterature. In the future, the framework can be used to extract information\nfrom the broader design and manufacturing literature in the engineering\ndiscipline."
    },
    {
        "date": "2024-07",
        "title": "A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models",
        "author": "Julian Neuberger, Lars Ackermann, Han van der Aa, and Stefan Jablonski",
        "link": "http://arxiv.org/abs/2407.18540v1",
        "abstract": "Over the past decade, extensive research efforts have been dedicated to the\nextraction of information from textual process descriptions. Despite the\nremarkable progress witnessed in natural language processing (NLP), information\nextraction within the Business Process Management domain remains predominantly\nreliant on rule-based systems and machine learning methodologies. Data scarcity\nhas so far prevented the successful application of deep learning techniques.\nHowever, the rapid progress in generative large language models (LLMs) makes it\npossible to solve many NLP tasks with very high quality without the need for\nextensive data. Therefore, we systematically investigate the potential of LLMs\nfor extracting information from textual process descriptions, targeting the\ndetection of process elements such as activities and actors, and relations\nbetween them. Using a heuristic algorithm, we demonstrate the suitability of\nthe extracted information for process model generation. Based on a novel\nprompting strategy, we show that LLMs are able to outperform state-of-the-art\nmachine learning approaches with absolute performance improvements of up to 8\\%\n$F_1$ score across three different datasets. We evaluate our prompting strategy\non eight different LLMs, showing it is universally applicable, while also\nanalyzing the impact of certain prompt parts on extraction quality. The number\nof example texts, the specificity of definitions, and the rigour of format\ninstructions are identified as key for improving the accuracy of extracted\ninformation. Our code, prompts, and data are publicly available."
    },
    {
        "date": "2024-07",
        "title": "SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)",
        "author": "Bernardo Consoli, Xizhi Wu, Song Wang, Xinyu Zhao, Yanshan Wang, Justin Rousseau, Tom Hartvigsen, Li Shen, Huanmei Wu, Yifan Peng, Qi Long, Tianlong Chen, and Ying Ding",
        "link": "http://arxiv.org/abs/2407.17126v1",
        "abstract": "Extracting social determinants of health (SDoH) from unstructured medical\nnotes depends heavily on labor-intensive annotations, which are typically\ntask-specific, hampering reusability and limiting sharing. In this study we\nintroduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM)\nmethod leveraging contrastive examples and concise instructions to extract SDoH\nwithout relying on extensive medical annotations or costly human intervention.\nIt achieved tenfold and twentyfold reductions in time and cost respectively,\nand superior consistency with human annotators measured by Cohen's kappa of up\nto 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the\nstrengths of both, ensuring high accuracy and computational efficiency while\nconsistently maintaining 0.90+ AUROC scores. Testing across three distinct\ndatasets has confirmed its robustness and accuracy. This study highlights the\npotential of leveraging LLMs to revolutionize medical note classification,\ndemonstrating their capability to achieve highly accurate classifications with\nsignificantly reduced time and cost."
    },
    {
        "date": "2024-07",
        "title": "From Text to Insight: Large Language Models for Materials Science Data Extraction",
        "author": "Mara Schilling-Wilhelmi, Marti\u00f1o R\u00edos-Garc\u00eda, Sherjeel Shabih, Mar\u00eda Victoria Gil, Santiago Miret, Christoph T. Koch, Jos\u00e9 A. M\u00e1rquez, and Kevin Maik Jablonka",
        "link": "http://arxiv.org/abs/2407.16867v2",
        "abstract": "The vast majority of materials science knowledge exists in unstructured\nnatural language, yet structured data is crucial for innovative and systematic\nmaterials design. Traditionally, the field has relied on manual curation and\npartial automation for data extraction for specific use cases. The advent of\nlarge language models (LLMs) represents a significant shift, potentially\nenabling efficient extraction of structured, actionable data from unstructured\ntext by non-experts. While applying LLMs to materials science data extraction\npresents unique challenges, domain knowledge offers opportunities to guide and\nvalidate LLM outputs. This review provides a comprehensive overview of\nLLM-based structured data extraction in materials science, synthesizing current\nknowledge and outlining future directions. We address the lack of standardized\nguidelines and present frameworks for leveraging the synergy between LLMs and\nmaterials science expertise. This work serves as a foundational resource for\nresearchers aiming to harness LLMs for data-driven materials research. The\ninsights presented here could significantly enhance how researchers across\ndisciplines access and utilize scientific information, potentially accelerating\nthe development of novel materials for critical societal needs."
    },
    {
        "date": "2024-07",
        "title": "Causality extraction from medical text using Large Language Models (LLMs)",
        "author": "Seethalakshmi Gopalakrishnan, Luciana Garbayo, and Wlodek Zadrozny",
        "link": "http://arxiv.org/abs/2407.10020v1",
        "abstract": "This study explores the potential of natural language models, including large\nlanguage models, to extract causal relations from medical texts, specifically\nfrom Clinical Practice Guidelines (CPGs). The outcomes causality extraction\nfrom Clinical Practice Guidelines for gestational diabetes are presented,\nmarking a first in the field. We report on a set of experiments using variants\nof BERT (BioBERT, DistilBERT, and BERT) and using Large Language Models (LLMs),\nnamely GPT-4 and LLAMA2. Our experiments show that BioBERT performed better\nthan other models, including the Large Language Models, with an average\nF1-score of 0.72. GPT-4 and LLAMA2 results show similar performance but less\nconsistency. We also release the code and an annotated a corpus of causal\nstatements within the Clinical Practice Guidelines for gestational diabetes."
    },
    {
        "date": "2024-07",
        "title": "Empowering Few-Shot Relation Extraction with The Integration of Traditional RE Methods and Large Language Models",
        "author": "Ye Liu, Kai Zhang, Aoran Gan, Linan Yue, Feng Hu, Qi Liu, and Enhong Chen",
        "link": "http://arxiv.org/abs/2407.08967v1",
        "abstract": "Few-Shot Relation Extraction (FSRE), a subtask of Relation Extraction (RE)\nthat utilizes limited training instances, appeals to more researchers in\nNatural Language Processing (NLP) due to its capability to extract textual\ninformation in extremely low-resource scenarios. The primary methodologies\nemployed for FSRE have been fine-tuning or prompt tuning techniques based on\nPre-trained Language Models (PLMs). Recently, the emergence of Large Language\nModels (LLMs) has prompted numerous researchers to explore FSRE through\nIn-Context Learning (ICL). However, there are substantial limitations\nassociated with methods based on either traditional RE models or LLMs.\nTraditional RE models are hampered by a lack of necessary prior knowledge,\nwhile LLMs fall short in their task-specific capabilities for RE. To address\nthese shortcomings, we propose a Dual-System Augmented Relation Extractor\n(DSARE), which synergistically combines traditional RE models with LLMs.\nSpecifically, DSARE innovatively injects the prior knowledge of LLMs into\ntraditional RE models, and conversely enhances LLMs' task-specific aptitude for\nRE through relation extraction augmentation. Moreover, an Integrated Prediction\nmodule is employed to jointly consider these two respective predictions and\nderive the final results. Extensive experiments demonstrate the efficacy of our\nproposed method."
    },
    {
        "date": "2024-07",
        "title": "Extracting Training Data from Document-Based VQA Models",
        "author": "Francesco Pinto, Nathalie Rauschmayr, Florian Tram\u00e8r, Philip Torr, and Federico Tombari",
        "link": "http://arxiv.org/abs/2407.08707v1",
        "abstract": "Vision-Language Models (VLMs) have made remarkable progress in document-based\nVisual Question Answering (i.e., responding to queries about the contents of an\ninput document provided as an image). In this work, we show these models can\nmemorize responses for training samples and regurgitate them even when the\nrelevant visual information has been removed. This includes Personal\nIdentifiable Information (PII) repeated once in the training set, indicating\nthese models could divulge memorised sensitive information and therefore pose a\nprivacy risk. We quantitatively measure the extractability of information in\ncontrolled experiments and differentiate between cases where it arises from\ngeneralization capabilities or from memorization. We further investigate the\nfactors that influence memorization across multiple state-of-the-art models and\npropose an effective heuristic countermeasure that empirically prevents the\nextractability of PII."
    },
    {
        "date": "2024-07",
        "title": "ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction",
        "author": "Shaozhe Hao, Kai Han, Zhengyao Lv, Shihao Zhao, and Kwan-Yee K. Wong",
        "link": "http://arxiv.org/abs/2407.07077v1",
        "abstract": "While personalized text-to-image generation has enabled the learning of a\nsingle concept from multiple images, a more practical yet challenging scenario\ninvolves learning multiple concepts within a single image. However, existing\nworks tackling this scenario heavily rely on extensive human annotations. In\nthis paper, we introduce a novel task named Unsupervised Concept Extraction\n(UCE) that considers an unsupervised setting without any human knowledge of the\nconcepts. Given an image that contains multiple concepts, the task aims to\nextract and recreate individual concepts solely relying on the existing\nknowledge from pretrained diffusion models. To achieve this, we present\nConceptExpress that tackles UCE by unleashing the inherent capabilities of\npretrained diffusion models in two aspects. Specifically, a concept\nlocalization approach automatically locates and disentangles salient concepts\nby leveraging spatial correspondence from diffusion self-attention; and based\non the lookup association between a concept and a conceptual token, a\nconcept-wise optimization process learns discriminative tokens that represent\neach individual concept. Finally, we establish an evaluation protocol tailored\nfor the UCE task. Extensive experiments demonstrate that ConceptExpress is a\npromising solution to the UCE task. Our code and data are available at:\nhttps://github.com/haoosz/ConceptExpress"
    },
    {
        "date": "2024-07",
        "title": "Large Language Models for Judicial Entity Extraction: A Comparative Study",
        "author": "Atin Sakkeer Hussain, and Anu Thomas",
        "link": "http://arxiv.org/abs/2407.05786v1",
        "abstract": "Domain-specific Entity Recognition holds significant importance in legal\ncontexts, serving as a fundamental task that supports various applications such\nas question-answering systems, text summarization, machine translation,\nsentiment analysis, and information retrieval specifically within case law\ndocuments. Recent advancements have highlighted the efficacy of Large Language\nModels in natural language processing tasks, demonstrating their capability to\naccurately detect and classify domain-specific facts (entities) from\nspecialized texts like clinical and financial documents. This research\ninvestigates the application of Large Language Models in identifying\ndomain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents,\nFIR nos.) within case law documents, with a specific focus on their aptitude\nfor handling domain-specific language complexity and contextual variations. The\nstudy evaluates the performance of state-of-the-art Large Language Model\narchitectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in\nthe context of extracting judicial facts tailored to Indian judicial texts.\nMistral and Gemma emerged as the top-performing models, showcasing balanced\nprecision and recall crucial for accurate entity identification. These findings\nconfirm the value of Large Language Models in judicial documents and\ndemonstrate how they can facilitate and quicken scientific research by\nproducing precise, organised data outputs that are appropriate for in-depth\nexamination."
    },
    {
        "date": "2024-07",
        "title": "Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation",
        "author": "Pablo Messina, Ren\u00e9 Vidal, Denis Parra, \u00c1lvaro Soto, and Vladimir Araujo",
        "link": "http://arxiv.org/abs/2407.01948v1",
        "abstract": "Advancing representation learning in specialized fields like medicine remains\nchallenging due to the scarcity of expert annotations for text and images. To\ntackle this issue, we present a novel two-stage framework designed to extract\nhigh-quality factual statements from free-text radiology reports in order to\nimprove the representations of text encoders and, consequently, their\nperformance on various downstream tasks. In the first stage, we propose a\n\\textit{Fact Extractor} that leverages large language models (LLMs) to identify\nfactual statements from well-curated domain-specific datasets. In the second\nstage, we introduce a \\textit{Fact Encoder} (CXRFE) based on a BERT model\nfine-tuned with objective functions designed to improve its representations\nusing the extracted factual data. Our framework also includes a new\nembedding-based metric (CXRFEScore) for evaluating chest X-ray text generation\nsystems, leveraging both stages of our approach. Extensive evaluations show\nthat our fact extractor and encoder outperform current state-of-the-art methods\nin tasks such as sentence ranking, natural language inference, and label\nextraction from radiology reports. Additionally, our metric proves to be more\nrobust and effective than existing metrics commonly used in the radiology\nreport generation literature. The code of this project is available at\n\\url{https://github.com/PabloMessina/CXR-Fact-Encoder}."
    },
    {
        "date": "2024-07",
        "title": "QUEEN: Query Unlearning against Model Extraction",
        "author": "Huajie Chen, Tianqing Zhu, Lefeng Zhang, Bo Liu, Derui Wang, Wanlei Zhou, and Minhui Xue",
        "link": "http://arxiv.org/abs/2407.01251v1",
        "abstract": "Model extraction attacks currently pose a non-negligible threat to the\nsecurity and privacy of deep learning models. By querying the model with a\nsmall dataset and usingthe query results as the ground-truth labels, an\nadversary can steal a piracy model with performance comparable to the original\nmodel. Two key issues that cause the threat are, on the one hand, accurate and\nunlimited queries can be obtained by the adversary; on the other hand, the\nadversary can aggregate the query results to train the model step by step. The\nexisting defenses usually employ model watermarking or fingerprinting to\nprotect the ownership. However, these methods cannot proactively prevent the\nviolation from happening. To mitigate the threat, we propose QUEEN (QUEry\nunlEarNing) that proactively launches counterattacks on potential model\nextraction attacks from the very beginning. To limit the potential threat,\nQUEEN has sensitivity measurement and outputs perturbation that prevents the\nadversary from training a piracy model with high performance. In sensitivity\nmeasurement, QUEEN measures the single query sensitivity by its distance from\nthe center of its cluster in the feature space. To reduce the learning accuracy\nof attacks, for the highly sensitive query batch, QUEEN applies query\nunlearning, which is implemented by gradient reverse to perturb the softmax\noutput such that the piracy model will generate reverse gradients to worsen its\nperformance unconsciously. Experiments show that QUEEN outperforms the\nstate-of-the-art defenses against various model extraction attacks with a\nrelatively low cost to the model accuracy. The artifact is publicly available\nat https://anonymous.4open.science/r/queen implementation-5408/."
    },
    {
        "date": "2024-06",
        "title": "Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs",
        "author": "Lokesh Mishra, Sohayl Dhibi, Yusik Kim, Cesar Berrospi Ramis, Shubham Gupta, Michele Dolfi, and Peter Staar",
        "link": "http://arxiv.org/abs/2406.19102v1",
        "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability\nin the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based\nStatement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports."
    },
    {
        "date": "2024-06",
        "title": "Research on Information Extraction of LCSTS Dataset Based on an Improved BERTSum-LSTM Model",
        "author": "Yiming Chen, Haobin Chen, Simin Liu, Yunyun Liu, Fanhao Zhou, and Bing Wei",
        "link": "http://arxiv.org/abs/2406.18364v1",
        "abstract": "With the continuous advancement of artificial intelligence, natural language\nprocessing technology has become widely utilized in various fields. At the same\ntime, there are many challenges in creating Chinese news summaries. First of\nall, the semantics of Chinese news is complex, and the amount of information is\nenormous. Extracting critical information from Chinese news presents a\nsignificant challenge. Second, the news summary should be concise and clear,\nfocusing on the main content and avoiding redundancy. In addition, the\nparticularity of the Chinese language, such as polysemy, word segmentation,\netc., makes it challenging to generate Chinese news summaries. Based on the\nabove, this paper studies the information extraction method of the LCSTS\ndataset based on an improved BERTSum-LSTM model. We improve the BERTSum-LSTM\nmodel to make it perform better in generating Chinese news summaries. The\nexperimental results show that the proposed method has a good effect on\ncreating news summaries, which is of great importance to the construction of\nnews summaries."
    }
]