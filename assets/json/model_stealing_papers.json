[
    {
        "date": "2025-05",
        "title": "Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models",
        "author": "Zihao Li, Xu Wang, Yuzhe Yang, Ziyu Yao, Haoyi Xiong, and Mengnan Du",
        "link": "http://arxiv.org/abs/2505.15634v1",
        "abstract": "Large Language Models (LLMs) demonstrate the ability to solve reasoning and\nmathematical problems using the Chain-of-Thought (CoT) technique. Expanding CoT\nlength, as seen in models such as DeepSeek-R1, significantly enhances this\nreasoning for complex problems, but requires costly and high-quality long CoT\ndata and fine-tuning. This work, inspired by the deep thinking paradigm of\nDeepSeek-R1, utilizes a steering technique to enhance the reasoning ability of\nan LLM without external datasets. Our method first employs Sparse Autoencoders\n(SAEs) to extract interpretable features from vanilla CoT. These features are\nthen used to steer the LLM's internal states during generation. Recognizing\nthat many LLMs do not have corresponding pre-trained SAEs, we further introduce\na novel SAE-free steering algorithm, which directly computes steering\ndirections from the residual activations of an LLM, obviating the need for an\nexplicit SAE. Experimental results demonstrate that both our SAE-based and\nsubsequent SAE-free steering algorithms significantly enhance the reasoning\ncapabilities of LLMs."
    },
    {
        "date": "2025-05",
        "title": "LOD1 3D City Model from LiDAR: The Impact of Segmentation Accuracy on Quality of Urban 3D Modeling and Morphology Extraction",
        "author": "Fatemeh Chajaei, and Hossein Bagheri",
        "link": "http://arxiv.org/abs/2505.14747v1",
        "abstract": "Three-dimensional reconstruction of buildings, particularly at Level of\nDetail 1 (LOD1), plays a crucial role in various applications such as urban\nplanning, urban environmental studies, and designing optimized transportation\nnetworks. This study focuses on assessing the potential of LiDAR data for\naccurate 3D building reconstruction at LOD1 and extracting morphological\nfeatures from these models. Four deep semantic segmentation models, U-Net,\nAttention U-Net, U-Net3+, and DeepLabV3+, were used, applying transfer learning\nto extract building footprints from LiDAR data. The results showed that U-Net3+\nand Attention U-Net outperformed the others, achieving IoU scores of 0.833 and\n0.814, respectively. Various statistical measures, including maximum, range,\nmode, median, and the 90th percentile, were used to estimate building heights,\nresulting in the generation of 3D models at LOD1. As the main contribution of\nthe research, the impact of segmentation accuracy on the quality of 3D building\nmodeling and the accuracy of morphological features like building area and\nexternal wall surface area was investigated. The results showed that the\naccuracy of building identification (segmentation performance) significantly\naffects the 3D model quality and the estimation of morphological features,\ndepending on the height calculation method. Overall, the UNet3+ method,\nutilizing the 90th percentile and median measures, leads to accurate height\nestimation of buildings and the extraction of morphological features."
    },
    {
        "date": "2025-05",
        "title": "LLM-based Evaluation Policy Extraction for Ecological Modeling",
        "author": "Qi Cheng, Licheng Liu, Qing Zhu, Runlong Yu, Zhenong Jin, Yiqun Xie, and Xiaowei Jia",
        "link": "http://arxiv.org/abs/2505.13794v1",
        "abstract": "Evaluating ecological time series is critical for benchmarking model\nperformance in many important applications, including predicting greenhouse gas\nfluxes, capturing carbon-nitrogen dynamics, and monitoring hydrological cycles.\nTraditional numerical metrics (e.g., R-squared, root mean square error) have\nbeen widely used to quantify the similarity between modeled and observed\necosystem variables, but they often fail to capture domain-specific temporal\npatterns critical to ecological processes. As a result, these methods are often\naccompanied by expert visual inspection, which requires substantial human labor\nand limits the applicability to large-scale evaluation. To address these\nchallenges, we propose a novel framework that integrates metric learning with\nlarge language model (LLM)-based natural language policy extraction to develop\ninterpretable evaluation criteria. The proposed method processes pairwise\nannotations and implements a policy optimization mechanism to generate and\ncombine different assessment metrics. The results obtained on multiple datasets\nfor evaluating the predictions of crop gross primary production and carbon\ndioxide flux have confirmed the effectiveness of the proposed method in\ncapturing target assessment preferences, including both synthetically generated\nand expert-annotated model comparisons. The proposed framework bridges the gap\nbetween numerical metrics and expert knowledge while providing interpretable\nevaluation policies that accommodate the diverse needs of different ecosystem\nmodeling studies."
    },
    {
        "date": "2025-05",
        "title": "Extracting memorized pieces of (copyrighted) books from open-weight language models",
        "author": "A. Feder Cooper, Aaron Gokaslan, Amy B. Cyphert, Christopher De Sa, Mark A. Lemley, Daniel E. Ho, and Percy Liang",
        "link": "http://arxiv.org/abs/2505.12546v1",
        "abstract": "Plaintiffs and defendants in copyright lawsuits over generative AI often make\nsweeping, opposing claims about the extent to which large language models\n(LLMs) have memorized plaintiffs' protected expression. Drawing on adversarial\nML and copyright law, we show that these polarized positions dramatically\noversimplify the relationship between memorization and copyright. To do so, we\nleverage a recent probabilistic extraction technique to extract pieces of the\nBooks3 dataset from 13 open-weight LLMs. Through numerous experiments, we show\nthat it's possible to extract substantial parts of at least some books from\ndifferent LLMs. This is evidence that the LLMs have memorized the extracted\ntext; this memorized content is copied inside the model parameters. But the\nresults are complicated: the extent of memorization varies both by model and by\nbook. With our specific experiments, we find that the largest LLMs don't\nmemorize most books -- either in whole or in part. However, we also find that\nLlama 3.1 70B memorizes some books, like Harry Potter and 1984, almost\nentirely. We discuss why our results have significant implications for\ncopyright cases, though not ones that unambiguously favor either side."
    },
    {
        "date": "2025-05",
        "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models",
        "author": "Luca Collini, Baleegh Ahmad, Joey Ah-kiow, and Ramesh Karri",
        "link": "http://arxiv.org/abs/2505.11963v1",
        "abstract": "Hardware security verification is a challenging and time-consuming task. For\nthis purpose, design engineers may utilize tools such as formal verification,\nlinters, and functional simulation tests, coupled with analysis and a deep\nunderstanding of the hardware design being inspected. Large Language Models\n(LLMs) have been used to assist during this task, either directly or in\nconjunction with existing tools. We improve the state of the art by proposing\nMARVEL, a multi-agent LLM framework for a unified approach to decision-making,\ntool use, and reasoning. MARVEL mimics the cognitive process of a designer\nlooking for security vulnerabilities in RTL code. It consists of a supervisor\nagent that devises the security policy of the system-on-chips (SoCs) using its\nsecurity documentation. It delegates tasks to validate the security policy to\nindividual executor agents. Each executor agent carries out its assigned task\nusing a particular strategy. Each executor agent may use one or more tools to\nidentify potential security bugs in the design and send the results back to the\nsupervisor agent for further analysis and confirmation. MARVEL includes\nexecutor agents that leverage formal tools, linters, simulation tests,\nLLM-based detection schemes, and static analysis-based checks. We test our\napproach on a known buggy SoC based on OpenTitan from the Hack@DATE\ncompetition. We find that 20 of the 48 issues reported by MARVEL pose security\nvulnerabilities."
    },
    {
        "date": "2025-05",
        "title": "LAMP: Extracting Locally Linear Decision Surfaces from LLM World Models",
        "author": "Ryan Chen, Youngmin Ko, Zeyu Zhang, Catherine Cho, Sunny Chung, Mauro Giuffr\u00e9, Dennis L. Shung, and Bradly C. Stadie",
        "link": "http://arxiv.org/abs/2505.11772v2",
        "abstract": "We introduce LAMP (Linear Attribution Mapping Probe), a method that shines\nlight onto a black-box language model's decision surface and studies how\nreliably a model maps its stated reasons to its predictions through a locally\nlinear model approximating the decision surface. LAMP treats the model's own\nself-reported explanations as a coordinate system and fits a locally linear\nsurrogate that links those weights to the model's output. By doing so, it\nreveals which stated factors steer the model's decisions, and by how much. We\napply LAMP to three tasks: sentiment analysis, controversial-topic detection,\nand safety-prompt auditing. Across these tasks, LAMP reveals that many LLMs\nexhibit locally linear decision landscapes. In addition, these surfaces\ncorrelate with human judgments on explanation quality and, on a clinical\ncase-file data set, aligns with expert assessments. Since LAMP operates without\nrequiring access to model gradients, logits, or internal activations, it serves\nas a practical and lightweight framework for auditing proprietary language\nmodels, and enabling assessment of whether a model behaves consistently with\nthe explanations it provides."
    },
    {
        "date": "2025-05",
        "title": "On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction",
        "author": "Fatima Ezzeddine, Rinad Akel, Ihab Sbeity, Silvia Giordano, Marc Langheinrich, and Omran Ayoub",
        "link": "http://arxiv.org/abs/2505.08847v1",
        "abstract": "Machine Learning as a Service (MLaaS) has gained important attraction as a\nmeans for deploying powerful predictive models, offering ease of use that\nenables organizations to leverage advanced analytics without substantial\ninvestments in specialized infrastructure or expertise. However, MLaaS\nplatforms must be safeguarded against security and privacy attacks, such as\nmodel extraction (MEA) attacks. The increasing integration of explainable AI\n(XAI) within MLaaS has introduced an additional privacy challenge, as attackers\ncan exploit model explanations particularly counterfactual explanations (CFs)\nto facilitate MEA. In this paper, we investigate the trade offs among model\nperformance, privacy, and explainability when employing Differential Privacy\n(DP), a promising technique for mitigating CF facilitated MEA. We evaluate two\ndistinct DP strategies: implemented during the classification model training\nand at the explainer during CF generation."
    },
    {
        "date": "2025-05",
        "title": "CM1 -- A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models",
        "author": "Fabian Wolf, Oliver T\u00fcselmann, Arthur Matei, Lukas Hennies, Christoph Rass, and Gernot A. Fink",
        "link": "http://arxiv.org/abs/2505.04214v1",
        "abstract": "The automatic extraction of key-value information from handwritten documents\nis a key challenge in document analysis. A reliable extraction is a\nprerequisite for the mass digitization efforts of many archives. Large Vision\nLanguage Models (LVLM) are a promising technology to tackle this problem\nespecially in scenarios where little annotated training data is available. In\nthis work, we present a novel dataset specifically designed to evaluate the\nfew-shot capabilities of LVLMs. The CM1 documents are a historic collection of\nforms with handwritten entries created in Europe to administer the Care and\nMaintenance program after World War Two. The dataset establishes three\nbenchmarks on extracting name and birthdate information and, furthermore,\nconsiders different training set sizes. We provide baseline results for two\ndifferent LVLMs and compare performances to an established full-page extraction\nmodel. While the traditional full-page model achieves highly competitive\nperformances, our experiments show that when only a few training samples are\navailable the considered LVLMs benefit from their size and heavy pretraining\nand outperform the classical approach."
    },
    {
        "date": "2025-05",
        "title": "DMRL: Data- and Model-aware Reward Learning for Data Extraction",
        "author": "Zhiqiang Wang, and Ruoxi Cheng",
        "link": "http://arxiv.org/abs/2505.06284v1",
        "abstract": "Large language models (LLMs) are inherently vulnerable to unintended privacy\nbreaches. Consequently, systematic red-teaming research is essential for\ndeveloping robust defense mechanisms. However, current data extraction methods\nsuffer from several limitations: (1) rely on dataset duplicates (addressable\nvia deduplication), (2) depend on prompt engineering (now countered by\ndetection and defense), and (3) rely on random-search adversarial generation.\nTo address these challenges, we propose DMRL, a Data- and Model-aware Reward\nLearning approach for data extraction. This technique leverages inverse\nreinforcement learning to extract sensitive data from LLMs. Our method consists\nof two main components: (1) constructing an introspective reasoning dataset\nthat captures leakage mindsets to guide model behavior, and (2) training reward\nmodels with Group Relative Policy Optimization (GRPO), dynamically tuning\noptimization based on task difficulty at both the data and model levels.\nComprehensive experiments across various LLMs demonstrate that DMRL outperforms\nall baseline methods in data extraction performance."
    },
    {
        "date": "2025-05",
        "title": "Non-Adaptive Cryptanalytic Time-Space Lower Bounds via a Shearer-like Inequality for Permutations",
        "author": "Itai Dinur, Nathan Keller, and Avichai Marmor",
        "link": "http://arxiv.org/abs/2505.00894v1",
        "abstract": "The power of adaptivity in algorithms has been intensively studied in diverse\nareas of theoretical computer science. In this paper, we obtain a number of\nsharp lower bound results which show that adaptivity provides a significant\nextra power in cryptanalytic time-space tradeoffs with (possibly unlimited)\npreprocessing time.\n  Most notably, we consider the discrete logarithm (DLOG) problem in a generic\ngroup of $N$ elements. The classical `baby-step giant-step' algorithm for the\nproblem has time complexity $T=O(\\sqrt{N})$, uses $O(\\sqrt{N})$ bits of space\n(up to logarithmic factors in $N$) and achieves constant success probability.\n  We examine a generalized setting where an algorithm obtains an advice string\nof $S$ bits and is allowed to make $T$ arbitrary non-adaptive queries that\ndepend on the advice string (but not on the challenge group element).\n  We show that in this setting, the $T=O(\\sqrt{N})$ online time complexity of\nthe baby-step giant-step algorithm cannot be improved, unless the advice string\nis more than $\\Omega(\\sqrt{N})$ bits long. This lies in stark contrast with the\nclassical adaptive Pollard's rho algorithm for DLOG, which can exploit\npreprocessing to obtain the tradeoff curve $ST^2=O(N)$. We obtain similar sharp\nlower bounds for several other cryptanalytic problems.\n  To obtain our results, we present a new model that allows analyzing\nnon-adaptive preprocessing algorithms for a wide array of search and decision\nproblems in a unified way. Since previous proof techniques inherently cannot\ndistinguish between adaptive and non-adaptive algorithms for the problems in\nour model, they cannot be used to obtain our results. Consequently, our proof\nuses a variant of Shearer's lemma for this setting, due to Barthe,\nCordero-Erausquin, Ledoux, and Maurey (2011). This seems to be the first time a\nvariant of Shearer's lemma for permutations is used in an algorithmic context."
    },
    {
        "date": "2025-04",
        "title": "DeeP-Mod: Deep Dynamic Programming based Environment Modelling using Feature Extraction",
        "author": "Chris Child, and Lam Ngo",
        "link": "http://arxiv.org/abs/2504.20535v1",
        "abstract": "The DeeP-Mod framework builds an environment model using features from a Deep\nDynamic Programming Network (DDPN), trained via a Deep Q-Network (DQN). While\nDeep Q-Learning is effective in decision-making, state information is lost in\ndeeper DQN layers due to mixed state-action representations. We address this by\nusing Dynamic Programming (DP) to train a DDPN, where Value Iteration ensures\nthe output represents state values, not state-action pairs. Extracting features\nfrom the DDPN preserves state information, enabling task and action set\nindependence. We show that a reduced DDPN can be trained using features\nextracted from the original DDPN trained on an identical problem. This reduced\nDDPN achieves faster convergence under noise and outperforms the original DDPN.\nFinally, we introduce the DeeP-Mod framework, which creates an environment\nmodel using the evolution of features extracted from a DDPN in response to\nactions. A second DDPN, which learns directly from this feature model rather\nthan raw states, can learn an effective feature-value representation and thus\noptimal policy. A key advantage of DeeP-Mod is that an externally defined\nenvironment model is not needed at any stage, making DDPN applicable to a wide\nrange of environments."
    },
    {
        "date": "2025-04",
        "title": "A Multimodal Pipeline for Clinical Data Extraction: Applying Vision-Language Models to Scans of Transfusion Reaction Reports",
        "author": "Henning Sch\u00e4fer, Cynthia S. Schmidt, Johannes Wutzkowsky, Kamil Lorek, Lea Reinartz, Johannes R\u00fcckert, Christian Temme, Britta B\u00f6ckmann, Peter A. Horn, and Christoph M. Friedrich",
        "link": "http://arxiv.org/abs/2504.20220v1",
        "abstract": "Despite the growing adoption of electronic health records, many processes\nstill rely on paper documents, reflecting the heterogeneous real-world\nconditions in which healthcare is delivered. The manual transcription process\nis time-consuming and prone to errors when transferring paper-based data to\ndigital formats. To streamline this workflow, this study presents an\nopen-source pipeline that extracts and categorizes checkbox data from scanned\ndocuments. Demonstrated on transfusion reaction reports, the design supports\nadaptation to other checkbox-rich document types. The proposed method\nintegrates checkbox detection, multilingual optical character recognition (OCR)\nand multilingual vision-language models (VLMs). The pipeline achieves high\nprecision and recall compared against annually compiled gold-standards from\n2017 to 2024. The result is a reduction in administrative workload and accurate\nregulatory reporting. The open-source availability of this pipeline encourages\nself-hosted parsing of checkbox forms."
    },
    {
        "date": "2025-04",
        "title": "Hallucinations and Key Information Extraction in Medical Texts: A Comprehensive Assessment of Open-Source Large Language Models",
        "author": "Anindya Bijoy Das, Shibbir Ahmed, and Shahnewaz Karim Sakib",
        "link": "http://arxiv.org/abs/2504.19061v1",
        "abstract": "Clinical summarization is crucial in healthcare as it distills complex\nmedical data into digestible information, enhancing patient understanding and\ncare management. Large language models (LLMs) have shown significant potential\nin automating and improving the accuracy of such summarizations due to their\nadvanced natural language understanding capabilities. These models are\nparticularly applicable in the context of summarizing medical/clinical texts,\nwhere precise and concise information transfer is essential. In this paper, we\ninvestigate the effectiveness of open-source LLMs in extracting key events from\ndischarge reports, such as reasons for hospital admission, significant\nin-hospital events, and critical follow-up actions. In addition, we also assess\nthe prevalence of various types of hallucinations in the summaries produced by\nthese models. Detecting hallucinations is vital as it directly influences the\nreliability of the information, potentially affecting patient care and\ntreatment outcomes. We conduct comprehensive numerical simulations to\nrigorously evaluate the performance of these models, further probing the\naccuracy and fidelity of the extracted content in clinical summarization."
    },
    {
        "date": "2025-04",
        "title": "EMRModel: A Large Language Model for Extracting Medical Consultation Dialogues into Structured Medical Records",
        "author": "Shuguang Zhao, Qiangzhong Feng, Zhiyang He, Peipei Sun, Yingying Wang, Xiaodong Tao, Xiaoliang Lu, Mei Cheng, Xinyue Wu, Yanyan Wang, and Wei Liang",
        "link": "http://arxiv.org/abs/2504.16448v1",
        "abstract": "Medical consultation dialogues contain critical clinical information, yet\ntheir unstructured nature hinders effective utilization in diagnosis and\ntreatment. Traditional methods, relying on rule-based or shallow machine\nlearning techniques, struggle to capture deep and implicit semantics. Recently,\nlarge pre-trained language models and Low-Rank Adaptation (LoRA), a lightweight\nfine-tuning method, have shown promise for structured information extraction.\nWe propose EMRModel, a novel approach that integrates LoRA-based fine-tuning\nwith code-style prompt design, aiming to efficiently convert medical\nconsultation dialogues into structured electronic medical records (EMRs).\nAdditionally, we construct a high-quality, realistically grounded dataset of\nmedical consultation dialogues with detailed annotations. Furthermore, we\nintroduce a fine-grained evaluation benchmark for medical consultation\ninformation extraction and provide a systematic evaluation methodology,\nadvancing the optimization of medical natural language processing (NLP) models.\nExperimental results show EMRModel achieves an F1 score of 88.1%, improving\nby49.5% over standard pre-trained models. Compared to traditional LoRA\nfine-tuning methods, our model shows superior performance, highlighting its\neffectiveness in structured medical record extraction tasks."
    },
    {
        "date": "2025-04",
        "title": "A Large-Language Model Framework for Relative Timeline Extraction from PubMed Case Reports",
        "author": "Jing Wang, and Jeremy C Weiss",
        "link": "http://arxiv.org/abs/2504.12350v1",
        "abstract": "Timing of clinical events is central to characterization of patient\ntrajectories, enabling analyses such as process tracing, forecasting, and\ncausal reasoning. However, structured electronic health records capture few\ndata elements critical to these tasks, while clinical reports lack temporal\nlocalization of events in structured form. We present a system that transforms\ncase reports into textual time series-structured pairs of textual events and\ntimestamps. We contrast manual and large language model (LLM) annotations\n(n=320 and n=390 respectively) of ten randomly-sampled PubMed open-access\n(PMOA) case reports (N=152,974) and assess inter-LLM agreement (n=3,103; N=93).\nWe find that the LLM models have moderate event recall(O1-preview: 0.80) but\nhigh temporal concordance among identified events (O1-preview: 0.95). By\nestablishing the task, annotation, and assessment systems, and by demonstrating\nhigh concordance, this work may serve as a benchmark for leveraging the PMOA\ncorpus for temporal analytics."
    },
    {
        "date": "2025-04",
        "title": "LauraTSE: Target Speaker Extraction using Auto-Regressive Decoder-Only Language Models",
        "author": "Beilong Tang, Bang Zeng, and Ming Li",
        "link": "http://arxiv.org/abs/2504.07402v1",
        "abstract": "We propose LauraTSE, an Auto-Regressive Decoder-Only Language Model for\nTarget Speaker Extraction (TSE) based on the LauraGPT backbone. It employs a\nsmall-scale auto-regressive decoder-only language model which takes the\ncontinuous representations for both the mixture and the reference speeches and\nproduces the first few layers of the target speech's discrete codec\nrepresentations. In addition, a one-step encoder-only language model\nreconstructs the sum of the predicted codec embeddings using both the mixture\nand the reference information. Our approach achieves superior or comparable\nperformance to existing generative and discriminative TSE models. To the best\nof our knowledge, LauraTSE is the first single-task TSE model to leverage an\nauto-regressive decoder-only language model as the backbone."
    },
    {
        "date": "2025-03",
        "title": "Extracting Patient History from Clinical Text: A Comparative Study of Clinical Large Language Models",
        "author": "Hieu Nghiem, Tuan-Dung Le, Suhao Chen, Thanh Thieu, Andrew Gin, Ellie Phuong Nguyen, Dursun Delen, Johnson Thomas, Jivan Lamichhane, and Zhuqi Miao",
        "link": "http://arxiv.org/abs/2503.23281v1",
        "abstract": "Extracting medical history entities (MHEs) related to a patient's chief\ncomplaint (CC), history of present illness (HPI), and past, family, and social\nhistory (PFSH) helps structure free-text clinical notes into standardized EHRs,\nstreamlining downstream tasks like continuity of care, medical coding, and\nquality metrics. Fine-tuned clinical large language models (cLLMs) can assist\nin this process while ensuring the protection of sensitive data via on-premises\ndeployment. This study evaluates the performance of cLLMs in recognizing\nCC/HPI/PFSH-related MHEs and examines how note characteristics impact model\naccuracy. We annotated 1,449 MHEs across 61 outpatient-related clinical notes\nfrom the MTSamples repository. To recognize these entities, we fine-tuned seven\nstate-of-the-art cLLMs. Additionally, we assessed the models' performance when\nenhanced by integrating, problems, tests, treatments, and other basic medical\nentities (BMEs). We compared the performance of these models against GPT-4o in\na zero-shot setting. To further understand the textual characteristics\naffecting model accuracy, we conducted an error analysis focused on note\nlength, entity length, and segmentation. The cLLMs showed potential in reducing\nthe time required for extracting MHEs by over 20%. However, detecting many\ntypes of MHEs remained challenging due to their polysemous nature and the\nfrequent involvement of non-medical vocabulary. Fine-tuned GatorTron and\nGatorTronS, two of the most extensively trained cLLMs, demonstrated the highest\nperformance. Integrating pre-identified BME information improved model\nperformance for certain entities. Regarding the impact of textual\ncharacteristics on model performance, we found that longer entities were harder\nto identify, note length did not correlate with a higher error rate, and\nwell-organized segments with headings are beneficial for the extraction."
    },
    {
        "date": "2025-03",
        "title": "ICE: Intrinsic Concept Extraction from a Single Image via Diffusion Models",
        "author": "Fernando Julio Cendra, and Kai Han",
        "link": "http://arxiv.org/abs/2503.19902v2",
        "abstract": "The inherent ambiguity in defining visual concepts poses significant\nchallenges for modern generative models, such as the diffusion-based\nText-to-Image (T2I) models, in accurately learning concepts from a single\nimage. Existing methods lack a systematic way to reliably extract the\ninterpretable underlying intrinsic concepts. To address this challenge, we\npresent ICE, short for Intrinsic Concept Extraction, a novel framework that\nexclusively utilises a T2I model to automatically and systematically extract\nintrinsic concepts from a single image. ICE consists of two pivotal stages. In\nthe first stage, ICE devises an automatic concept localization module to\npinpoint relevant text-based concepts and their corresponding masks within the\nimage. This critical stage streamlines concept initialization and provides\nprecise guidance for subsequent analysis. The second stage delves deeper into\neach identified mask, decomposing the object-level concepts into intrinsic\nconcepts and general concepts. This decomposition allows for a more granular\nand interpretable breakdown of visual elements. Our framework demonstrates\nsuperior performance on intrinsic concept extraction from a single image in an\nunsupervised manner. Project page: https://visual-ai.github.io/ice"
    },
    {
        "date": "2025-03",
        "title": "Model-Guardian: Protecting against Data-Free Model Stealing Using Gradient Representations and Deceptive Predictions",
        "author": "Yunfei Yang, Xiaojun Chen, Yuexin Xuan, and Zhendong Zhao",
        "link": "http://arxiv.org/abs/2503.18081v1",
        "abstract": "Model stealing attack is increasingly threatening the confidentiality of\nmachine learning models deployed in the cloud. Recent studies reveal that\nadversaries can exploit data synthesis techniques to steal machine learning\nmodels even in scenarios devoid of real data, leading to data-free model\nstealing attacks. Existing defenses against such attacks suffer from\nlimitations, including poor effectiveness, insufficient generalization ability,\nand low comprehensiveness. In response, this paper introduces a novel defense\nframework named Model-Guardian. Comprising two components, Data-Free Model\nStealing Detector (DFMS-Detector) and Deceptive Predictions (DPreds),\nModel-Guardian is designed to address the shortcomings of current defenses with\nthe help of the artifact properties of synthetic samples and gradient\nrepresentations of samples. Extensive experiments on seven prevalent data-free\nmodel stealing attacks showcase the effectiveness and superior generalization\nability of Model-Guardian, outperforming eleven defense methods and\nestablishing a new state-of-the-art performance. Notably, this work pioneers\nthe utilization of various GANs and diffusion models for generating highly\nrealistic query samples in attacks, with Model-Guardian demonstrating accurate\ndetection capabilities."
    },
    {
        "date": "2025-03",
        "title": "Feature-Based Dual Visual Feature Extraction Model for Compound Multimodal Emotion Recognition",
        "author": "Ran Liu, Fengyu Zhang, Cong Yu, Longjiang Yang, Zhuofan Wen, Siyuan Zhang, Hailiang Yao, Shun Chen, Zheng Lian, and Bin Liu",
        "link": "http://arxiv.org/abs/2503.17453v1",
        "abstract": "This article presents our results for the eighth Affective Behavior Analysis\nin-the-wild (ABAW) competition.Multimodal emotion recognition (ER) has\nimportant applications in affective computing and human-computer interaction.\nHowever, in the real world, compound emotion recognition faces greater issues\nof uncertainty and modal conflicts. For the Compound Expression (CE)\nRecognition Challenge,this paper proposes a multimodal emotion recognition\nmethod that fuses the features of Vision Transformer (ViT) and Residual Network\n(ResNet). We conducted experiments on the C-EXPR-DB and MELD datasets. The\nresults show that in scenarios with complex visual and audio cues (such as\nC-EXPR-DB), the model that fuses the features of ViT and ResNet exhibits\nsuperior performance.Our code are avalible on\nhttps://github.com/MyGitHub-ax/8th_ABAW"
    },
    {
        "date": "2025-03",
        "title": "ATOM: A Framework of Detecting Query-Based Model Extraction Attacks for Graph Neural Networks",
        "author": "Zhan Cheng, Bolin Shen, Tianming Sha, Yuan Gao, Shibo Li, and Yushun Dong",
        "link": "http://arxiv.org/abs/2503.16693v1",
        "abstract": "Graph Neural Networks (GNNs) have gained traction in Graph-based Machine\nLearning as a Service (GMLaaS) platforms, yet they remain vulnerable to\ngraph-based model extraction attacks (MEAs), where adversaries reconstruct\nsurrogate models by querying the victim model. Existing defense mechanisms,\nsuch as watermarking and fingerprinting, suffer from poor real-time\nperformance, susceptibility to evasion, or reliance on post-attack\nverification, making them inadequate for handling the dynamic characteristics\nof graph-based MEA variants. To address these limitations, we propose ATOM, a\nnovel real-time MEA detection framework tailored for GNNs. ATOM integrates\nsequential modeling and reinforcement learning to dynamically detect evolving\nattack patterns, while leveraging $k$-core embedding to capture the structural\nproperties, enhancing detection precision. Furthermore, we provide theoretical\nanalysis to characterize query behaviors and optimize detection strategies.\nExtensive experiments on multiple real-world datasets demonstrate that ATOM\noutperforms existing approaches in detection performance, maintaining stable\nacross different time steps, thereby offering a more effective defense\nmechanism for GMLaaS environments."
    },
    {
        "date": "2025-03",
        "title": "BI-RADS prediction of mammographic masses using uncertainty information extracted from a Bayesian Deep Learning model",
        "author": "Mohaddeseh Chegini, and Ali Mahloojifar",
        "link": "http://arxiv.org/abs/2503.13999v2",
        "abstract": "The BI_RADS score is a probabilistic reporting tool used by radiologists to\nexpress the level of uncertainty in predicting breast cancer based on some\nmorphological features in mammography images. There is a significant\nvariability in describing masses which sometimes leads to BI_RADS\nmisclassification. Using a BI_RADS prediction system is required to support the\nfinal radiologist decisions. In this study, the uncertainty information\nextracted by a Bayesian deep learning model is utilized to predict the BI_RADS\nscore. The investigation results based on the pathology information demonstrate\nthat the f1-scores of the predictions of the radiologist are 42.86%, 48.33% and\n48.28%, meanwhile, the f1-scores of the model performance are 73.33%, 59.60%\nand 59.26% in the BI_RADS 2, 3 and 5 dataset samples, respectively. Also, the\nmodel can distinguish malignant from benign samples in the BI_RADS 0 category\nof the used dataset with an accuracy of 75.86% and correctly identify all\nmalignant samples as BI_RADS 5. The Grad-CAM visualization shows the model pays\nattention to the morphological features of the lesions. Therefore, this study\nshows the uncertainty-aware Bayesian Deep Learning model can report his\nuncertainty about the malignancy of a lesion based on morphological features,\nlike a radiologist."
    },
    {
        "date": "2025-03",
        "title": "ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction",
        "author": "Tong Zhou, Shijin Duan, Gaowen Liu, Charles Fleming, Ramana Rao Kompella, Shaolei Ren, and Xiaolin Xu",
        "link": "http://arxiv.org/abs/2503.13224v1",
        "abstract": "Pre-trained models are valuable intellectual property, capturing both\ndomain-specific and domain-invariant features within their weight spaces.\nHowever, model extraction attacks threaten these assets by enabling\nunauthorized source-domain inference and facilitating cross-domain transfer via\nthe exploitation of domain-invariant features. In this work, we introduce\n**ProDiF**, a novel framework that leverages targeted weight space manipulation\nto secure pre-trained models against extraction attacks. **ProDiF** quantifies\nthe transferability of filters and perturbs the weights of critical filters in\nunsecured memory, while preserving actual critical weights in a Trusted\nExecution Environment (TEE) for authorized users. A bi-level optimization\nfurther ensures resilience against adaptive fine-tuning attacks. Experimental\nresults show that **ProDiF** reduces source-domain accuracy to near-random\nlevels and decreases cross-domain transferability by 74.65\\%, providing robust\nprotection for pre-trained models. This work offers comprehensive protection\nfor pre-trained DNN models and highlights the potential of weight space\nmanipulation as a novel approach to model security."
    },
    {
        "date": "2025-03",
        "title": "Defense Against Model Stealing Based on Account-Aware Distribution Discrepancy",
        "author": "Jian-Ping Mei, Weibin Zhang, Jie Chen, Xuyun Zhang, and Tiantian Zhu",
        "link": "http://arxiv.org/abs/2503.12497v1",
        "abstract": "Malicious users attempt to replicate commercial models functionally at low\ncost by training a clone model with query responses. It is challenging to\ntimely prevent such model-stealing attacks to achieve strong protection and\nmaintain utility. In this paper, we propose a novel non-parametric detector\ncalled Account-aware Distribution Discrepancy (ADD) to recognize queries from\nmalicious users by leveraging account-wise local dependency. We formulate each\nclass as a Multivariate Normal distribution (MVN) in the feature space and\nmeasure the malicious score as the sum of weighted class-wise distribution\ndiscrepancy. The ADD detector is combined with random-based prediction\npoisoning to yield a plug-and-play defense module named D-ADD for image\nclassification models. Results of extensive experimental studies show that\nD-ADD achieves strong defense against different types of attacks with little\ninterference in serving benign users for both soft and hard-label settings."
    },
    {
        "date": "2025-03",
        "title": "Review GIDE -- Restaurant Review Gastrointestinal Illness Detection and Extraction with Large Language Models",
        "author": "Timothy Laurence, Joshua Harris, Leo Loman, Amy Douglas, Yung-Wai Chan, Luke Hounsome, Lesley Larkin, and Michael Borowitz",
        "link": "http://arxiv.org/abs/2503.09743v1",
        "abstract": "Foodborne gastrointestinal (GI) illness is a common cause of ill health in\nthe UK. However, many cases do not interact with the healthcare system, posing\nsignificant challenges for traditional surveillance methods. The growth of\npublicly available online restaurant reviews and advancements in large language\nmodels (LLMs) present potential opportunities to extend disease surveillance by\nidentifying public reports of GI illness. In this study, we introduce a novel\nannotation schema, developed with experts in GI illness, applied to the Yelp\nOpen Dataset of reviews. Our annotations extend beyond binary disease\ndetection, to include detailed extraction of information on symptoms and foods.\nWe evaluate the performance of open-weight LLMs across these three tasks: GI\nillness detection, symptom extraction, and food extraction. We compare this\nperformance to RoBERTa-based classification models fine-tuned specifically for\nthese tasks. Our results show that using prompt-based approaches, LLMs achieve\nmicro-F1 scores of over 90% for all three of our tasks. Using prompting alone,\nwe achieve micro-F1 scores that exceed those of smaller fine-tuned models. We\nfurther demonstrate the robustness of LLMs in GI illness detection across three\nbias-focused experiments. Our results suggest that publicly available review\ntext and LLMs offer substantial potential for public health surveillance of GI\nillness by enabling highly effective extraction of key information. While LLMs\nappear to exhibit minimal bias in processing, the inherent limitations of\nrestaurant review data highlight the need for cautious interpretation of\nresults."
    },
    {
        "date": "2025-03",
        "title": "Attackers Can Do Better: Over- and Understated Factors of Model Stealing Attacks",
        "author": "Daryna Oliynyk, Rudolf Mayer, and Andreas Rauber",
        "link": "http://arxiv.org/abs/2503.06188v1",
        "abstract": "Machine learning models were shown to be vulnerable to model stealing\nattacks, which lead to intellectual property infringement. Among other methods,\nsubstitute model training is an all-encompassing attack applicable to any\nmachine learning model whose behaviour can be approximated from input-output\nqueries. Whereas prior works mainly focused on improving the performance of\nsubstitute models by, e.g. developing a new substitute training method, there\nhave been only limited ablation studies on the impact the attacker's strength\nhas on the substitute model's performance. As a result, different authors came\nto diverse, sometimes contradicting, conclusions. In this work, we exhaustively\nexamine the ambivalent influence of different factors resulting from varying\nthe attacker's capabilities and knowledge on a substitute training attack. Our\nfindings suggest that some of the factors that have been considered important\nin the past are, in fact, not that influential; instead, we discover new\ncorrelations between attack conditions and success rate. In particular, we\ndemonstrate that better-performing target models enable higher-fidelity attacks\nand explain the intuition behind this phenomenon. Further, we propose to shift\nthe focus from the complexity of target models toward the complexity of their\nlearning tasks. Therefore, for the substitute model, rather than aiming for a\nhigher architecture complexity, we suggest focusing on getting data of higher\ncomplexity and an appropriate architecture. Finally, we demonstrate that even\nin the most limited data-free scenario, there is no need to overcompensate weak\nknowledge with millions of queries. Our results often exceed or match the\nperformance of previous attacks that assume a stronger attacker, suggesting\nthat these stronger attacks are likely endangering a model owner's intellectual\nproperty to a significantly higher degree than shown until now."
    },
    {
        "date": "2025-03",
        "title": "EVE: Towards End-to-End Video Subtitle Extraction with Vision-Language Models",
        "author": "Haiyang Yu, Jinghui Lu, Yanjie Wang, Yang Li, Han Wang, Can Huang, and Bin Li",
        "link": "http://arxiv.org/abs/2503.04058v1",
        "abstract": "The advent of Large Vision-Language Models (LVLMs) has advanced the\nvideo-based tasks, such as video captioning and video understanding. Some\nprevious research indicates that taking texts in videos as input can further\nimprove the performance of video understanding. As a type of indispensable\ninformation in short videos or movies, subtitles can assist LVLMs to better\nunderstand videos. Most existing methods for video subtitle extraction are\nbased on a multi-stage framework, handling each frame independently. They can\nhardly exploit the temporal information of videos. Although some LVLMs exhibit\nthe robust OCR capability, predicting accurate timestamps for subtitle texts is\nstill challenging. In this paper, we propose an End-to-end Video Subtitle\nExtraction method, called EVE, which consists of three modules: a vision\nencoder, an adapter module, and a large language model. To effectively compress\nthe visual tokens from the vision encoder, we propose a novel adapter\nInterleavedVT to interleave two modalities. It contains a visual compressor and\na textual region compressor. The proposed InterleavedVT exploits both the\nmerits of average pooling and Q-Former in token compression. Taking the\ntemporal information of videos into account, we introduce a sliding-window\nmechanism in the textual region compressor. To benchmark the video subtitle\nextraction task, we propose a large dataset ViSa including 2.5M videos.\nExtensive experiments on ViSa demonstrate that the proposed EVE can outperform\nexisting open-sourced tools and LVLMs."
    },
    {
        "date": "2025-03",
        "title": "OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature Extraction",
        "author": "Huang Huang, Fangchen Liu, Letian Fu, Tingfan Wu, Mustafa Mukadam, Jitendra Malik, Ken Goldberg, and Pieter Abbeel",
        "link": "http://arxiv.org/abs/2503.03734v3",
        "abstract": "Vision-Language-Action (VLA) models aim to predict robotic actions based on\nvisual observations and language instructions. Existing approaches require\nfine-tuning pre-trained visionlanguage models (VLMs) as visual and language\nfeatures are independently fed into downstream policies, degrading the\npre-trained semantic alignments. We propose OTTER, a novel VLA architecture\nthat leverages these existing alignments through explicit, text-aware visual\nfeature extraction. Instead of processing all visual features, OTTER\nselectively extracts and passes only task-relevant visual features that are\nsemantically aligned with the language instruction to the policy transformer.\nThis allows OTTER to keep the pre-trained vision-language encoders frozen.\nThereby, OTTER preserves and utilizes the rich semantic understanding learned\nfrom large-scale pre-training, enabling strong zero-shot generalization\ncapabilities. In simulation and real-world experiments, OTTER significantly\noutperforms existing VLA models, demonstrating strong zeroshot generalization\nto novel objects and environments. Video, code, checkpoints, and dataset:\nhttps://ottervla.github.io/."
    },
    {
        "date": "2025-03",
        "title": "An Aspect Extraction Framework using Different Embedding Types, Learning Models, and Dependency Structure",
        "author": "Ali Erkan, and Tunga G\u00fcng\u00f6r",
        "link": "http://arxiv.org/abs/2503.03512v1",
        "abstract": "Aspect-based sentiment analysis has gained significant attention in recent\nyears due to its ability to provide fine-grained insights for sentiment\nexpressions related to specific features of entities. An important component of\naspect-based sentiment analysis is aspect extraction, which involves\nidentifying and extracting aspect terms from text. Effective aspect extraction\nserves as the foundation for accurate sentiment analysis at the aspect level.\nIn this paper, we propose aspect extraction models that use different types of\nembeddings for words and part-of-speech tags and that combine several learning\nmodels. We also propose tree positional encoding that is based on dependency\nparsing output to capture better the aspect positions in sentences. In\naddition, a new aspect extraction dataset is built for Turkish by machine\ntranslating an English dataset in a controlled setting. The experiments\nconducted on two Turkish datasets showed that the proposed models mostly\noutperform the studies that use the same datasets, and incorporating tree\npositional encoding increases the performance of the models."
    },
    {
        "date": "2025-03",
        "title": "Computer-aided shape features extraction and regression models for predicting the ascending aortic aneurysm growth rate",
        "author": "Leonardo Geronzi, Antonio Martinez, Michel Rochette, Kexin Yan, Aline Bel-Brunon, Pascal Haigron, Pierre Escrig, Jacques Tomasi, Morgan Daniel, Alain Lalande, Siyu Lin, Diana Marcela Marin-Castrillon, Olivier Bouchot, Jean Porterie, Pier Paolo Valentini, and Marco Evangelos Biancolini",
        "link": "http://arxiv.org/abs/2503.02915v1",
        "abstract": "Objective: ascending aortic aneurysm growth prediction is still challenging\nin clinics. In this study, we evaluate and compare the ability of local and\nglobal shape features to predict ascending aortic aneurysm growth.\n  Material and methods: 70 patients with aneurysm, for which two 3D\nacquisitions were available, are included. Following segmentation, three local\nshape features are computed: (1) the ratio between maximum diameter and length\nof the ascending aorta centerline, (2) the ratio between the length of external\nand internal lines on the ascending aorta and (3) the tortuosity of the\nascending tract. By exploiting longitudinal data, the aneurysm growth rate is\nderived. Using radial basis function mesh morphing, iso-topological surface\nmeshes are created. Statistical shape analysis is performed through\nunsupervised principal component analysis (PCA) and supervised partial least\nsquares (PLS). Two types of global shape features are identified: three\nPCA-derived and three PLS-based shape modes. Three regression models are set\nfor growth prediction: two based on gaussian support vector machine using local\nand PCA-derived global shape features; the third is a PLS linear regression\nmodel based on the related global shape features. The prediction results are\nassessed and the aortic shapes most prone to growth are identified.\n  Results: the prediction root mean square error from leave-one-out\ncross-validation is: 0.112 mm/month, 0.083 mm/month and 0.066 mm/month for\nlocal, PCA-based and PLS-derived shape features, respectively. Aneurysms close\nto the root with a large initial diameter report faster growth.\n  Conclusion: global shape features might provide an important contribution for\npredicting the aneurysm growth."
    },
    {
        "date": "2025-02",
        "title": "PolyPrompt: Automating Knowledge Extraction from Multilingual Language Models with Dynamic Prompt Generation",
        "author": "Nathan Roll",
        "link": "http://arxiv.org/abs/2502.19756v1",
        "abstract": "Large language models (LLMs) showcase increasingly impressive English\nbenchmark scores, however their performance profiles remain inconsistent across\nmultilingual settings. To address this gap, we introduce PolyPrompt, a novel,\nparameter-efficient framework for enhancing the multilingual capabilities of\nLLMs. Our method learns a set of trigger tokens for each language through a\ngradient-based search, identifying the input query's language and selecting the\ncorresponding trigger tokens which are prepended to the prompt during\ninference. We perform experiments on two ~1 billion parameter models, with\nevaluations on the global MMLU benchmark across fifteen typologically and\nresource diverse languages, demonstrating accuracy gains of 3.7%-19.9% compared\nto naive and translation-pipeline baselines."
    },
    {
        "date": "2025-02",
        "title": "Can Large Language Models Extract Customer Needs as well as Professional Analysts?",
        "author": "Artem Timoshenko, Chengfeng Mao, and John R. Hauser",
        "link": "http://arxiv.org/abs/2503.01870v1",
        "abstract": "Identifying customer needs (CNs) is important for product management, product\ndevelopment, and marketing. Applications rely on professional analysts\ninterpreting textual data (e.g., interview transcripts, online reviews) to\nunderstand the nuances of customer experience and concisely formulate \"jobs to\nbe done.\" The task is cognitively complex and time-consuming. Current practice\nfacilitates the process with keyword search and machine learning but relies on\nhuman judgment to formulate CNs. We examine whether Large Language Models\n(LLMs) can automatically extract CNs. Because evaluating CNs requires\nprofessional judgment, we partnered with a marketing consulting firm to conduct\na blind study of CNs extracted by: (1) a foundational LLM with prompt\nengineering only (Base LLM), (2) an LLM fine-tuned with professionally\nidentified CNs (SFT LLM), and (3) professional analysts. The SFT LLM performs\nas well as or better than professional analysts when extracting CNs. The\nextracted CNs are well-formulated, sufficiently specific to identify\nopportunities, and justified by source content (no hallucinations). The SFT LLM\nis efficient and provides more complete coverage of CNs. The Base LLM was not\nsufficiently accurate or specific. Organizations can rely on SFT LLMs to reduce\nmanual effort, enhance the precision of CN articulation, and provide improved\ninsight for innovation and marketing strategy."
    },
    {
        "date": "2025-02",
        "title": "Examining the Threat Landscape: Foundation Models and Model Stealing",
        "author": "Ankita Raj, Deepankar Varma, and Chetan Arora",
        "link": "http://arxiv.org/abs/2502.18077v1",
        "abstract": "Foundation models (FMs) for computer vision learn rich and robust\nrepresentations, enabling their adaptation to task/domain-specific deployments\nwith little to no fine-tuning. However, we posit that the very same strength\ncan make applications based on FMs vulnerable to model stealing attacks.\nThrough empirical analysis, we reveal that models fine-tuned from FMs harbor\nheightened susceptibility to model stealing, compared to conventional vision\narchitectures like ResNets. We hypothesize that this behavior is due to the\ncomprehensive encoding of visual patterns and features learned by FMs during\npre-training, which are accessible to both the attacker and the victim. We\nreport that an attacker is able to obtain 94.28% agreement (matched predictions\nwith victim) for a Vision Transformer based victim model (ViT-L/16) trained on\nCIFAR-10 dataset, compared to only 73.20% agreement for a ResNet-18 victim,\nwhen using ViT-L/16 as the thief model. We arguably show, for the first time,\nthat utilizing FMs for downstream tasks may not be the best choice for\ndeployment in commercial APIs due to their susceptibility to model theft. We\nthereby alert model owners towards the associated security risks, and highlight\nthe need for robust security measures to safeguard such models against theft.\nCode is available at https://github.com/rajankita/foundation_model_stealing."
    },
    {
        "date": "2025-02",
        "title": "FedBM: Stealing Knowledge from Pre-trained Language Models for Heterogeneous Federated Learning",
        "author": "Meilu Zhu, Qiushi Yang, Zhifan Gao, Yixuan Yuan, and Jun Liu",
        "link": "http://arxiv.org/abs/2502.16832v1",
        "abstract": "Federated learning (FL) has shown great potential in medical image computing\nsince it provides a decentralized learning paradigm that allows multiple\nclients to train a model collaboratively without privacy leakage. However,\ncurrent studies have shown that data heterogeneity incurs local learning bias\nin classifiers and feature extractors of client models during local training,\nleading to the performance degradation of a federation system. To address these\nissues, we propose a novel framework called Federated Bias eliMinating (FedBM)\nto get rid of local learning bias in heterogeneous federated learning (FL),\nwhich mainly consists of two modules, i.e., Linguistic Knowledge-based\nClassifier Construction (LKCC) and Concept-guided Global Distribution\nEstimation (CGDE). Specifically, LKCC exploits class concepts, prompts and\npre-trained language models (PLMs) to obtain concept embeddings. These\nembeddings are used to estimate the latent concept distribution of each class\nin the linguistic space. Based on the theoretical derivation, we can rely on\nthese distributions to pre-construct a high-quality classifier for clients to\nachieve classification optimization, which is frozen to avoid classifier bias\nduring local training. CGDE samples probabilistic concept embeddings from the\nlatent concept distributions to learn a conditional generator to capture the\ninput space of the global model. Three regularization terms are introduced to\nimprove the quality and utility of the generator. The generator is shared by\nall clients and produces pseudo data to calibrate updates of local feature\nextractors. Extensive comparison experiments and ablation studies on public\ndatasets demonstrate the superior performance of FedBM over state-of-the-arts\nand confirm the effectiveness of each module, respectively. The code is\navailable at https://github.com/CUHK-AIM-Group/FedBM."
    },
    {
        "date": "2025-02",
        "title": "Advanced Chain-of-Thought Reasoning for Parameter Extraction from Documents Using Large Language Models",
        "author": "Hong Cai Chen, Yi Pin Xu, and Yang Zhang",
        "link": "http://arxiv.org/abs/2502.16540v1",
        "abstract": "Extracting parameters from technical documentation is crucial for ensuring\ndesign precision and simulation reliability in electronic design. However,\ncurrent methods struggle to handle high-dimensional design data and meet the\ndemands of real-time processing. In electronic design automation (EDA),\nengineers often manually search through extensive documents to retrieve\ncomponent parameters required for constructing PySpice models, a process that\nis both labor-intensive and time-consuming. To address this challenge, we\npropose an innovative framework that leverages large language models (LLMs) to\nautomate the extraction of parameters and the generation of PySpice models\ndirectly from datasheets. Our framework introduces three Chain-of-Thought (CoT)\nbased techniques: (1) Targeted Document Retrieval (TDR), which enables the\nrapid identification of relevant technical sections; (2) Iterative Retrieval\nOptimization (IRO), which refines the parameter search through iterative\nimprovements; and (3) Preference Optimization (PO), which dynamically\nprioritizes key document sections based on relevance. Experimental results show\nthat applying all three methods together improves retrieval precision by 47.69%\nand reduces processing latency by 37.84%. Furthermore, effect size analysis\nusing Cohen's d reveals that PO significantly reduces latency, while IRO\ncontributes most to precision enhancement. These findings underscore the\npotential of our framework to streamline EDA processes, enhance design\naccuracy, and shorten development timelines. Additionally, our algorithm has\nmodel-agnostic generalization, meaning it can improve parameter search\nperformance across different LLMs."
    },
    {
        "date": "2025-02",
        "title": "Merger-as-a-Stealer: Stealing Targeted PII from Aligned LLMs with Model Merging",
        "author": "Lin Lu, Zhigang Zuo, Ziji Sheng, and Pan Zhou",
        "link": "http://arxiv.org/abs/2502.16094v1",
        "abstract": "Model merging has emerged as a promising approach for updating large language\nmodels (LLMs) by integrating multiple domain-specific models into a\ncross-domain merged model. Despite its utility and plug-and-play nature,\nunmonitored mergers can introduce significant security vulnerabilities, such as\nbackdoor attacks and model merging abuse. In this paper, we identify a novel\nand more realistic attack surface where a malicious merger can extract targeted\npersonally identifiable information (PII) from an aligned model with model\nmerging. Specifically, we propose \\texttt{Merger-as-a-Stealer}, a two-stage\nframework to achieve this attack: First, the attacker fine-tunes a malicious\nmodel to force it to respond to any PII-related queries. The attacker then\nuploads this malicious model to the model merging conductor and obtains the\nmerged model. Second, the attacker inputs direct PII-related queries to the\nmerged model to extract targeted PII. Extensive experiments demonstrate that\n\\texttt{Merger-as-a-Stealer} successfully executes attacks against various LLMs\nand model merging methods across diverse settings, highlighting the\neffectiveness of the proposed framework. Given that this attack enables\ncharacter-level extraction for targeted PII without requiring any additional\nknowledge from the attacker, we stress the necessity for improved model\nalignment and more robust defense mechanisms to mitigate such threats."
    },
    {
        "date": "2025-02",
        "title": "Stealing Training Data from Large Language Models in Decentralized Training through Activation Inversion Attack",
        "author": "Chenxi Dai, Lin Lu, and Pan Zhou",
        "link": "http://arxiv.org/abs/2502.16086v1",
        "abstract": "Decentralized training has become a resource-efficient framework to\ndemocratize the training of large language models (LLMs). However, the privacy\nrisks associated with this framework, particularly due to the potential\ninclusion of sensitive data in training datasets, remain unexplored. This paper\nidentifies a novel and realistic attack surface: the privacy leakage from\ntraining data in decentralized training, and proposes \\textit{activation\ninversion attack} (AIA) for the first time. AIA first constructs a shadow\ndataset comprising text labels and corresponding activations using public\ndatasets. Leveraging this dataset, an attack model can be trained to\nreconstruct the training data from activations in victim decentralized\ntraining. We conduct extensive experiments on various LLMs and publicly\navailable datasets to demonstrate the susceptibility of decentralized training\nto AIA. These findings highlight the urgent need to enhance security measures\nin decentralized training to mitigate privacy risks in training LLMs."
    },
    {
        "date": "2025-02",
        "title": "A Survey of Model Extraction Attacks and Defenses in Distributed Computing Environments",
        "author": "Kaixiang Zhao, Lincan Li, Kaize Ding, Neil Zhenqiang Gong, Yue Zhao, and Yushun Dong",
        "link": "http://arxiv.org/abs/2502.16065v1",
        "abstract": "Model Extraction Attacks (MEAs) threaten modern machine learning systems by\nenabling adversaries to steal models, exposing intellectual property and\ntraining data. With the increasing deployment of machine learning models in\ndistributed computing environments, including cloud, edge, and federated\nlearning settings, each paradigm introduces distinct vulnerabilities and\nchallenges. Without a unified perspective on MEAs across these distributed\nenvironments, organizations risk fragmented defenses, inadequate risk\nassessments, and substantial economic and privacy losses. This survey is\nmotivated by the urgent need to understand how the unique characteristics of\ncloud, edge, and federated deployments shape attack vectors and defense\nrequirements. We systematically examine the evolution of attack methodologies\nand defense mechanisms across these environments, demonstrating how\nenvironmental factors influence security strategies in critical sectors such as\nautonomous vehicles, healthcare, and financial services. By synthesizing recent\nadvances in MEAs research and discussing the limitations of current evaluation\npractices, this survey provides essential insights for developing robust and\nadaptive defense strategies. Our comprehensive approach highlights the\nimportance of integrating protective measures across the entire distributed\ncomputing landscape to ensure the secure deployment of machine learning models."
    },
    {
        "date": "2025-02",
        "title": "Med-gte-hybrid: A contextual embedding transformer model for extracting actionable information from clinical texts",
        "author": "Aditya Kumar, Simon Rauch, Mario Cypko, and Oliver Amft",
        "link": "http://arxiv.org/abs/2502.15996v2",
        "abstract": "We introduce a novel contextual embedding model med-gte-hybrid that was\nderived from the gte-large sentence transformer to extract information from\nunstructured clinical narratives. Our model tuning strategy for med-gte-hybrid\ncombines contrastive learning and a denoising autoencoder. To evaluate the\nperformance of med-gte-hybrid, we investigate several clinical prediction tasks\nin large patient cohorts extracted from the MIMIC-IV dataset, including Chronic\nKidney Disease (CKD) patient prognosis, estimated glomerular filtration rate\n(eGFR) prediction, and patient mortality prediction. Furthermore, we\ndemonstrate that the med-gte-hybrid model improves patient stratification,\nclustering, and text retrieval, thus outperforms current state-of-the-art\nmodels on the Massive Text Embedding Benchmark (MTEB). While some of our\nevaluations focus on CKD, our hybrid tuning of sentence transformers could be\ntransferred to other medical domains and has the potential to improve clinical\ndecision-making and personalised treatment pathways in various healthcare\napplications."
    },
    {
        "date": "2025-02",
        "title": "Model Privacy: A Unified Framework to Understand Model Stealing Attacks and Defenses",
        "author": "Ganghua Wang, Yuhong Yang, and Jie Ding",
        "link": "http://arxiv.org/abs/2502.15567v1",
        "abstract": "The use of machine learning (ML) has become increasingly prevalent in various\ndomains, highlighting the importance of understanding and ensuring its safety.\nOne pressing concern is the vulnerability of ML applications to model stealing\nattacks. These attacks involve adversaries attempting to recover a learned\nmodel through limited query-response interactions, such as those found in\ncloud-based services or on-chip artificial intelligence interfaces. While\nexisting literature proposes various attack and defense strategies, these often\nlack a theoretical foundation and standardized evaluation criteria. In\nresponse, this work presents a framework called ``Model Privacy'', providing a\nfoundation for comprehensively analyzing model stealing attacks and defenses.\nWe establish a rigorous formulation for the threat model and objectives,\npropose methods to quantify the goodness of attack and defense strategies, and\nanalyze the fundamental tradeoffs between utility and privacy in ML models. Our\ndeveloped theory offers valuable insights into enhancing the security of ML\nmodels, especially highlighting the importance of the attack-specific structure\nof perturbations for effective defenses. We demonstrate the application of\nmodel privacy from the defender's perspective through various learning\nscenarios. Extensive experiments corroborate the insights and the effectiveness\nof defense mechanisms developed under the proposed framework."
    },
    {
        "date": "2025-02",
        "title": "MACPruning: Dynamic Operation Pruning to Mitigate Side-Channel DNN Model Extraction",
        "author": "Ruyi Ding, Cheng Gongye, Davis Ranney, Aidong Adam Ding, and Yunsi Fei",
        "link": "http://arxiv.org/abs/2502.15020v1",
        "abstract": "As deep learning gains popularity, edge IoT devices have seen proliferating\ndeployment of pre-trained Deep Neural Network (DNN) models. These DNNs\nrepresent valuable intellectual property and face significant confidentiality\nthreats from side-channel analysis (SCA), particularly non-invasive\nDifferential Electromagnetic (EM) Analysis (DEMA), which retrieves individual\nmodel parameters from EM traces collected during model inference. Traditional\nSCA mitigation methods, such as masking and shuffling, can still be applied to\nDNN inference, but will incur significant performance degradation due to the\nlarge volume of operations and parameters. Based on the insight that DNN models\nhave high redundancy and are robust to input variation, we introduce\nMACPruning, a novel lightweight defense against DEMA-based parameter extraction\nattacks, exploiting specific characteristics of DNN execution. The design\nprinciple of MACPruning is to randomly deactivate input pixels and prune the\noperations (typically multiply-accumulate-MAC) on those pixels. The technique\nremoves certain leakages and overall redistributes weight-dependent EM leakages\ntemporally, and thus effectively mitigates DEMA. To maintain DNN performance,\nwe propose an importance-aware pixel map that preserves critical input pixels,\nkeeping randomness in the defense while minimizing its impact on DNN\nperformance due to operation pruning. We conduct a comprehensive security\nanalysis of MACPruning on various datasets for DNNs on edge devices. Our\nevaluations demonstrate that MACPruning effectively reduces EM leakages with\nminimal impact on the model accuracy and negligible computational overhead."
    },
    {
        "date": "2025-02",
        "title": "Keep what you need : extracting efficient subnetworks from large audio representation models",
        "author": "David Genova, Philippe Esling, and Tom Hurlin",
        "link": "http://arxiv.org/abs/2502.12925v1",
        "abstract": "Recently, research on audio foundation models has witnessed notable advances,\nas illustrated by the ever improving results on complex downstream tasks.\nSubsequently, those pretrained networks have quickly been used for various\naudio applications. These improvements have however resulted in a considerable\nincrease both in size and complexity of these models. Along the environmental\nconcerns this issue raises, this prevents the deployment of such networks on\nconsumer-level devices, and precludes their use for real-time applications.\nMoreover, this appears contradictory with the specificity of the tasks for\nwhich these models are used, which are often simpler compared to extracting a\nrich, multi-purpose representation from any type of audio data. In this paper,\nwe address this issue with a simple, yet effective method to extract\nlightweight specialist subnetworks from large foundation models. Specifically,\nwe introduce learnable binary masks in-between the layers of a pretrained\nrepresentation model. When training the end-to-end model on a downstream task,\nwe add a sparsity-inducing loss to the overall objective, hence learning a\ncompact subnetwork specialized on a single task. Importantly, the weights of\nthe foundation model are kept frozen, resulting into low additional training\ncosts. Once trained, the masked computational units can then be removed from\nthe network, implying significant performance gains. We assess our method on\nthree widespread audio foundation models, each based on a different backbone\narchitecture, and illustrate its effectiveness on common audio representation\nevaluation tasks, as well as its versatility on both speech, music, and general\naudio. Code for reproducing the results and supporting webpage are available at\nhttps://github.com/gnvIRCAM/Audio-representation-trimming"
    },
    {
        "date": "2025-02",
        "title": "Archetypal SAE: Adaptive and Stable Dictionary Learning for Concept Extraction in Large Vision Models",
        "author": "Thomas Fel, Ekdeep Singh Lubana, Jacob S. Prince, Matthew Kowal, Victor Boutin, Isabel Papadimitriou, Binxu Wang, Martin Wattenberg, Demba Ba, and Talia Konkle",
        "link": "http://arxiv.org/abs/2502.12892v1",
        "abstract": "Sparse Autoencoders (SAEs) have emerged as a powerful framework for machine\nlearning interpretability, enabling the unsupervised decomposition of model\nrepresentations into a dictionary of abstract, human-interpretable concepts.\nHowever, we reveal a fundamental limitation: existing SAEs exhibit severe\ninstability, as identical models trained on similar datasets can produce\nsharply different dictionaries, undermining their reliability as an\ninterpretability tool. To address this issue, we draw inspiration from the\nArchetypal Analysis framework introduced by Cutler & Breiman (1994) and present\nArchetypal SAEs (A-SAE), wherein dictionary atoms are constrained to the convex\nhull of data. This geometric anchoring significantly enhances the stability of\ninferred dictionaries, and their mildly relaxed variants RA-SAEs further match\nstate-of-the-art reconstruction abilities. To rigorously assess dictionary\nquality learned by SAEs, we introduce two new benchmarks that test (i)\nplausibility, if dictionaries recover \"true\" classification directions and (ii)\nidentifiability, if dictionaries disentangle synthetic concept mixtures. Across\nall evaluations, RA-SAEs consistently yield more structured representations\nwhile uncovering novel, semantically meaningful concepts in large-scale vision\nmodels."
    },
    {
        "date": "2025-02",
        "title": "Label Drop for Multi-Aspect Relation Modeling in Universal Information Extraction",
        "author": "Lu Yang, Jiajia Li, En Ci, Lefei Zhang, Zuchao Li, and Ping Wang",
        "link": "http://arxiv.org/abs/2502.12614v1",
        "abstract": "Universal Information Extraction (UIE) has garnered significant attention due\nto its ability to address model explosion problems effectively. Extractive UIE\ncan achieve strong performance using a relatively small model, making it widely\nadopted. Extractive UIEs generally rely on task instructions for different\ntasks, including single-target instructions and multiple-target instructions.\nSingle-target instruction UIE enables the extraction of only one type of\nrelation at a time, limiting its ability to model correlations between\nrelations and thus restricting its capability to extract complex relations.\nWhile multiple-target instruction UIE allows for the extraction of multiple\nrelations simultaneously, the inclusion of irrelevant relations introduces\ndecision complexity and impacts extraction accuracy. Therefore, for\nmulti-relation extraction, we propose LDNet, which incorporates multi-aspect\nrelation modeling and a label drop mechanism. By assigning different relations\nto different levels for understanding and decision-making, we reduce decision\nconfusion. Additionally, the label drop mechanism effectively mitigates the\nimpact of irrelevant relations. Experiments show that LDNet outperforms or\nachieves competitive performance with state-of-the-art systems on 9 tasks, 33\ndatasets, in both single-modal and multi-modal, few-shot and zero-shot\nsettings.\\footnote{https://github.com/Lu-Yang666/LDNet}"
    },
    {
        "date": "2025-02",
        "title": "Evaluating improvements on using Large Language Models (LLMs) for property extraction in the Open Research Knowledge Graph (ORKG)",
        "author": "Sandra Schaftner",
        "link": "http://arxiv.org/abs/2502.10768v1",
        "abstract": "Current research highlights the great potential of Large Language Models\n(LLMs) for constructing Scholarly Knowledge Graphs (SKGs). One particularly\ncomplex step in this process is relation extraction, aimed at identifying\nsuitable properties to describe the content of research. This study builds\ndirectly on previous research of three Open Research Knowledge Graph (ORKG)\nteam members who assessed the readiness of LLMs such as GPT-3.5, Llama 2, and\nMistral for property extraction in scientific literature. Given the moderate\nperformance observed, the previous work concluded that fine-tuning is needed to\nimprove these models' alignment with scientific tasks and their emulation of\nhuman expertise. Expanding on this prior experiment, this study evaluates the\nimpact of advanced prompt engineering techniques and demonstrates that these\ntechniques can highly significantly enhance the results. Additionally, this\nstudy extends the property extraction process to include property matching to\nexisting ORKG properties, which are retrieved via the API. The evaluation\nreveals that results generated through advanced prompt engineering achieve a\nhigher proportion of matches with ORKG properties, further emphasizing the\nenhanced alignment achieved. Moreover, this lays the groundwork for addressing\nchallenges such as the inconsistency of ORKG properties, an issue highlighted\nin prior studies. By assigning unique URIs and using standardized terminology,\nthis work increases the consistency of the properties, fulfilling a crucial\naspect of Linked Data and FAIR principles - core commitments of ORKG. This, in\nturn, significantly enhances the applicability of ORKG content for subsequent\ntasks such as comparisons of research publications. Finally, the study\nconcludes with recommendations for future improvements in the overall property\nextraction process."
    },
    {
        "date": "2025-02",
        "title": "Leveraging large language models for structured information extraction from pathology reports",
        "author": "Jeya Balaji Balasubramanian, Daniel Adams, Ioannis Roxanis, Amy Berrington de Gonzalez, Penny Coulson, Jonas S. Almeida, and Montserrat Garc\u00eda-Closas",
        "link": "http://arxiv.org/abs/2502.12183v1",
        "abstract": "Background: Structured information extraction from unstructured\nhistopathology reports facilitates data accessibility for clinical research.\nManual extraction by experts is time-consuming and expensive, limiting\nscalability. Large language models (LLMs) offer efficient automated extraction\nthrough zero-shot prompting, requiring only natural language instructions\nwithout labeled data or training. We evaluate LLMs' accuracy in extracting\nstructured information from breast cancer histopathology reports, compared to\nmanual extraction by a trained human annotator.\n  Methods: We developed the Medical Report Information Extractor, a web\napplication leveraging LLMs for automated extraction. We developed a gold\nstandard extraction dataset to evaluate the human annotator alongside five LLMs\nincluding GPT-4o, a leading proprietary model, and the Llama 3 model family,\nwhich allows self-hosting for data privacy. Our assessment involved 111\nhistopathology reports from the Breast Cancer Now (BCN) Generations Study,\nextracting 51 pathology features specified in the study's data dictionary.\n  Results: Evaluation against the gold standard dataset showed that both Llama\n3.1 405B (94.7% accuracy) and GPT-4o (96.1%) achieved extraction accuracy\ncomparable to the human annotator (95.4%; p = 0.146 and p = 0.106,\nrespectively). While Llama 3.1 70B (91.6%) performed below human accuracy (p\n<0.001), its reduced computational requirements make it a viable option for\nself-hosting.\n  Conclusion: We developed an open-source tool for structured information\nextraction that can be customized by non-programmers using natural language.\nIts modular design enables reuse for various extraction tasks, producing\nstandardized, structured data from unstructured text reports to facilitate\nanalytics through improved accessibility and interoperability."
    },
    {
        "date": "2025-02",
        "title": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models",
        "author": "Belinda Mo, Kyssen Yu, Joshua Kazdan, Proud Mpala, Lisa Yu, Chris Cundy, Charilaos Kanatsoulis, and Sanmi Koyejo",
        "link": "http://arxiv.org/abs/2502.09956v1",
        "abstract": "Recent interest in building foundation models for KGs has highlighted a\nfundamental challenge: knowledge-graph data is relatively scarce. The\nbest-known KGs are primarily human-labeled, created by pattern-matching, or\nextracted using early NLP techniques. While human-generated KGs are in short\nsupply, automatically extracted KGs are of questionable quality. We present a\nsolution to this data scarcity problem in the form of a text-to-KG generator\n(KGGen), a package that uses language models to create high-quality graphs from\nplaintext. Unlike other KG extractors, KGGen clusters related entities to\nreduce sparsity in extracted KGs. KGGen is available as a Python library\n(\\texttt{pip install kg-gen}), making it accessible to everyone. Along with\nKGGen, we release the first benchmark, Measure of of Information in Nodes and\nEdges (MINE), that tests an extractor's ability to produce a useful KG from\nplain text. We benchmark our new tool against existing extractors and\ndemonstrate far superior performance."
    },
    {
        "date": "2025-02",
        "title": "The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics",
        "author": "Danni Feng, Runzhi Li, Jing Wang, Siyu Yan, Lihong Ma, and Yunli Xing",
        "link": "http://arxiv.org/abs/2502.09247v1",
        "abstract": "Joint entity-relation extraction is a critical task in transforming\nunstructured or semi-structured text into triplets, facilitating the\nconstruction of large-scale knowledge graphs, and supporting various downstream\napplications. Despite its importance, research on Chinese text, particularly\nwith complex semantics in specialized domains like medicine, remains limited.\nTo address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions\ndataset designed to capture the intricacies of medical text. Leveraging the\nstrengths of attention mechanisms in capturing long-range dependencies, we\npropose the SEA module, which enhances the extraction of complex contextual\nsemantic information, thereby improving entity recognition and relation\nextraction. Additionally, to address the inefficiencies of existing methods in\nfacilitating information exchange between entity recognition and relation\nextraction, we present an interactive fusion representation module. This module\nemploys Cross Attention for bidirectional information exchange between the\ntasks and further refines feature extraction through BiLSTM. Experimental\nresults on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that\nour model exhibits strong generalization capabilities. On the CH-DDI dataset,\nour model achieves an F1-score of 96.73% for entity recognition and 78.43% for\nrelation extraction. On the CoNLL04 dataset, it attains an entity recognition\nprecision of 89.54% and a relation extraction accuracy of 71.64%."
    },
    {
        "date": "2025-02",
        "title": "ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports",
        "author": "Aynur Guluzade, Naguib Heiba, Zeyd Boukhers, Florim Hamiti, Jahid Hasan Polash, Yehya Mohamad, and Carlos A Velasco",
        "link": "http://arxiv.org/abs/2502.05638v1",
        "abstract": "Europe's healthcare systems require enhanced interoperability and\ndigitalization, driving a demand for innovative solutions to process legacy\nclinical data. This paper presents the results of our project, which aims to\nleverage Large Language Models (LLMs) to extract structured information from\nunstructured clinical reports, focusing on patient history, diagnoses,\ntreatments, and other predefined categories. We developed a workflow with a\nuser interface and evaluated LLMs of varying sizes through prompting strategies\nand fine-tuning. Our results show that fine-tuned smaller models match or\nsurpass larger counterparts in performance, offering efficiency for\nresource-limited settings. A new dataset of 60,000 annotated English clinical\nsummaries and 24,000 German translations was validated with automated and\nmanual checks. The evaluations used ROUGE, BERTScore, and entity-level metrics.\nThe work highlights the approach's viability and outlines future improvements."
    },
    {
        "date": "2025-02",
        "title": "From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks",
        "author": "Awa Khouna, Julien Ferry, and Thibaut Vidal",
        "link": "http://arxiv.org/abs/2502.05325v1",
        "abstract": "The advent of Machine Learning as a Service (MLaaS) has heightened the\ntrade-off between model explainability and security. In particular,\nexplainability techniques, such as counterfactual explanations, inadvertently\nincrease the risk of model extraction attacks, enabling unauthorized\nreplication of proprietary models. In this paper, we formalize and characterize\nthe risks and inherent complexity of model reconstruction, focusing on the\n\"oracle'' queries required for faithfully inferring the underlying prediction\nfunction. We present the first formal analysis of model extraction attacks\nthrough the lens of competitive analysis, establishing a foundational framework\nto evaluate their efficiency. Focusing on models based on additive decision\ntrees (e.g., decision trees, gradient boosting, and random forests), we\nintroduce novel reconstruction algorithms that achieve provably perfect\nfidelity while demonstrating strong anytime performance. Our framework provides\ntheoretical bounds on the query complexity for extracting tree-based model,\noffering new insights into the security vulnerabilities of their deployment."
    },
    {
        "date": "2025-02",
        "title": "QExplorer: Large Language Model Based Query Extraction for Toxic Content Exploration",
        "author": "Shaola Ren, Li Ke, Longtao Huang, Dehong Gao, and Hui Xue",
        "link": "http://arxiv.org/abs/2502.18480v1",
        "abstract": "Automatically extracting effective queries is challenging in information\nretrieval, especially in toxic content exploration, as such content is likely\nto be disguised. With the recent achievements in generative Large Language\nModel (LLM), we are able to leverage the capabilities of LLMs to extract\neffective queries for similar content exploration directly. This study proposes\nQExplorer, an approach of large language model based Query Extraction for toxic\ncontent Exploration. The QExplorer approach involves a 2-stage training\nprocess: instruction Supervised FineTuning (SFT) and preference alignment using\nDirect Preference Optimization (DPO), as well as the datasets construction with\nfeedback of search system. To verify the effectiveness of QExplorer, a series\nof offline and online experiments are conducted on our real-world system. The\noffline empirical results demonstrate that the performance of our automatic\nquery extraction outperforms that of several LLMs and humans. The online\ndeployment shows a significant increase in the detection of toxic items."
    },
    {
        "date": "2025-02",
        "title": "MARAGE: Transferable Multi-Model Adversarial Attack for Retrieval-Augmented Generation Data Extraction",
        "author": "Xiao Hu, Eric Liu, Weizhou Wang, Xiangyu Guo, and David Lie",
        "link": "http://arxiv.org/abs/2502.04360v1",
        "abstract": "Retrieval-Augmented Generation (RAG) offers a solution to mitigate\nhallucinations in Large Language Models (LLMs) by grounding their outputs to\nknowledge retrieved from external sources. The use of private resources and\ndata in constructing these external data stores can expose them to risks of\nextraction attacks, in which attackers attempt to steal data from these private\ndatabases. Existing RAG extraction attacks often rely on manually crafted\nprompts, which limit their effectiveness. In this paper, we introduce a\nframework called MARAGE for optimizing an adversarial string that, when\nappended to user queries submitted to a target RAG system, causes outputs\ncontaining the retrieved RAG data verbatim. MARAGE leverages a continuous\noptimization scheme that integrates gradients from multiple models with\ndifferent architectures simultaneously to enhance the transferability of the\noptimized string to unseen models. Additionally, we propose a strategy that\nemphasizes the initial tokens in the target RAG data, further improving the\nattack's generalizability. Evaluations show that MARAGE consistently\noutperforms both manual and optimization-based baselines across multiple LLMs\nand RAG datasets, while maintaining robust transferability to previously unseen\nmodels. Moreover, we conduct probing tasks to shed light on the reasons why\nMARAGE is more effective compared to the baselines and to analyze the impact of\nour approach on the model's internal state."
    },
    {
        "date": "2025-02",
        "title": "Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment",
        "author": "Yaling Shen, Zhixiong Zhuang, Kun Yuan, Maria-Irina Nicolae, Nassir Navab, Nicolas Padoy, and Mario Fritz",
        "link": "http://arxiv.org/abs/2502.02438v1",
        "abstract": "Medical multimodal large language models (MLLMs) are becoming an instrumental\npart of healthcare systems, assisting medical personnel with decision making\nand results analysis. Models for radiology report generation are able to\ninterpret medical imagery, thus reducing the workload of radiologists. As\nmedical data is scarce and protected by privacy regulations, medical MLLMs\nrepresent valuable intellectual property. However, these assets are potentially\nvulnerable to model stealing, where attackers aim to replicate their\nfunctionality via black-box access. So far, model stealing for the medical\ndomain has focused on classification; however, existing attacks are not\neffective against MLLMs. In this paper, we introduce Adversarial Domain\nAlignment (ADA-STEAL), the first stealing attack against medical MLLMs.\nADA-STEAL relies on natural images, which are public and widely available, as\nopposed to their medical counterparts. We show that data augmentation with\nadversarial noise is sufficient to overcome the data distribution gap between\nnatural images and the domain-specific distribution of the victim MLLM.\nExperiments on the IU X-RAY and MIMIC-CXR radiology datasets demonstrate that\nAdversarial Domain Alignment enables attackers to steal the medical MLLM\nwithout any access to medical data."
    },
    {
        "date": "2025-01",
        "title": "How Much Do Code Language Models Remember? An Investigation on Data Extraction Attacks before and after Fine-tuning",
        "author": "Fabio Salerno, Ali Al-Kaswan, and Maliheh Izadi",
        "link": "http://arxiv.org/abs/2501.17501v2",
        "abstract": "Code language models, while widely popular, are often trained on unsanitized\nsource code gathered from across the Internet. Previous work revealed that\npre-trained models can remember the content of their training data and\nregurgitate them through data extraction attacks. Due to the large size of\ncurrent models, only a few entities have the resources for pre-training such\nmodels. However, fine-tuning requires fewer resources and is increasingly used\nby both small and large entities for its effectiveness on specialized data.\nSuch small curated data for fine-tuning might contain sensitive information or\nproprietary assets. In this study, we attack both pre-trained and fine-tuned\ncode language models to investigate the extent of data extractability. We first\ndevelop a custom benchmark to assess the vulnerability of both pre-training and\nfine-tuning samples to extraction attacks. Our findings reveal that 54.9% of\nextractable pre-training data could be retrieved from StarCoder2-15B, whereas\nthis number decreased to 23.5% after fine-tuning. This indicates that\nfine-tuning reduces the extractability of pre-training data. However, compared\nto larger models, fine-tuning smaller models increases their vulnerability to\ndata extraction attacks on fine-tuning data. Given the potential sensitivity of\nfine-tuning data, this can lead to more severe consequences. Lastly, we also\nmanually analyzed 2000 extractable samples before and after fine-tuning. We\nalso found that data carriers and licensing information are the most likely\ndata categories to be memorized from pre-trained and fine-tuned models, while\nthe latter is the most likely to be forgotten after fine-tuning."
    },
    {
        "date": "2025-01",
        "title": "A Floating Normalization Scheme for Deep Learning-Based Custom-Range Parameter Extraction in BSIM-CMG Compact Models",
        "author": "Aasim Ashai, Aakash Jadhav, and Biplab Sarkar",
        "link": "http://arxiv.org/abs/2501.15190v1",
        "abstract": "A deep-learning (DL) based methodology for automated extraction of BSIM-CMG\ncompact model parameters from experimental gate capacitance vs gate voltage\n(Cgg-Vg) and drain current vs gate voltage (Id-Vg) measurements is proposed in\nthis paper. The proposed method introduces a floating normalization scheme\nwithin a cascaded forward and inverse ANN architecture enabling user-defined\nparameter extraction ranges. Unlike conventional DL-based extraction\ntechniques, which are often constrained by fixed normalization ranges, the\nfloating normalization approach adapts dynamically to user-specified ranges,\nallowing for fine-tuned control over the extracted parameters. Experimental\nvalidation, using a TCAD calibrated 14 nm FinFET process, demonstrates high\naccuracy for both Cgg-Vg and Id-Vg parameter extraction. The proposed framework\noffers enhanced flexibility, making it applicable to various compact models\nbeyond BSIM-CMG."
    },
    {
        "date": "2025-01",
        "title": "State Space Models for Extractive Summarization in Low Resource Scenarios",
        "author": "Nisrine Ait Khayi",
        "link": "http://arxiv.org/abs/2501.14673v1",
        "abstract": "Extractive summarization involves selecting the most relevant sentences from\na text. Recently, researchers have focused on advancing methods to improve\nstate-of-the-art results in low-resource settings. Motivated by these\nadvancements, we propose the MPoincareSum method. This method applies the Mamba\nstate space model to generate the semantics of reviews and sentences, which are\nthen concatenated. A Poincare compression is used to select the most meaningful\nfeatures, followed by the application of a linear layer to predict sentence\nrelevance based on the corresponding review. Finally, we paraphrase the\nrelevant sentences to create the final summary. To evaluate the effectiveness\nof MPoincareSum, we conducted extensive experiments using the Amazon review\ndataset. The performance of the method was assessed using ROUGE scores. The\nexperimental results demonstrate that MPoincareSum outperforms several existing\napproaches in the literature"
    },
    {
        "date": "2025-01",
        "title": "GRID: Protecting Training Graph from Link Stealing Attacks on GNN Models",
        "author": "Jiadong Lou, Xu Yuan, Rui Zhang, Xingliang Yuan, Neil Gong, and Nian-Feng Tzeng",
        "link": "http://arxiv.org/abs/2501.10985v2",
        "abstract": "Graph neural networks (GNNs) have exhibited superior performance in various\nclassification tasks on graph-structured data. However, they encounter the\npotential vulnerability from the link stealing attacks, which can infer the\npresence of a link between two nodes via measuring the similarity of its\nincident nodes' prediction vectors produced by a GNN model. Such attacks pose\nsevere security and privacy threats to the training graph used in GNN models.\nIn this work, we propose a novel solution, called Graph Link Disguise (GRID),\nto defend against link stealing attacks with the formal guarantee of GNN model\nutility for retaining prediction accuracy. The key idea of GRID is to add\ncarefully crafted noises to the nodes' prediction vectors for disguising\nadjacent nodes as n-hop indirect neighboring nodes. We take into account the\ngraph topology and select only a subset of nodes (called core nodes) covering\nall links for adding noises, which can avert the noises offset and have the\nfurther advantages of reducing both the distortion loss and the computation\ncost. Our crafted noises can ensure 1) the noisy prediction vectors of any two\nadjacent nodes have their similarity level like that of two non-adjacent nodes\nand 2) the model prediction is unchanged to ensure zero utility loss. Extensive\nexperiments on five datasets are conducted to show the effectiveness of our\nproposed GRID solution against different representative link-stealing attacks\nunder transductive settings and inductive settings respectively, as well as two\ninfluence-based attacks. Meanwhile, it achieves a much better privacy-utility\ntrade-off than existing methods when extended to GNNs."
    },
    {
        "date": "2025-01",
        "title": "Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide",
        "author": "Elena Albu, Shan Gao, Pieter Stijnen, Frank E. Rademakers, Bas C T van Bussel, Taya Collyer, Tina Hernandez-Boussard, Laure Wynants, and Ben Van Calster",
        "link": "http://arxiv.org/abs/2501.10240v2",
        "abstract": "Dynamic predictive modelling using electronic health record (EHR) data has\ngained significant attention in recent years. The reliability and\ntrustworthiness of such models depend heavily on the quality of the underlying\ndata, which is, in part, determined by the stages preceding the model\ndevelopment: data extraction from EHR systems and data preparation. In this\narticle, we identified over forty challenges encountered during these stages\nand provide actionable recommendations for addressing them. These challenges\nare organized into four categories: cohort definition, outcome definition,\nfeature engineering, and data cleaning. This comprehensive list serves as a\npractical guide for data extraction engineers and researchers, promoting best\npractices and improving the quality and real-world applicability of dynamic\nprediction models in clinical settings."
    },
    {
        "date": "2025-01",
        "title": "Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against Model Extraction Attacks",
        "author": "Yixiao Xu, Binxing Fang, Rui Wang, Yinghai Zhou, Shouling Ji, Yuan Liu, Mohan Li, and Zhihong Tian",
        "link": "http://arxiv.org/abs/2501.09328v2",
        "abstract": "Developing high-performance deep learning models is resource-intensive,\nleading model owners to utilize Machine Learning as a Service (MLaaS) platforms\ninstead of publicly releasing their models. However, malicious users may\nexploit query interfaces to execute model extraction attacks, reconstructing\nthe target model's functionality locally. While prior research has investigated\ntriggerable watermarking techniques for asserting ownership, existing methods\nface significant challenges: (1) most approaches require additional training,\nresulting in high overhead and limited flexibility, and (2) they often fail to\naccount for advanced attackers, leaving them vulnerable to adaptive attacks.\n  In this paper, we propose Neural Honeytrace, a robust plug-and-play\nwatermarking framework against model extraction attacks. We first formulate a\nwatermark transmission model from an information-theoretic perspective,\nproviding an interpretable account of the principles and limitations of\nexisting triggerable watermarking. Guided by the model, we further introduce:\n(1) a similarity-based training-free watermarking method for plug-and-play and\nflexible watermarking, and (2) a distribution-based multi-step watermark\ninformation transmission strategy for robust watermarking. Comprehensive\nexperiments on four datasets demonstrate that Neural Honeytrace outperforms\nprevious methods in efficiency and resisting adaptive attacks. Neural\nHoneytrace reduces the average number of samples required for a worst-case\nt-Test-based copyright claim from $12,000$ to $200$ with zero training cost."
    },
    {
        "date": "2025-01",
        "title": "GLiREL -- Generalist Model for Zero-Shot Relation Extraction",
        "author": "Jack Boylan, Chris Hokamp, and Demian Gholipour Ghalandari",
        "link": "http://arxiv.org/abs/2501.03172v1",
        "abstract": "We introduce GLiREL (Generalist Lightweight model for zero-shot Relation\nExtraction), an efficient architecture and training paradigm for zero-shot\nrelation classification. Inspired by recent advancements in zero-shot named\nentity recognition, this work presents an approach to efficiently and\naccurately predict zero-shot relationship labels between multiple entities in a\nsingle forward pass. Experiments using the FewRel and WikiZSL benchmarks\ndemonstrate that our approach achieves state-of-the-art results on the\nzero-shot relation classification task. In addition, we contribute a protocol\nfor synthetically-generating datasets with diverse relation labels."
    },
    {
        "date": "2025-01",
        "title": "HoneypotNet: Backdoor Attacks Against Model Extraction",
        "author": "Yixu Wang, Tianle Gu, Yan Teng, Yingchun Wang, and Xingjun Ma",
        "link": "http://arxiv.org/abs/2501.01090v1",
        "abstract": "Model extraction attacks are one type of inference-time attacks that\napproximate the functionality and performance of a black-box victim model by\nlaunching a certain number of queries to the model and then leveraging the\nmodel's predictions to train a substitute model. These attacks pose severe\nsecurity threats to production models and MLaaS platforms and could cause\nsignificant monetary losses to the model owners. A body of work has proposed to\ndefend machine learning models against model extraction attacks, including both\nactive defense methods that modify the model's outputs or increase the query\noverhead to avoid extraction and passive defense methods that detect malicious\nqueries or leverage watermarks to perform post-verification. In this work, we\nintroduce a new defense paradigm called attack as defense which modifies the\nmodel's output to be poisonous such that any malicious users that attempt to\nuse the output to train a substitute model will be poisoned. To this end, we\npropose a novel lightweight backdoor attack method dubbed HoneypotNet that\nreplaces the classification layer of the victim model with a honeypot layer and\nthen fine-tunes the honeypot layer with a shadow model (to simulate model\nextraction) via bi-level optimization to modify its output to be poisonous\nwhile remaining the original performance. We empirically demonstrate on four\ncommonly used benchmark datasets that HoneypotNet can inject backdoors into\nsubstitute models with a high success rate. The injected backdoor not only\nfacilitates ownership verification but also disrupts the functionality of\nsubstitute models, serving as a significant deterrent to model extraction\nattacks."
    },
    {
        "date": "2024-12",
        "title": "Extracting effective solutions hidden in large language models via generated comprehensive specialists: case studies in developing electronic devices",
        "author": "Hikari Tomita, Nobuhiro Nakamura, Shoichi Ishida, Toshio Kamiya, and Kei Terayama",
        "link": "http://arxiv.org/abs/2501.00224v1",
        "abstract": "Recently, many studies have increasingly explored the use of large language\nmodels (LLMs) to generate research ideas and scientific hypotheses. However,\nreal-world research and development often require solving complex,\ninterdisciplinary challenges where solutions may not be readily found through\nexisting knowledge related to the problem. Therefore, it is desirable to\nleverage the vast, comprehensive knowledge of LLMs to generate effective,\nbreakthrough solutions by integrating various perspectives from other\ndisciplines. Here, we propose SELLM (Solution Enumeration via comprehensive\nList and LLM), a framework leveraging LLMs and structured guidance using MECE\n(Mutually Exclusive, Collectively Exhaustive) principles, such as International\nPatent Classification (IPC) and the periodic table of elements. SELLM\nsystematically constructs comprehensive expert agents from the list to generate\ncross-disciplinary and effective solutions. To evaluate SELLM's practicality,\nwe applied it to two challenges: improving light extraction in organic\nlight-emitting diode (OLED) lighting and developing electrodes for\nnext-generation memory materials. The results demonstrate that SELLM\nsignificantly facilitates the generation of effective solutions compared to\ncases without specific customization or effort, showcasing the potential of\nSELLM to enable LLMs to generate effective solutions even for challenging\nproblems."
    },
    {
        "date": "2024-12",
        "title": "Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models",
        "author": "Zihan Zhou, Ziyi Zeng, Wenhao Jiang, Yihui Zhu, Jiaxin Mao, Yonggui Yuan, Min Xia, Shubin Zhao, Mengyu Yao, and Yunqian Chen",
        "link": "http://arxiv.org/abs/2412.18419v1",
        "abstract": "As social changes accelerate, the incidence of psychosomatic disorders has\nsignificantly increased, becoming a major challenge in global health issues.\nThis necessitates an innovative knowledge system and analytical methods to aid\nin diagnosis and treatment. Here, we establish the ontology model and entity\ntypes, using the BERT model and LoRA-tuned LLM for named entity recognition,\nconstructing the knowledge graph with 9668 triples. Next, by analyzing the\nnetwork distances between disease, symptom, and drug modules, it was found that\ncloser network distances among diseases can predict greater similarities in\ntheir clinical manifestations, treatment approaches, and psychological\nmechanisms, and closer distances between symptoms indicate that they are more\nlikely to co-occur. Lastly, by comparing the proximity d and proximity z score,\nit was shown that symptom-disease pairs in primary diagnostic relationships\nhave a stronger association and are of higher referential value than those in\ndiagnostic relationships. The research results revealed the potential\nconnections between diseases, co-occurring symptoms, and similarities in\ntreatment strategies, providing new perspectives for the diagnosis and\ntreatment of psychosomatic disorders and valuable information for future mental\nhealth research and practice."
    },
    {
        "date": "2024-12",
        "title": "GeneSUM: Large Language Model-based Gene Summary Extraction",
        "author": "Zhijian Chen, Chuan Hu, Min Wu, Qingqing Long, Xuezhi Wang, Yuanchun Zhou, and Meng Xiao",
        "link": "http://arxiv.org/abs/2412.18154v1",
        "abstract": "Emerging topics in biomedical research are continuously expanding, providing\na wealth of information about genes and their function. This rapid\nproliferation of knowledge presents unprecedented opportunities for scientific\ndiscovery and formidable challenges for researchers striving to keep abreast of\nthe latest advancements. One significant challenge is navigating the vast\ncorpus of literature to extract vital gene-related information, a\ntime-consuming and cumbersome task. To enhance the efficiency of this process,\nit is crucial to address several key challenges: (1) the overwhelming volume of\nliterature, (2) the complexity of gene functions, and (3) the automated\nintegration and generation. In response, we propose GeneSUM, a two-stage\nautomated gene summary extractor utilizing a large language model (LLM). Our\napproach retrieves and eliminates redundancy of target gene literature and then\nfine-tunes the LLM to refine and streamline the summarization process. We\nconducted extensive experiments to validate the efficacy of our proposed\nframework. The results demonstrate that LLM significantly enhances the\nintegration of gene-specific information, allowing more efficient\ndecision-making in ongoing research."
    },
    {
        "date": "2024-12",
        "title": "Automated CVE Analysis: Harnessing Machine Learning In Designing Question-Answering Models For Cybersecurity Information Extraction",
        "author": "Tanjim Bin Faruk",
        "link": "http://arxiv.org/abs/2412.16484v1",
        "abstract": "The vast majority of cybersecurity information is unstructured text,\nincluding critical data within databases such as CVE, NVD, CWE, CAPEC, and the\nMITRE ATT&CK Framework. These databases are invaluable for analyzing attack\npatterns and understanding attacker behaviors. Creating a knowledge graph by\nintegrating this information could unlock significant insights. However,\nprocessing this large amount of data requires advanced deep-learning\ntechniques. A crucial step towards building such a knowledge graph is\ndeveloping a robust mechanism for automating the extraction of answers to\nspecific questions from the unstructured text. Question Answering (QA) systems\nplay a pivotal role in this process by pinpointing and extracting precise\ninformation, facilitating the mapping of relationships between various data\npoints. In the cybersecurity context, QA systems encounter unique challenges\ndue to the need to interpret and answer questions based on a wide array of\ndomain-specific information. To tackle these challenges, it is necessary to\ndevelop a cybersecurity-specific dataset and train a machine learning model on\nit, aimed at enhancing the understanding and retrieval of domain-specific\ninformation. This paper presents a novel dataset and describes a machine\nlearning model trained on this dataset for the QA task. It also discusses the\nmodel's performance and key findings in a manner that maintains a balance\nbetween formality and accessibility."
    },
    {
        "date": "2024-12",
        "title": "Extracting Interpretable Task-Specific Circuits from Large Language Models for Faster Inference",
        "author": "Jorge Garc\u00eda-Carrasco, Alejandro Mat\u00e9, and Juan Trujillo",
        "link": "http://arxiv.org/abs/2412.15750v1",
        "abstract": "Large Language Models (LLMs) have shown impressive performance across a wide\nrange of tasks. However, the size of LLMs is steadily increasing, hindering\ntheir application on computationally constrained environments. On the other\nhand, despite their general capabilities, there are many situations where only\none specific task is performed, rendering all other capabilities unnecessary\nand wasteful. This leads us to the following question: Is it possible to\nextract the minimal subset from an LLM that is able to perform a specific task\nin a faster, standalone manner? Recent works on Mechanistic Interpretability\n(MI) have shown that specific tasks are performed by a localized subset of\ncomponents, or circuit. However, current techniques used to identify the\ncircuit cannot be used to extract it for its standalone usage. In this work, we\npropose a novel approach to automatically extract the subset of the LLM that\nproperly performs a targeted task requiring no additional training and a small\namount of data samples. We evaluate our approach on different tasks and show\nthat the resulting models are (i) considerably smaller, reducing the number of\nparameters up to 82.77% and (ii) more interpretable, as they focus on the\ncircuit that is used to carry out the specific task, and can therefore be\nunderstood using MI techniques."
    },
    {
        "date": "2024-12",
        "title": "Towards scientific discovery with dictionary learning: Extracting biological concepts from microscopy foundation models",
        "author": "Konstantin Donhauser, Kristina Ulicna, Gemma Elyse Moran, Aditya Ravuri, Kian Kenyon-Dean, Cian Eastwood, and Jason Hartford",
        "link": "http://arxiv.org/abs/2412.16247v2",
        "abstract": "Dictionary learning (DL) has emerged as a powerful interpretability tool for\nlarge language models. By extracting known concepts (e.g., Golden-Gate Bridge)\nfrom human-interpretable data (e.g., text), sparse DL can elucidate a model's\ninner workings. In this work, we ask if DL can also be used to discover unknown\nconcepts from less human-interpretable scientific data (e.g., cell images),\nultimately enabling modern approaches to scientific discovery. As a first step,\nwe use DL algorithms to study microscopy foundation models trained on\nmulti-cell image data, where little prior knowledge exists regarding which\nhigh-level concepts should arise. We show that sparse dictionaries indeed\nextract biologically-meaningful concepts such as cell type and genetic\nperturbation type. We also propose Iterative Codebook Feature Learning~(ICFL)\nand combine it with a pre-processing step which uses PCA whitening from a\ncontrol dataset. In our experiments, we demonstrate that both ICFL and PCA\nimprove the selectivity of extracted features compared to TopK sparse\nautoencoders."
    },
    {
        "date": "2024-12",
        "title": "Exploring Query Efficient Data Generation towards Data-free Model Stealing in Hard Label Setting",
        "author": "Gaozheng Pei, Shaojie lyu, Ke Ma, Pinci Yang, Qianqian Xu, and Yingfei Sun",
        "link": "http://arxiv.org/abs/2412.15276v1",
        "abstract": "Data-free model stealing involves replicating the functionality of a target\nmodel into a substitute model without accessing the target model's structure,\nparameters, or training data. The adversary can only access the target model's\npredictions for generated samples. Once the substitute model closely\napproximates the behavior of the target model, attackers can exploit its\nwhite-box characteristics for subsequent malicious activities, such as\nadversarial attacks. Existing methods within cooperative game frameworks often\nproduce samples with high confidence for the prediction of the substitute\nmodel, which makes it difficult for the substitute model to replicate the\nbehavior of the target model. This paper presents a new data-free model\nstealing approach called Query Efficient Data Generation (\\textbf{QEDG}). We\nintroduce two distinct loss functions to ensure the generation of sufficient\nsamples that closely and uniformly align with the target model's decision\nboundary across multiple classes. Building on the limitation of current\nmethods, which typically yield only one piece of supervised information per\nquery, we propose the query-free sample augmentation that enables the\nacquisition of additional supervised information without increasing the number\nof queries. Motivated by theoretical analysis, we adopt the consistency rate\nmetric, which more accurately evaluates the similarity between the substitute\nand target models. We conducted extensive experiments to verify the\neffectiveness of our proposed method, which achieved better performance with\nfewer queries compared to the state-of-the-art methods on the real\n\\textbf{MLaaS} scenario and five datasets."
    },
    {
        "date": "2024-12",
        "title": "Leveraging Foundation Language Models (FLMs) for Automated Cohort Extraction from Large EHR Databases",
        "author": "Purity Mugambi, Alexandra Meliou, and Madalina Fiterau",
        "link": "http://arxiv.org/abs/2412.11472v1",
        "abstract": "A crucial step in cohort studies is to extract the required cohort from one\nor more study datasets. This step is time-consuming, especially when a\nresearcher is presented with a dataset that they have not previously worked\nwith. When the cohort has to be extracted from multiple datasets, cohort\nextraction can be extremely laborious. In this study, we present an approach\nfor partially automating cohort extraction from multiple electronic health\nrecord (EHR) databases. We formulate the guided multi-dataset cohort extraction\nproblem in which selection criteria are first converted into queries,\ntranslating them from natural language text to language that maps to database\nentities. Then, using FLMs, columns of interest identified from the queries are\nautomatically matched between the study databases. Finally, the generated\nqueries are run across all databases to extract the study cohort. We propose\nand evaluate an algorithm for automating column matching on two large, popular\nand publicly-accessible EHR databases -- MIMIC-III and eICU. Our approach\nachieves a high top-three accuracy of $92\\%$, correctly matching $12$ out of\nthe $13$ columns of interest, when using a small, pre-trained general purpose\nlanguage model. Furthermore, this accuracy is maintained even as the search\nspace (i.e., size of the database) increases."
    },
    {
        "date": "2024-12",
        "title": "Extracting PAC Decision Trees from Black Box Binary Classifiers: The Gender Bias Study Case on BERT-based Language Models",
        "author": "Ana Ozaki, Roberto Confalonieri, Ricardo Guimar\u00e3es, and Anders Imenes",
        "link": "http://arxiv.org/abs/2412.10513v1",
        "abstract": "Decision trees are a popular machine learning method, known for their\ninherent explainability. In Explainable AI, decision trees can be used as\nsurrogate models for complex black box AI models or as approximations of parts\nof such models. A key challenge of this approach is determining how accurately\nthe extracted decision tree represents the original model and to what extent it\ncan be trusted as an approximation of their behavior. In this work, we\ninvestigate the use of the Probably Approximately Correct (PAC) framework to\nprovide a theoretical guarantee of fidelity for decision trees extracted from\nAI models. Based on theoretical results from the PAC framework, we adapt a\ndecision tree algorithm to ensure a PAC guarantee under certain conditions. We\nfocus on binary classification and conduct experiments where we extract\ndecision trees from BERT-based language models with PAC guarantees. Our results\nindicate occupational gender bias in these models."
    },
    {
        "date": "2024-12",
        "title": "Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Pathology Analysis",
        "author": "Shengxuming Zhang, Weihan Li, Tianhong Gao, Jiacong Hu, Haoming Luo, Xiuming Zhang, Jing Zhang, Mingli Song, and Zunlei Feng",
        "link": "http://arxiv.org/abs/2412.09521v3",
        "abstract": "Pathological diagnosis is vital for determining disease characteristics,\nguiding treatment, and assessing prognosis, relying heavily on detailed,\nmulti-scale analysis of high-resolution whole slide images (WSI). However,\nexisting large vision-language models (LVLMs) are limited by input resolution\nconstraints, hindering their efficiency and accuracy in pathology image\nanalysis. To overcome these issues, we propose two innovative strategies: the\nmixed task-guided feature enhancement, which directs feature extraction toward\nlesion-related details across scales, and the prompt-guided detail feature\ncompletion, which integrates coarse- and fine-grained features from WSI based\non specific prompts without compromising inference speed. Leveraging a\ncomprehensive dataset of 490K samples from diverse pathology tasks, we trained\nthe pathology-specialized LVLM, OmniPath. Extensive experiments demonstrate\nthat this model significantly outperforms existing methods in diagnostic\naccuracy and efficiency, providing an interactive, clinically aligned approach\nfor auxiliary diagnosis in a wide range of pathology applications."
    },
    {
        "date": "2024-12",
        "title": "Kajal: Extracting Grammar of a Source Code Using Large Language Models",
        "author": "Mohammad Jalili Torkamani",
        "link": "http://arxiv.org/abs/2412.08842v1",
        "abstract": "Understanding and extracting the grammar of a domain-specific language (DSL)\nis crucial for various software engineering tasks; however, manually creating\nthese grammars is time-intensive and error-prone. This paper presents Kajal, a\nnovel approach that automatically infers grammar from DSL code snippets by\nleveraging Large Language Models (LLMs) through prompt engineering and few-shot\nlearning. Kajal dynamically constructs input prompts, using contextual\ninformation to guide the LLM in generating the corresponding grammars, which\nare iteratively refined through a feedback-driven approach. Our experiments\nshow that Kajal achieves 60% accuracy with few-shot learning and 45% without\nit, demonstrating the significant impact of few-shot learning on the tool's\neffectiveness. This approach offers a promising solution for automating DSL\ngrammar extraction, and future work will explore using smaller, open-source\nLLMs and testing on larger datasets to further validate Kajal's performance."
    },
    {
        "date": "2024-12",
        "title": "A Unified Model For Voice and Accent Conversion In Speech and Singing using Self-Supervised Learning and Feature Extraction",
        "author": "Sowmya Cheripally",
        "link": "http://arxiv.org/abs/2412.08312v1",
        "abstract": "This paper presents a new voice conversion model capable of transforming both\nspeaking and singing voices. It addresses key challenges in current systems,\nsuch as conveying emotions, managing pronunciation and accent changes, and\nreproducing non-verbal sounds. One of the model's standout features is its\nability to perform accent conversion on hybrid voice samples that encompass\nboth speech and singing, allowing it to change the speaker's accent while\npreserving the original content and prosody. The proposed model uses an\nencoder-decoder architecture: the encoder is based on HuBERT to process the\nspeech's acoustic and linguistic content, while the HiFi-GAN decoder audio\nmatches the target speaker's voice. The model incorporates fundamental\nfrequency (f0) features and singer embeddings to enhance performance while\nensuring the pitch & tone accuracy and vocal identity are preserved during\ntransformation. This approach improves how naturally and flexibly voice style\ncan be transformed, showing strong potential for applications in voice dubbing,\ncontent creation, and technologies like Text-to-Speech (TTS) and Interactive\nVoice Response (IVR) systems."
    },
    {
        "date": "2024-12",
        "title": "Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks",
        "author": "Faqian Guan, Tianqing Zhu, Wenhan Chang, Wei Ren, and Wanlei Zhou",
        "link": "http://arxiv.org/abs/2412.05830v1",
        "abstract": "Graph Neural Networks (GNNs), specifically designed to process the graph\ndata, have achieved remarkable success in various applications. Link stealing\nattacks on graph data pose a significant privacy threat, as attackers aim to\nextract sensitive relationships between nodes (entities), potentially leading\nto academic misconduct, fraudulent transactions, or other malicious activities.\nPrevious studies have primarily focused on single datasets and did not explore\ncross-dataset attacks, let alone attacks that leverage the combined knowledge\nof multiple attackers. However, we find that an attacker can combine the data\nknowledge of multiple attackers to create a more effective attack model, which\ncan be referred to cross-dataset attacks. Moreover, if knowledge can be\nextracted with the help of Large Language Models (LLMs), the attack capability\nwill be more significant. In this paper, we propose a novel link stealing\nattack method that takes advantage of cross-dataset and Large Language Models\n(LLMs). The LLM is applied to process datasets with different data structures\nin cross-dataset attacks. Each attacker fine-tunes the LLM on their specific\ndataset to generate a tailored attack model. We then introduce a novel model\nmerging method to integrate the parameters of these attacker-specific models\neffectively. The result is a merged attack model with superior generalization\ncapabilities, enabling effective attacks not only on the attackers' datasets\nbut also on previously unseen (out-of-domain) datasets. We conducted extensive\nexperiments in four datasets to demonstrate the effectiveness of our method.\nAdditional experiments with three different GNN and LLM architectures further\nillustrate the generality of our approach."
    },
    {
        "date": "2024-12",
        "title": "Espresso: High Compression For Rich Extraction From Videos for Your Vision-Language Model",
        "author": "Keunwoo Peter Yu, Achal Dave, Rares Ambrus, and Jean Mercat",
        "link": "http://arxiv.org/abs/2412.04729v3",
        "abstract": "Recent advances in vision-language models (VLMs) have shown great promise in\nconnecting images and text, but extending these models to long videos remains\nchallenging due to the rapid growth in token counts. Models that compress\nvideos by local aggregation in time or space have become popular for handling\nlong-form inputs; however, these pooling-based projectors sacrifice the\nbenefits of fixed-length representations that are crucial for streaming and\nefficient video understanding. We introduce $\\texttt{Espresso}$, a new\narchitecture that separately compresses spatial and temporal features into\nfixed-length sequences. $\\texttt{Espresso}$ enables efficient video encoding\nwhile maintaining strong long-form reasoning capabilities. Experiments show\nthat fixed-length compression combined with segment-wise processing offers a\nscalable and competitive alternative to pooling-based approaches. Our results\ndemonstrate that fixed-length projectors, when properly designed and trained,\nremain a viable foundation for video-language modeling."
    },
    {
        "date": "2024-12",
        "title": "Prompting Large Language Models for Clinical Temporal Relation Extraction",
        "author": "Jianping He, Laila Rasmy, Haifang Li, Jianfu Li, Zenan Sun, Evan Yu, Degui Zhi, and Cui Tao",
        "link": "http://arxiv.org/abs/2412.04512v1",
        "abstract": "Objective: This paper aims to prompt large language models (LLMs) for\nclinical temporal relation extraction (CTRE) in both few-shot and fully\nsupervised settings. Materials and Methods: This study utilizes four LLMs:\nEncoder-based GatorTron-Base (345M)/Large (8.9B); Decoder-based\nLLaMA3-8B/MeLLaMA-13B. We developed full (FFT) and parameter-efficient (PEFT)\nfine-tuning strategies and evaluated these strategies on the 2012 i2b2 CTRE\ntask. We explored four fine-tuning strategies for GatorTron-Base: (1) Standard\nFine-Tuning, (2) Hard-Prompting with Unfrozen LLMs, (3) Soft-Prompting with\nFrozen LLMs, and (4) Low-Rank Adaptation (LoRA) with Frozen LLMs. For\nGatorTron-Large, we assessed two PEFT strategies-Soft-Prompting and LoRA with\nFrozen LLMs-leveraging Quantization techniques. Additionally, LLaMA3-8B and\nMeLLaMA-13B employed two PEFT strategies: LoRA strategy with Quantization\n(QLoRA) applied to Frozen LLMs using instruction tuning and standard\nfine-tuning. Results: Under fully supervised settings, Hard-Prompting with\nUnfrozen GatorTron-Base achieved the highest F1 score (89.54%), surpassing the\nSOTA model (85.70%) by 3.74%. Additionally, two variants of QLoRA adapted to\nGatorTron-Large and Standard Fine-Tuning of GatorTron-Base exceeded the SOTA\nmodel by 2.36%, 1.88%, and 0.25%, respectively. Decoder-based models with\nfrozen parameters outperformed their Encoder-based counterparts in this\nsetting; however, the trend reversed in few-shot scenarios. Discussions and\nConclusions: This study presented new methods that significantly improved CTRE\nperformance, benefiting downstream tasks reliant on CTRE systems. The findings\nunderscore the importance of selecting appropriate models and fine-tuning\nstrategies based on task requirements and data availability. Future work will\nexplore larger models and broader CTRE applications."
    },
    {
        "date": "2024-12",
        "title": "A Review on Scientific Knowledge Extraction using Large Language Models in Biomedical Sciences",
        "author": "Gabriel Lino Garcia, Jo\u00e3o Renato Ribeiro Manesco, Pedro Henrique Paiola, Lucas Miranda, Maria Paola de Salvo, and Jo\u00e3o Paulo Papa",
        "link": "http://arxiv.org/abs/2412.03531v1",
        "abstract": "The rapid advancement of large language models (LLMs) has opened new\nboundaries in the extraction and synthesis of medical knowledge, particularly\nwithin evidence synthesis. This paper reviews the state-of-the-art applications\nof LLMs in the biomedical domain, exploring their effectiveness in automating\ncomplex tasks such as evidence synthesis and data extraction from a biomedical\ncorpus of documents. While LLMs demonstrate remarkable potential, significant\nchallenges remain, including issues related to hallucinations, contextual\nunderstanding, and the ability to generalize across diverse medical tasks. We\nhighlight critical gaps in the current research literature, particularly the\nneed for unified benchmarks to standardize evaluations and ensure reliability\nin real-world applications. In addition, we propose directions for future\nresearch, emphasizing the integration of state-of-the-art techniques such as\nretrieval-augmented generation (RAG) to enhance LLM performance in evidence\nsynthesis. By addressing these challenges and utilizing the strengths of LLMs,\nwe aim to improve access to medical literature and facilitate meaningful\ndiscoveries in healthcare."
    },
    {
        "date": "2024-11",
        "title": "Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models",
        "author": "Valentina Anita Carriero, Antonia Azzini, Ilaria Baroni, Mario Scrocca, and Irene Celino",
        "link": "http://arxiv.org/abs/2412.03589v1",
        "abstract": "Procedural Knowledge is the know-how expressed in the form of sequences of\nsteps needed to perform some tasks. Procedures are usually described by means\nof natural language texts, such as recipes or maintenance manuals, possibly\nspread across different documents and systems, and their interpretation and\nsubsequent execution is often left to the reader. Representing such procedures\nin a Knowledge Graph (KG) can be the basis to build digital tools to support\nthose users who need to apply or execute them. In this paper, we leverage Large\nLanguage Model (LLM) capabilities and propose a prompt engineering approach to\nextract steps, actions, objects, equipment and temporal information from a\ntextual procedure, in order to populate a Procedural KG according to a\npre-defined ontology. We evaluate the KG extraction results by means of a user\nstudy, in order to qualitatively and quantitatively assess the perceived\nquality and usefulness of the LLM-extracted procedural knowledge. We show that\nLLMs can produce outputs of acceptable quality and we assess the subjective\nperception of AI by human evaluators."
    },
    {
        "date": "2024-11",
        "title": "A survey on cutting-edge relation extraction techniques based on language models",
        "author": "Jose A. Diaz-Garcia, and Julio Amador Diaz Lopez",
        "link": "http://arxiv.org/abs/2411.18157v1",
        "abstract": "This comprehensive survey delves into the latest advancements in Relation\nExtraction (RE), a pivotal task in natural language processing essential for\napplications across biomedical, financial, and legal sectors. This study\nhighlights the evolution and current state of RE techniques by analyzing 137\npapers presented at the Association for Computational Linguistics (ACL)\nconferences over the past four years, focusing on models that leverage language\nmodels. Our findings underscore the dominance of BERT-based methods in\nachieving state-of-the-art results for RE while also noting the promising\ncapabilities of emerging large language models (LLMs) like T5, especially in\nfew-shot relation extraction scenarios where they excel in identifying\npreviously unseen relations."
    },
    {
        "date": "2024-11",
        "title": "DocEDA: Automated Extraction and Design of Analog Circuits from Documents with Large Language Model",
        "author": "Hong Cai Chen, Longchang Wu, Ming Gao, Lingrui Shen, Jiarui Zhong, and Yipin Xu",
        "link": "http://arxiv.org/abs/2412.05301v1",
        "abstract": "Efficient and accurate extraction of electrical parameters from circuit\ndatasheets and design documents is critical for accelerating circuit design in\nElectronic Design Automation (EDA). Traditional workflows often rely on\nengineers manually searching and extracting these parameters, which is\ntime-consuming, and prone to human error. To address these challenges, we\nintroduce DocEDA, an automated system that leverages advanced computer vision\ntechniques and Large Language Models (LLMs) to extract electrical parameters\nseamlessly from documents. The layout analysis model specifically designed for\ndatasheet is proposed to classify documents into circuit-related parts.\nUtilizing the inherent Chain-of-Thought reasoning capabilities of LLMs, DocEDA\nautomates the extraction of electronic component parameters from documents. For\ncircuit diagrams parsing, an improved GAM-YOLO model is hybrid with topology\nidentification to transform diagrams into circuit netlists. Then, a space\nmapping enhanced optimization framework is evoked for optimization the layout\nin the document. Experimental evaluations demonstrate that DocEDA significantly\nenhances the efficiency of processing circuit design documents and the accuracy\nof electrical parameter extraction. It exhibits adaptability to various circuit\ndesign scenarios and document formats, offering a novel solution for EDA with\nthe potential to transform traditional methodologies."
    },
    {
        "date": "2024-11",
        "title": "RAMIE: Retrieval-Augmented Multi-task Information Extraction with Large Language Models on Dietary Supplements",
        "author": "Zaifu Zhan, Shuang Zhou, Mingchen Li, and Rui Zhang",
        "link": "http://arxiv.org/abs/2411.15700v1",
        "abstract": "\\textbf{Objective:} We aimed to develop an advanced multi-task large language\nmodel (LLM) framework to extract multiple types of information about dietary\nsupplements (DS) from clinical records.\n  \\textbf{Methods:} We used four core DS information extraction tasks - namely,\nnamed entity recognition (NER: 2,949 clinical sentences), relation extraction\n(RE: 4,892 sentences), triple extraction (TE: 2,949 sentences), and usage\nclassification (UC: 2,460 sentences) as our multitasks. We introduced a novel\nRetrieval-Augmented Multi-task Information Extraction (RAMIE) Framework,\nincluding: 1) employed instruction fine-tuning techniques with task-specific\nprompts, 2) trained LLMs for multiple tasks with improved storage efficiency\nand lower training costs, and 3) incorporated retrieval augmentation generation\n(RAG) techniques by retrieving similar examples from the training set. We\ncompared RAMIE's performance to LLMs with instruction fine-tuning alone and\nconducted an ablation study to assess the contributions of multi-task learning\nand RAG to improved multitasking performance.\n  \\textbf{Results:} With the aid of the RAMIE framework, Llama2-13B achieved an\nF1 score of 87.39 (3.51\\% improvement) on the NER task and demonstrated\noutstanding performance on the RE task with an F1 score of 93.74 (1.15\\%\nimprovement). For the TE task, Llama2-7B scored 79.45 (14.26\\% improvement),\nand MedAlpaca-7B achieved the highest F1 score of 93.45 (0.94\\% improvement) on\nthe UC task. The ablation study revealed that while MTL increased efficiency\nwith a slight trade-off in performance, RAG significantly boosted overall\naccuracy.\n  \\textbf{Conclusion:} This study presents a novel RAMIE framework that\ndemonstrates substantial improvements in multi-task information extraction for\nDS-related data from clinical records. Our framework can potentially be applied\nto other domains."
    },
    {
        "date": "2024-11",
        "title": "Variable Extraction for Model Recovery in Scientific Literature",
        "author": "Chunwei Liu, Enrique Noriega-Atala, Adarsh Pyarelal, Clayton T Morrison, and Mike Cafarella",
        "link": "http://arxiv.org/abs/2411.14569v1",
        "abstract": "The global output of academic publications exceeds 5 million articles per\nyear, making it difficult for humans to keep up with even a tiny fraction of\nscientific output. We need methods to navigate and interpret the artifacts --\ntexts, graphs, charts, code, models, and datasets -- that make up the\nliterature. This paper evaluates various methods for extracting mathematical\nmodel variables from epidemiological studies, such as ``infection rate\n($\\alpha$),'' ``recovery rate ($\\gamma$),'' and ``mortality rate ($\\mu$).''\nVariable extraction appears to be a basic task, but plays a pivotal role in\nrecovering models from scientific literature. Once extracted, we can use these\nvariables for automatic mathematical modeling, simulation, and replication of\npublished results.\n  We introduce a benchmark dataset comprising manually-annotated variable\ndescriptions and variable values extracted from scientific papers. Based on\nthis dataset, we present several baseline methods for variable extraction based\non Large Language Models (LLMs) and rule-based information extraction systems.\nOur analysis shows that LLM-based solutions perform the best. Despite the\nincremental benefits of combining rule-based extraction outputs with LLMs, the\nleap in performance attributed to the transfer-learning and instruction-tuning\ncapabilities of LLMs themselves is far more significant. This investigation\ndemonstrates the potential of LLMs to enhance automatic comprehension of\nscientific artifacts and for automatic model recovery and simulation."
    },
    {
        "date": "2024-11",
        "title": "Bounding-box Watermarking: Defense against Model Extraction Attacks on Object Detectors",
        "author": "Satoru Koda, and Ikuya Morikawa",
        "link": "http://arxiv.org/abs/2411.13047v1",
        "abstract": "Deep neural networks (DNNs) deployed in a cloud often allow users to query\nmodels via the APIs. However, these APIs expose the models to model extraction\nattacks (MEAs). In this attack, the attacker attempts to duplicate the target\nmodel by abusing the responses from the API. Backdoor-based DNN watermarking is\nknown as a promising defense against MEAs, wherein the defender injects a\nbackdoor into extracted models via API responses. The backdoor is used as a\nwatermark of the model; if a suspicious model has the watermark (i.e.,\nbackdoor), it is verified as an extracted model. This work focuses on object\ndetection (OD) models. Existing backdoor attacks on OD models are not\napplicable for model watermarking as the defense against MEAs on a realistic\nthreat model. Our proposed approach involves inserting a backdoor into\nextracted models via APIs by stealthily modifying the bounding-boxes (BBs) of\nobjects detected in queries while keeping the OD capability. In our experiments\non three OD datasets, the proposed approach succeeded in identifying the\nextracted models with 100% accuracy in a wide variety of experimental\nscenarios."
    },
    {
        "date": "2024-11",
        "title": "StreetviewLLM: Extracting Geographic Information Using a Chain-of-Thought Multimodal Large Language Model",
        "author": "Zongrong Li, Junhao Xu, Siqin Wang, Yifan Wu, and Haiyang Li",
        "link": "http://arxiv.org/abs/2411.14476v1",
        "abstract": "Geospatial predictions are crucial for diverse fields such as disaster\nmanagement, urban planning, and public health. Traditional machine learning\nmethods often face limitations when handling unstructured or multi-modal data\nlike street view imagery. To address these challenges, we propose\nStreetViewLLM, a novel framework that integrates a large language model with\nthe chain-of-thought reasoning and multimodal data sources. By combining street\nview imagery with geographic coordinates and textual data, StreetViewLLM\nimproves the precision and granularity of geospatial predictions. Using\nretrieval-augmented generation techniques, our approach enhances geographic\ninformation extraction, enabling a detailed analysis of urban environments. The\nmodel has been applied to seven global cities, including Hong Kong, Tokyo,\nSingapore, Los Angeles, New York, London, and Paris, demonstrating superior\nperformance in predicting urban indicators, including population density,\naccessibility to healthcare, normalized difference vegetation index, building\nheight, and impervious surface. The results show that StreetViewLLM\nconsistently outperforms baseline models, offering improved predictive accuracy\nand deeper insights into the built environment. This research opens new\nopportunities for integrating the large language model into urban analytics,\ndecision-making in urban planning, infrastructure management, and environmental\nmonitoring."
    },
    {
        "date": "2024-11",
        "title": "LLM-IE: A Python Package for Generative Information Extraction with Large Language Models",
        "author": "Enshuo Hsu, and Kirk Roberts",
        "link": "http://arxiv.org/abs/2411.11779v1",
        "abstract": "Objectives: Despite the recent adoption of large language models (LLMs) for\nbiomedical information extraction, challenges in prompt engineering and\nalgorithms persist, with no dedicated software available. To address this, we\ndeveloped LLM-IE: a Python package for building complete information extraction\npipelines. Our key innovation is an interactive LLM agent to support schema\ndefinition and prompt design.\n  Materials and Methods: The LLM-IE supports named entity recognition, entity\nattribute extraction, and relation extraction tasks. We benchmarked on the i2b2\ndatasets and conducted a system evaluation.\n  Results: The sentence-based prompting algorithm resulted in the best\nperformance while requiring a longer inference time. System evaluation provided\nintuitive visualization.\n  Discussion: LLM-IE was designed from practical NLP experience in healthcare\nand has been adopted in internal projects. It should hold great value to the\nbiomedical NLP community.\n  Conclusion: We developed a Python package, LLM-IE, that provides building\nblocks for robust information extraction pipeline construction."
    },
    {
        "date": "2024-11",
        "title": "Few-shot Model Extraction Attacks against Sequential Recommender Systems",
        "author": "Hui Zhang, and Fu Liu",
        "link": "http://arxiv.org/abs/2411.11677v2",
        "abstract": "Among adversarial attacks against sequential recommender systems, model\nextraction attacks represent a method to attack sequential recommendation\nmodels without prior knowledge. Existing research has primarily concentrated on\nthe adversary's execution of black-box attacks through data-free model\nextraction. However, a significant gap remains in the literature concerning the\ndevelopment of surrogate models by adversaries with access to few-shot raw data\n(10\\% even less). That is, the challenge of how to construct a surrogate model\nwith high functional similarity within the context of few-shot data scenarios\nremains an issue that requires resolution.This study addresses this gap by\nintroducing a novel few-shot model extraction framework against sequential\nrecommenders, which is designed to construct a superior surrogate model with\nthe utilization of few-shot data. The proposed few-shot model extraction\nframework is comprised of two components: an autoregressive augmentation\ngeneration strategy and a bidirectional repair loss-facilitated model\ndistillation procedure. Specifically, to generate synthetic data that closely\napproximate the distribution of raw data, autoregressive augmentation\ngeneration strategy integrates a probabilistic interaction sampler to extract\ninherent dependencies and a synthesis determinant signal module to characterize\nuser behavioral patterns. Subsequently, bidirectional repair loss, which target\nthe discrepancies between the recommendation lists, is designed as auxiliary\nloss to rectify erroneous predictions from surrogate models, transferring\nknowledge from the victim model to the surrogate model effectively. Experiments\non three datasets show that the proposed few-shot model extraction framework\nyields superior surrogate models."
    },
    {
        "date": "2024-11",
        "title": "Chapter 7 Review of Data-Driven Generative AI Models for Knowledge Extraction from Scientific Literature in Healthcare",
        "author": "Leon Kopitar, Primoz Kocbek, Lucija Gosak, and Gregor Stiglic",
        "link": "http://arxiv.org/abs/2411.11635v1",
        "abstract": "This review examines the development of abstractive NLP-based text\nsummarization approaches and compares them to existing techniques for\nextractive summarization. A brief history of text summarization from the 1950s\nto the introduction of pre-trained language models such as Bidirectional\nEncoder Representations from Transformer (BERT) and Generative Pre-training\nTransformers (GPT) are presented. In total, 60 studies were identified in\nPubMed and Web of Science, of which 29 were excluded and 24 were read and\nevaluated for eligibility, resulting in the use of seven studies for further\nanalysis. This chapter also includes a section with examples including an\nexample of a comparison between GPT-3 and state-of-the-art GPT-4 solutions in\nscientific text summarisation. Natural language processing has not yet reached\nits full potential in the generation of brief textual summaries. As there are\nacknowledged concerns that must be addressed, we can expect gradual\nintroduction of such models in practise."
    },
    {
        "date": "2024-11",
        "title": "A Hard-Label Cryptanalytic Extraction of Non-Fully Connected Deep Neural Networks using Side-Channel Attacks",
        "author": "Benoit Coqueret, Mathieu Carbone, Olivier Sentieys, and Gabriel Zaid",
        "link": "http://arxiv.org/abs/2411.10174v1",
        "abstract": "During the past decade, Deep Neural Networks (DNNs) proved their value on a\nlarge variety of subjects. However despite their high value and public\naccessibility, the protection of the intellectual property of DNNs is still an\nissue and an emerging research field. Recent works have successfully extracted\nfully-connected DNNs using cryptanalytic methods in hard-label settings,\nproving that it was possible to copy a DNN with high fidelity, i.e., high\nsimilitude in the output predictions. However, the current cryptanalytic\nattacks cannot target complex, i.e., not fully connected, DNNs and are limited\nto special cases of neurons present in deep networks.\n  In this work, we introduce a new end-to-end attack framework designed for\nmodel extraction of embedded DNNs with high fidelity. We describe a new\nblack-box side-channel attack which splits the DNN in several linear parts for\nwhich we can perform cryptanalytic extraction and retrieve the weights in\nhard-label settings. With this method, we are able to adapt cryptanalytic\nextraction, for the first time, to non-fully connected DNNs, while maintaining\na high fidelity. We validate our contributions by targeting several\narchitectures implemented on a microcontroller unit, including a Multi-Layer\nPerceptron (MLP) of 1.7 million parameters and a shortened MobileNetv1. Our\nframework successfully extracts all of these DNNs with high fidelity (88.4% for\nthe MobileNetv1 and 93.2% for the MLP). Furthermore, we use the stolen model to\ngenerate adversarial examples and achieve close to white-box performance on the\nvictim's model (95.8% and 96.7% transfer rate)."
    },
    {
        "date": "2024-11",
        "title": "Model Stealing for Any Low-Rank Language Model",
        "author": "Allen Liu, and Ankur Moitra",
        "link": "http://arxiv.org/abs/2411.07536v1",
        "abstract": "Model stealing, where a learner tries to recover an unknown model via\ncarefully chosen queries, is a critical problem in machine learning, as it\nthreatens the security of proprietary models and the privacy of data they are\ntrained on. In recent years, there has been particular interest in stealing\nlarge language models (LLMs). In this paper, we aim to build a theoretical\nunderstanding of stealing language models by studying a simple and\nmathematically tractable setting. We study model stealing for Hidden Markov\nModels (HMMs), and more generally low-rank language models.\n  We assume that the learner works in the conditional query model, introduced\nby Kakade, Krishnamurthy, Mahajan and Zhang. Our main result is an efficient\nalgorithm in the conditional query model, for learning any low-rank\ndistribution. In other words, our algorithm succeeds at stealing any language\nmodel whose output distribution is low-rank. This improves upon the previous\nresult by Kakade, Krishnamurthy, Mahajan and Zhang, which also requires the\nunknown distribution to have high \"fidelity\", a property that holds only in\nrestricted cases. There are two key insights behind our algorithm: First, we\nrepresent the conditional distributions at each timestep by constructing\nbarycentric spanners among a collection of vectors of exponentially large\ndimension. Second, for sampling from our representation, we iteratively solve a\nsequence of convex optimization problems that involve projection in relative\nentropy to prevent compounding of errors over the length of the sequence. This\nis an interesting example where, at least theoretically, allowing a machine\nlearning model to solve more complex problems at inference time can lead to\ndrastic improvements in its performance."
    },
    {
        "date": "2024-11",
        "title": "AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data",
        "author": "Tianyi Zhang, Miu Kojima, and Simon D'Alfonso",
        "link": "http://arxiv.org/abs/2411.04691v1",
        "abstract": "Smartphones, equipped with an array of sensors, have become valuable tools\nfor personal sensing. Particularly in digital health, smartphones facilitate\nthe tracking of health-related behaviors and contexts, contributing\nsignificantly to digital phenotyping, a process where data from digital\ninteractions is analyzed to infer behaviors and assess mental health.\nTraditional methods process raw sensor data into information features for\nstatistical and machine learning analyses. In this paper, we introduce a novel\napproach that systematically converts smartphone-collected data into\nstructured, chronological narratives. The AWARE Narrator translates\nquantitative smartphone sensing data into English language descriptions,\nforming comprehensive narratives of an individual's activities. We apply the\nframework to the data collected from university students over a week,\ndemonstrating the potential of utilizing the narratives to summarize individual\nbehavior, and analyzing psychological states by leveraging large language\nmodels."
    },
    {
        "date": "2024-11",
        "title": "Fine-Tuning Vision-Language Model for Automated Engineering Drawing Information Extraction",
        "author": "Muhammad Tayyab Khan, Lequn Chen, Ye Han Ng, Wenhe Feng, Nicholas Yew Jin Tan, and Seung Ki Moon",
        "link": "http://arxiv.org/abs/2411.03707v1",
        "abstract": "Geometric Dimensioning and Tolerancing (GD&T) plays a critical role in\nmanufacturing by defining acceptable variations in part features to ensure\ncomponent quality and functionality. However, extracting GD&T information from\n2D engineering drawings is a time-consuming and labor-intensive task, often\nrelying on manual efforts or semi-automated tools. To address these challenges,\nthis study proposes an automated and computationally efficient GD&T extraction\nmethod by fine-tuning Florence-2, an open-source vision-language model (VLM).\nThe model is trained on a dataset of 400 drawings with ground truth annotations\nprovided by domain experts. For comparison, two state-of-the-art closed-source\nVLMs, GPT-4o and Claude-3.5-Sonnet, are evaluated on the same dataset. All\nmodels are assessed using precision, recall, F1-score, and hallucination\nmetrics. Due to the computational cost and impracticality of fine-tuning large\nclosed-source VLMs for domain-specific tasks, GPT-4o and Claude-3.5-Sonnet are\nevaluated in a zero-shot setting. In contrast, Florence-2, a smaller model with\n0.23 billion parameters, is optimized through full-parameter fine-tuning across\nthree distinct experiments, each utilizing datasets augmented to different\nlevels. The results show that Florence-2 achieves a 29.95% increase in\nprecision, a 37.75% increase in recall, a 52.40% improvement in F1-score, and a\n43.15% reduction in hallucination rate compared to the best-performing\nclosed-source model. These findings highlight the effectiveness of fine-tuning\nsmaller, open-source VLMs like Florence-2, offering a practical and efficient\nsolution for automated GD&T extraction to support downstream manufacturing\ntasks."
    },
    {
        "date": "2024-11",
        "title": "Speaker Emotion Recognition: Leveraging Self-Supervised Models for Feature Extraction Using Wav2Vec2 and HuBERT",
        "author": "Pourya Jafarzadeh, Amir Mohammad Rostami, and Padideh Choobdar",
        "link": "http://arxiv.org/abs/2411.02964v2",
        "abstract": "Speech is the most natural way of expressing ourselves as humans. Identifying\nemotion from speech is a nontrivial task due to the ambiguous definition of\nemotion itself. Speaker Emotion Recognition (SER) is essential for\nunderstanding human emotional behavior. The SER task is challenging due to the\nvariety of speakers, background noise, complexity of emotions, and speaking\nstyles. It has many applications in education, healthcare, customer service,\nand Human-Computer Interaction (HCI). Previously, conventional machine learning\nmethods such as SVM, HMM, and KNN have been used for the SER task. In recent\nyears, deep learning methods have become popular, with convolutional neural\nnetworks and recurrent neural networks being used for SER tasks. The input of\nthese methods is mostly spectrograms and hand-crafted features. In this work,\nwe study the use of self-supervised transformer-based models, Wav2Vec2 and\nHuBERT, to determine the emotion of speakers from their voice. The models\nautomatically extract features from raw audio signals, which are then used for\nthe classification task. The proposed solution is evaluated on reputable\ndatasets, including RAVDESS, SHEMO, SAVEE, AESDD, and Emo-DB. The results show\nthe effectiveness of the proposed method on different datasets. Moreover, the\nmodel has been used for real-world applications like call center conversations,\nand the results demonstrate that the model accurately predicts emotions."
    },
    {
        "date": "2024-11",
        "title": "DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural Networks",
        "author": "Jinyin Chen, Haonan Ma, and Haibin Zheng",
        "link": "http://arxiv.org/abs/2411.03364v2",
        "abstract": "Graph has become increasingly integral to the advancement of recommendation\nsystems, particularly with the fast development of graph neural network(GNN).\nBy exploring the virtue of rich node features and link information, GNN is\ndesigned to provide personalized and accurate suggestions. Meanwhile, the\nprivacy leakage of GNN in such contexts has also captured special attention.\nPrior work has revealed that a malicious user can utilize auxiliary knowledge\nto extract sensitive link data of the target graph, integral to recommendation\nsystems, via the decision made by the target GNN model. This poses a\nsignificant risk to the integrity and confidentiality of data used in\nrecommendation system. Though important, previous works on GNN's privacy\nleakage are still challenged in three aspects, i.e., limited stealing attack\nscenarios, sub-optimal attack performance, and adaptation against defense. To\naddress these issues, we propose a diffusion model based link stealing attack,\nnamed DM4Steal. It differs previous work from three critical aspects. (i)\nGenerality: aiming at six attack scenarios with limited auxiliary knowledge, we\npropose a novel training strategy for diffusion models so that DM4Steal is\ntransferable to diverse attack scenarios. (ii) Effectiveness: benefiting from\nthe retention of semantic structure in the diffusion model during the training\nprocess, DM4Steal is capable to learn the precise topology of the target graph\nthrough the GNN decision process. (iii) Adaptation: when GNN is defensive\n(e.g., DP, Dropout), DM4Steal relies on the stability that comes from sampling\nthe score model multiple times to keep performance degradation to a minimum,\nthus DM4Steal implements successful adaptive attack on defensive GNN."
    },
    {
        "date": "2024-11",
        "title": "HIP: Hierarchical Point Modeling and Pre-training for Visual Information Extraction",
        "author": "Rujiao Long, Pengfei Wang, Zhibo Yang, and Cong Yao",
        "link": "http://arxiv.org/abs/2411.01139v1",
        "abstract": "End-to-end visual information extraction (VIE) aims at integrating the\nhierarchical subtasks of VIE, including text spotting, word grouping, and\nentity labeling, into a unified framework. Dealing with the gaps among the\nthree subtasks plays a pivotal role in designing an effective VIE model.\nOCR-dependent methods heavily rely on offline OCR engines and inevitably suffer\nfrom OCR errors, while OCR-free methods, particularly those employing a\nblack-box model, might produce outputs that lack interpretability or contain\nhallucinated content. Inspired by CenterNet, DeepSolo, and ESP, we propose HIP,\nwhich models entities as HIerarchical Points to better conform to the\nhierarchical nature of the end-to-end VIE task. Specifically, such hierarchical\npoints can be flexibly encoded and subsequently decoded into desired text\ntranscripts, centers of various regions, and categories of entities.\nFurthermore, we devise corresponding hierarchical pre-training strategies,\ncategorized as image reconstruction, layout learning, and language enhancement,\nto reinforce the cross-modality representation of the hierarchical encoders.\nQuantitative experiments on public benchmarks demonstrate that HIP outperforms\nprevious state-of-the-art methods, while qualitative results show its excellent\ninterpretability."
    },
    {
        "date": "2024-10",
        "title": "Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document",
        "author": "Vicky Dong, Hao Yu, and Yao Chen",
        "link": "http://arxiv.org/abs/2410.23452v1",
        "abstract": "This study introduces a novel approach to sentence-level relation extraction\n(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models\n(LLMs) to generate contextually enriched support documents. By harnessing the\npower of LLMs to generate auxiliary information, our approach crafts an\nintricate graph representation of textual data. This graph is subsequently\nprocessed through a Graph Neural Network (GNN) to refine and enrich the\nembeddings associated with each entity ensuring a more nuanced and\ninterconnected understanding of the data. This methodology addresses the\nlimitations of traditional sentence-level RE models by incorporating broader\ncontexts and leveraging inter-entity interactions, thereby improving the\nmodel's ability to capture complex relationships across sentences. Our\nexperiments, conducted on the CrossRE dataset, demonstrate the effectiveness of\nour approach, with notable improvements in performance across various domains.\nThe results underscore the potential of combining GNNs with LLM-generated\ncontext to advance the field of relation extraction."
    },
    {
        "date": "2024-10",
        "title": "Image2Struct: Benchmarking Structure Extraction for Vision-Language Models",
        "author": "Josselin Somerville Roberts, Tony Lee, Chi Heem Wong, Michihiro Yasunaga, Yifan Mai, and Percy Liang",
        "link": "http://arxiv.org/abs/2410.22456v1",
        "abstract": "We introduce Image2Struct, a benchmark to evaluate vision-language models\n(VLMs) on extracting structure from images. Our benchmark 1) captures\nreal-world use cases, 2) is fully automatic and does not require human\njudgment, and 3) is based on a renewable stream of fresh data. In Image2Struct,\nVLMs are prompted to generate the underlying structure (e.g., LaTeX code or\nHTML) from an input image (e.g., webpage screenshot). The structure is then\nrendered to produce an output image (e.g., rendered webpage), which is compared\nagainst the input image to produce a similarity score. This round-trip\nevaluation allows us to quantitatively evaluate VLMs on tasks with multiple\nvalid structures. We create a pipeline that downloads fresh data from active\nonline communities upon execution and evaluates the VLMs without human\nintervention. We introduce three domains (Webpages, LaTeX, and Musical Scores)\nand use five image metrics (pixel similarity, cosine similarity between the\nInception vectors, learned perceptual image patch similarity, structural\nsimilarity index measure, and earth mover similarity) that allow efficient and\nautomatic comparison between pairs of images. We evaluate Image2Struct on 14\nprominent VLMs and find that scores vary widely, indicating that Image2Struct\ncan differentiate between the performances of different VLMs. Additionally, the\nbest score varies considerably across domains (e.g., 0.402 on sheet music vs.\n0.830 on LaTeX equations), indicating that Image2Struct contains tasks of\nvarying difficulty. For transparency, we release the full results at\nhttps://crfm.stanford.edu/helm/image2struct/v1.0.1/."
    },
    {
        "date": "2024-10",
        "title": "Measuring memorization in language models via probabilistic extraction",
        "author": "Jamie Hayes, Marika Swanberg, Harsh Chaudhari, Itay Yona, Ilia Shumailov, Milad Nasr, Christopher A. Choquette-Choo, Katherine Lee, and A. Feder Cooper",
        "link": "http://arxiv.org/abs/2410.19482v3",
        "abstract": "Large language models (LLMs) are susceptible to memorizing training data,\nraising concerns about the potential extraction of sensitive information at\ngeneration time. Discoverable extraction is the most common method for\nmeasuring this issue: split a training example into a prefix and suffix, then\nprompt the LLM with the prefix, and deem the example extractable if the LLM\ngenerates the matching suffix using greedy sampling. This definition yields a\nyes-or-no determination of whether extraction was successful with respect to a\nsingle query. Though efficient to compute, we show that this definition is\nunreliable because it does not account for non-determinism present in more\nrealistic (non-greedy) sampling schemes, for which LLMs produce a range of\noutputs for the same prompt. We introduce probabilistic discoverable\nextraction, which, without additional cost, relaxes discoverable extraction by\nconsidering multiple queries to quantify the probability of extracting a target\nsequence. We evaluate our probabilistic measure across different models,\nsampling schemes, and training-data repetitions, and find that this measure\nprovides more nuanced information about extraction risk compared to traditional\ndiscoverable extraction."
    },
    {
        "date": "2024-10",
        "title": "Integrating Deep Feature Extraction and Hybrid ResNet-DenseNet Model for Multi-Class Abnormality Detection in Endoscopic Images",
        "author": "Aman Sagar, Preeti Mehta, Monika Shrivastva, and Suchi Kumari",
        "link": "http://arxiv.org/abs/2410.18457v1",
        "abstract": "This paper presents a deep learning framework for the multi-class\nclassification of gastrointestinal abnormalities in Video Capsule Endoscopy\n(VCE) frames. The aim is to automate the identification of ten GI abnormality\nclasses, including angioectasia, bleeding, and ulcers, thereby reducing the\ndiagnostic burden on gastroenterologists. Utilizing an ensemble of DenseNet and\nResNet architectures, the proposed model achieves an overall accuracy of 94\\%\nacross a well-structured dataset. Precision scores range from 0.56 for erythema\nto 1.00 for worms, with recall rates peaking at 98% for normal findings. This\nstudy emphasizes the importance of robust data preprocessing techniques,\nincluding normalization and augmentation, in enhancing model performance. The\ncontributions of this work lie in developing an effective AI-driven tool that\nstreamlines the diagnostic process in gastroenterology, ultimately improving\npatient care and clinical outcomes."
    },
    {
        "date": "2024-10",
        "title": "Extracting Spatiotemporal Data from Gradients with Large Language Models",
        "author": "Lele Zheng, Yang Cao, Renhe Jiang, Kenjiro Taura, Yulong Shen, Sheng Li, and Masatoshi Yoshikawa",
        "link": "http://arxiv.org/abs/2410.16121v1",
        "abstract": "Recent works show that sensitive user data can be reconstructed from gradient\nupdates, breaking the key privacy promise of federated learning. While success\nwas demonstrated primarily on image data, these methods do not directly\ntransfer to other domains, such as spatiotemporal data. To understand privacy\nrisks in spatiotemporal federated learning, we first propose Spatiotemporal\nGradient Inversion Attack (ST-GIA), a gradient attack algorithm tailored to\nspatiotemporal data that successfully reconstructs the original location from\ngradients. Furthermore, the absence of priors in attacks on spatiotemporal data\nhas hindered the accurate reconstruction of real client data. To address this\nlimitation, we propose ST-GIA+, which utilizes an auxiliary language model to\nguide the search for potential locations, thereby successfully reconstructing\nthe original data from gradients. In addition, we design an adaptive defense\nstrategy to mitigate gradient inversion attacks in spatiotemporal federated\nlearning. By dynamically adjusting the perturbation levels, we can offer\ntailored protection for varying rounds of training data, thereby achieving a\nbetter trade-off between privacy and utility than current state-of-the-art\nmethods. Through intensive experimental analysis on three real-world datasets,\nwe reveal that the proposed defense strategy can well preserve the utility of\nspatiotemporal federated learning with effective security protection."
    },
    {
        "date": "2024-10",
        "title": "Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based on Nonlinear Feature Extraction and Intrinsic Correlation",
        "author": "Pei Liu, Nanfang Zheng, Yiqun Li, Junlan Chen, and Ziyuan Pu",
        "link": "http://arxiv.org/abs/2410.15814v1",
        "abstract": "With the development of AI-assisted driving, numerous methods have emerged\nfor ego-vehicle 3D perception tasks, but there has been limited research on\nroadside perception. With its ability to provide a global view and a broader\nsensing range, the roadside perspective is worth developing. LiDAR provides\nprecise three-dimensional spatial information, while cameras offer semantic\ninformation. These two modalities are complementary in 3D detection. However,\nadding camera data does not increase accuracy in some studies since the\ninformation extraction and fusion procedure is not sufficiently reliable.\nRecently, Kolmogorov-Arnold Networks (KANs) have been proposed as replacements\nfor MLPs, which are better suited for high-dimensional, complex data. Both the\ncamera and the LiDAR provide high-dimensional information, and employing KANs\nshould enhance the extraction of valuable features to produce better fusion\noutcomes. This paper proposes Kaninfradet3D, which optimizes the feature\nextraction and fusion modules. To extract features from complex\nhigh-dimensional data, the model's encoder and fuser modules were improved\nusing KAN Layers. Cross-attention was applied to enhance feature fusion, and\nvisual comparisons verified that camera features were more evenly integrated.\nThis addressed the issue of camera features being abnormally concentrated,\nnegatively impacting fusion. Compared to the benchmark, our approach shows\nimprovements of +9.87 mAP and +10.64 mAP in the two viewpoints of the TUMTraf\nIntersection Dataset and an improvement of +1.40 mAP in the roadside end of the\nTUMTraf V2X Cooperative Perception Dataset. The results indicate that\nKaninfradet3D can effectively fuse features, demonstrating the potential of\napplying KANs in roadside perception tasks."
    },
    {
        "date": "2024-10",
        "title": "Efficient Model Extraction via Boundary Sampling",
        "author": "Maor Biton Dor, and Yisroel Mirsky",
        "link": "http://arxiv.org/abs/2410.15429v1",
        "abstract": "This paper introduces a novel data-free model extraction attack that\nsignificantly advances the current state-of-the-art in terms of efficiency,\naccuracy, and effectiveness. Traditional black-box methods rely on using the\nvictim's model as an oracle to label a vast number of samples within\nhigh-confidence areas. This approach not only requires an extensive number of\nqueries but also results in a less accurate and less transferable model. In\ncontrast, our method innovates by focusing on sampling low-confidence areas\n(along the decision boundaries) and employing an evolutionary algorithm to\noptimize the sampling process. These novel contributions allow for a dramatic\nreduction in the number of queries needed by the attacker by a factor of 10x to\n600x while simultaneously improving the accuracy of the stolen model. Moreover,\nour approach improves boundary alignment, resulting in better transferability\nof adversarial examples from the stolen model to the victim's model (increasing\nthe attack success rate from 60\\% to 82\\% on average). Finally, we accomplish\nall of this with a strict black-box assumption on the victim, with no knowledge\nof the target's architecture or dataset.\n  We demonstrate our attack on three datasets with increasingly larger\nresolutions and compare our performance to four state-of-the-art model\nextraction attacks."
    },
    {
        "date": "2024-10",
        "title": "Transit Pulse: Utilizing Social Media as a Source for Customer Feedback and Information Extraction with Large Language Model",
        "author": "Jiahao Wang, and Amer Shalaby",
        "link": "http://arxiv.org/abs/2410.15016v1",
        "abstract": "Users of the transit system flood social networks daily with messages that\ncontain valuable insights crucial for improving service quality. These posts\nhelp transit agencies quickly identify emerging issues. Parsing topics and\nsentiments is key to gaining comprehensive insights to foster service\nexcellence. However, the volume of messages makes manual analysis impractical,\nand standard NLP techniques like Term Frequency-Inverse Document Frequency\n(TF-IDF) fall short in nuanced interpretation. Traditional sentiment analysis\nseparates topics and sentiments before integrating them, often missing the\ninteraction between them. This incremental approach complicates classification\nand reduces analytical productivity. To address these challenges, we propose a\nnovel approach to extracting and analyzing transit-related information,\nincluding sentiment and sarcasm detection, identification of unusual system\nproblems, and location data from social media. Our method employs Large\nLanguage Models (LLM), specifically Llama 3, for a streamlined analysis free\nfrom pre-established topic labels. To enhance the model's domain-specific\nknowledge, we utilize Retrieval-Augmented Generation (RAG), integrating\nexternal knowledge sources into the information extraction pipeline. We\nvalidated our method through extensive experiments comparing its performance\nwith traditional NLP approaches on user tweet data from the real world transit\nsystem. Our results demonstrate the potential of LLMs to transform social media\ndata analysis in the public transit domain, providing actionable insights and\nenhancing transit agencies' responsiveness by extracting a broader range of\ninformation."
    },
    {
        "date": "2024-10",
        "title": "Few-Shot Joint Multimodal Entity-Relation Extraction via Knowledge-Enhanced Cross-modal Prompt Model",
        "author": "Li Yuan, Yi Cai, and Junsheng Huang",
        "link": "http://arxiv.org/abs/2410.14225v2",
        "abstract": "Joint Multimodal Entity-Relation Extraction (JMERE) is a challenging task\nthat aims to extract entities and their relations from text-image pairs in\nsocial media posts. Existing methods for JMERE require large amounts of labeled\ndata. However, gathering and annotating fine-grained multimodal data for JMERE\nposes significant challenges. Initially, we construct diverse and comprehensive\nmultimodal few-shot datasets fitted to the original data distribution. To\naddress the insufficient information in the few-shot setting, we introduce the\n\\textbf{K}nowledge-\\textbf{E}nhanced \\textbf{C}ross-modal \\textbf{P}rompt\n\\textbf{M}odel (KECPM) for JMERE. This method can effectively address the\nproblem of insufficient information in the few-shot setting by guiding a large\nlanguage model to generate supplementary background knowledge. Our proposed\nmethod comprises two stages: (1) a knowledge ingestion stage that dynamically\nformulates prompts based on semantic similarity guide ChatGPT generating\nrelevant knowledge and employs self-reflection to refine the knowledge; (2) a\nknowledge-enhanced language model stage that merges the auxiliary knowledge\nwith the original input and utilizes a transformer-based model to align with\nJMERE's required output format. We extensively evaluate our approach on a\nfew-shot dataset derived from the JMERE dataset, demonstrating its superiority\nover strong baselines in terms of both micro and macro F$_1$ scores.\nAdditionally, we present qualitative analyses and case studies to elucidate the\neffectiveness of our model."
    },
    {
        "date": "2024-10",
        "title": "Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models",
        "author": "Tong Liu, and Hadi Meidani",
        "link": "http://arxiv.org/abs/2410.13051v1",
        "abstract": "Supply chain networks are critical to the operational efficiency of\nindustries, yet their increasing complexity presents significant challenges in\nmapping relationships and identifying the roles of various entities.\nTraditional methods for constructing supply chain networks rely heavily on\nstructured datasets and manual data collection, limiting their scope and\nefficiency. In contrast, recent advancements in Natural Language Processing\n(NLP) and large language models (LLMs) offer new opportunities for discovering\nand analyzing supply chain networks using unstructured text data. This paper\nproposes a novel approach that leverages LLMs to extract and process raw\ntextual information from publicly available sources to construct a\ncomprehensive supply chain graph. We focus on the civil engineering sector as a\ncase study, demonstrating how LLMs can uncover hidden relationships among\ncompanies, projects, and other entities. Additionally, we fine-tune an LLM to\nclassify entities within the supply chain graph, providing detailed insights\ninto their roles and relationships. The results show that domain-specific\nfine-tuning improves classification accuracy, highlighting the potential of\nLLMs for industry-specific supply chain analysis. Our contributions include the\ndevelopment of a supply chain graph for the civil engineering sector, as well\nas a fine-tuned LLM model that enhances entity classification and understanding\nof supply chain networks."
    },
    {
        "date": "2024-10",
        "title": "CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment",
        "author": "Qinfeng Li, Yangfan Xie, Tianyu Du, Zhiqiang Shen, Zhenghan Qin, Hao Peng, Xinkui Zhao, Xianwei Zhu, Jianwei Yin, and Xuhong Zhang",
        "link": "http://arxiv.org/abs/2410.13903v1",
        "abstract": "Proprietary large language models (LLMs) demonstrate exceptional\ngeneralization ability across various tasks. Additionally, deploying LLMs on\nedge devices is trending for efficiency and privacy reasons. However, edge\ndeployment of proprietary LLMs introduces new security threats: attackers who\nobtain an edge-deployed LLM can easily use it as a base model for various tasks\ndue to its high generalization ability, which we call foundational capability\nstealing. Unfortunately, existing model protection mechanisms are often\ntask-specific and fail to protect general-purpose LLMs, as they mainly focus on\nprotecting task-related parameters using trusted execution environments (TEEs).\nAlthough some recent TEE-based methods are able to protect the overall model\nparameters in a computation-efficient way, they still suffer from prohibitive\ncommunication costs between TEE and CPU/GPU, making it impractical to deploy\nfor edge LLMs. To protect the foundational capabilities of edge LLMs, we\npropose CoreGuard, a computation- and communication-efficient model protection\napproach against model stealing on edge devices. The core component of\nCoreGuard is a lightweight and propagative authorization module residing in\nTEE. Extensive experiments show that CoreGuard achieves the same security\nprotection as the black-box security guarantees with negligible overhead."
    },
    {
        "date": "2024-10",
        "title": "Identity-Focused Inference and Extraction Attacks on Diffusion Models",
        "author": "Jayneel Vora, Aditya Krishnan, Nader Bouacida, Prabhu RV Shankar, and Prasant Mohapatra",
        "link": "http://arxiv.org/abs/2410.10177v1",
        "abstract": "The increasing reliance on diffusion models for generating synthetic images\nhas amplified concerns about the unauthorized use of personal data,\nparticularly facial images, in model training. In this paper, we introduce a\nnovel identity inference framework to hold model owners accountable for\nincluding individuals' identities in their training data. Our approach moves\nbeyond traditional membership inference attacks by focusing on identity-level\ninference, providing a new perspective on data privacy violations. Through\ncomprehensive evaluations on two facial image datasets, Labeled Faces in the\nWild (LFW) and CelebA, our experiments demonstrate that the proposed membership\ninference attack surpasses baseline methods, achieving an attack success rate\nof up to 89% and an AUC-ROC of 0.91, while the identity inference attack\nattains 92% on LDM models trained on LFW, and the data extraction attack\nachieves 91.6% accuracy on DDPMs, validating the effectiveness of our approach\nacross diffusion models."
    },
    {
        "date": "2024-10",
        "title": "Enabling Advanced Land Cover Analytics: An Integrated Data Extraction Pipeline for Predictive Modeling with the Dynamic World Dataset",
        "author": "Victor Radermecker, Andrea Zanon, Nancy Thomas, Annita Vapsi, Saba Rahimi, Rama Ramakrishnan, and Daniel Borrajo",
        "link": "http://arxiv.org/abs/2410.09135v1",
        "abstract": "Understanding land cover holds considerable potential for a myriad of\npractical applications, particularly as data accessibility transitions from\nbeing exclusive to governmental and commercial entities to now including the\nbroader research community. Nevertheless, although the data is accessible to\nany community member interested in exploration, there exists a formidable\nlearning curve and no standardized process for accessing, pre-processing, and\nleveraging the data for subsequent tasks. In this study, we democratize this\ndata by presenting a flexible and efficient end to end pipeline for working\nwith the Dynamic World dataset, a cutting-edge near-real-time land use/land\ncover (LULC) dataset. This includes a pre-processing and representation\nframework which tackles noise removal, efficient extraction of large amounts of\ndata, and re-representation of LULC data in a format well suited for several\ndownstream tasks. To demonstrate the power of our pipeline, we use it to\nextract data for an urbanization prediction problem and build a suite of\nmachine learning models with excellent performance. This task is easily\ngeneralizable to the prediction of any type of land cover and our pipeline is\nalso compatible with a series of other downstream tasks."
    },
    {
        "date": "2024-10",
        "title": "Contrastive Learning to Fine-Tune Feature Extraction Models for the Visual Cortex",
        "author": "Alex Mulrooney, and Austin J. Brockmeier",
        "link": "http://arxiv.org/abs/2410.06067v1",
        "abstract": "Predicting the neural response to natural images in the visual cortex\nrequires extracting relevant features from the images and relating those\nfeature to the observed responses. In this work, we optimize the feature\nextraction in order to maximize the information shared between the image\nfeatures and the neural response across voxels in a given region of interest\n(ROI) extracted from the BOLD signal measured by fMRI. We adapt contrastive\nlearning (CL) to fine-tune a convolutional neural network, which was pretrained\nfor image classification, such that a mapping of a given image's features are\nmore similar to the corresponding fMRI response than to the responses to other\nimages. We exploit the recently released Natural Scenes Dataset (Allen et al.,\n2022) as organized for the Algonauts Project (Gifford et al., 2023), which\ncontains the high-resolution fMRI responses of eight subjects to tens of\nthousands of naturalistic images. We show that CL fine-tuning creates feature\nextraction models that enable higher encoding accuracy in early visual ROIs as\ncompared to both the pretrained network and a baseline approach that uses a\nregression loss at the output of the network to tune it for fMRI response\nencoding. We investigate inter-subject transfer of the CL fine-tuned models,\nincluding subjects from another, lower-resolution dataset (Gong et al., 2023).\nWe also pool subjects for fine-tuning to further improve the encoding\nperformance. Finally, we examine the performance of the fine-tuned models on\ncommon image classification tasks, explore the landscape of ROI-specific models\nby applying dimensionality reduction on the Bhattacharya dissimilarity matrix\ncreated using the predictions on those tasks (Mao et al., 2024), and\ninvestigate lateralization of the processing for early visual ROIs using\nsalience maps of the classifiers built on the CL-tuned models."
    },
    {
        "date": "2024-10",
        "title": "Polynomial Time Cryptanalytic Extraction of Deep Neural Networks in the Hard-Label Setting",
        "author": "Nicholas Carlini, Jorge Ch\u00e1vez-Saab, Anna Hambitzer, Francisco Rodr\u00edguez-Henr\u00edquez, and Adi Shamir",
        "link": "http://arxiv.org/abs/2410.05750v1",
        "abstract": "Deep neural networks (DNNs) are valuable assets, yet their public\naccessibility raises security concerns about parameter extraction by malicious\nactors. Recent work by Carlini et al. (crypto'20) and Canales-Mart\\'inez et al.\n(eurocrypt'24) has drawn parallels between this issue and block cipher key\nextraction via chosen plaintext attacks. Leveraging differential cryptanalysis,\nthey demonstrated that all the weights and biases of black-box ReLU-based DNNs\ncould be inferred using a polynomial number of queries and computational time.\nHowever, their attacks relied on the availability of the exact numeric value of\noutput logits, which allowed the calculation of their derivatives. To overcome\nthis limitation, Chen et al. (asiacrypt'24) tackled the more realistic\nhard-label scenario, where only the final classification label (e.g., \"dog\" or\n\"car\") is accessible to the attacker. They proposed an extraction method\nrequiring a polynomial number of queries but an exponential execution time. In\naddition, their approach was applicable only to a restricted set of\narchitectures, could deal only with binary classifiers, and was demonstrated\nonly on tiny neural networks with up to four neurons split among up to two\nhidden layers. This paper introduces new techniques that, for the first time,\nachieve cryptanalytic extraction of DNN parameters in the most challenging\nhard-label setting, using both a polynomial number of queries and polynomial\ntime. We validate our approach by extracting nearly one million parameters from\na DNN trained on the CIFAR-10 dataset, comprising 832 neurons in four hidden\nlayers. Our results reveal the surprising fact that all the weights of a\nReLU-based DNN can be efficiently determined by analyzing only the geometric\nshape of its decision boundaries."
    },
    {
        "date": "2024-10",
        "title": "Multiscale Latent Diffusion Model for Enhanced Feature Extraction from Medical Images",
        "author": "Rabeya Tus Sadia, Jie Zhang, and Jin Chen",
        "link": "http://arxiv.org/abs/2410.04000v3",
        "abstract": "Various imaging modalities are used in patient diagnosis, each offering\nunique advantages and valuable insights into anatomy and pathology. Computed\nTomography (CT) is crucial in diagnostics, providing high-resolution images for\nprecise internal organ visualization. CT's ability to detect subtle tissue\nvariations is vital for diagnosing diseases like lung cancer, enabling early\ndetection and accurate tumor assessment. However, variations in CT scanner\nmodels and acquisition protocols introduce significant variability in the\nextracted radiomic features, even when imaging the same patient. This\nvariability poses considerable challenges for downstream research and clinical\nanalysis, which depend on consistent and reliable feature extraction. Current\nmethods for medical image feature extraction, often based on supervised\nlearning approaches, including GAN-based models, face limitations in\ngeneralizing across different imaging environments. In response to these\nchallenges, we propose LTDiff++, a multiscale latent diffusion model designed\nto enhance feature extraction in medical imaging. The model addresses\nvariability by standardizing non-uniform distributions in the latent space,\nimproving feature consistency. LTDiff++ utilizes a UNet++ encoder-decoder\narchitecture coupled with a conditional Denoising Diffusion Probabilistic Model\n(DDPM) at the latent bottleneck to achieve robust feature extraction and\nstandardization. Extensive empirical evaluations on both patient and phantom CT\ndatasets demonstrate significant improvements in image standardization, with\nhigher Concordance Correlation Coefficients (CCC) across multiple radiomic\nfeature categories. Through these advancements, LTDiff++ represents a promising\nsolution for overcoming the inherent variability in medical imaging data,\noffering improved reliability and accuracy in feature extraction processes."
    },
    {
        "date": "2024-10",
        "title": "Extracting Training Data from Unconditional Diffusion Models",
        "author": "Yunhao Chen, Shujie Wang, Difan Zou, and Xingjun Ma",
        "link": "http://arxiv.org/abs/2410.02467v6",
        "abstract": "As diffusion probabilistic models (DPMs) are being employed as mainstream\nmodels for Generative Artificial Intelligence (GenAI), the study of their\nmemorization has attracted growing attention. Existing works in this field aim\nto establish an understanding of whether or to what extent DPMs learn via\nmemorization. Such an understanding is crucial for identifying potential risks\nof data leakage and copyright infringement in diffusion models and, more\nimportantly, for trustworthy application of GenAI. Existing works revealed that\nconditional DPMs are more prone to memorize training data than unconditional\nDPMs. And most data extraction methods developed so far target conditional\nDPMs. Although unconditional DPMs are less prone to data extraction, further\ninvestigation into these attacks remains essential since they serve as the\nfoundation for conditional models like Stable Diffusion, and exploring these\nattacks will enhance our understanding of memorization in DPMs. In this work,\nwe propose a novel data extraction method named \\textbf{Surrogate condItional\nData Extraction (SIDE)} that leverages a time-dependent classifier trained on\ngenerated data as surrogate conditions to extract training data from\nunconditional DPMs. Empirical results demonstrate that it can extract training\ndata in challenging scenarios where previous methods fail, and it is, on\naverage, over 50\\% more effective across different scales of the CelebA\ndataset. Furthermore, we provide a theoretical understanding of memorization in\nboth conditional and unconditional DPMs and why SIDE is effective."
    },
    {
        "date": "2024-10",
        "title": "A Novel Feature Extraction Model for the Detection of Plant Disease from Leaf Images in Low Computational Devices",
        "author": "Rikathi Pal, Anik Basu Bhaumik, Arpan Murmu, Sanoar Hossain, Biswajit Maity, and Soumya Sen",
        "link": "http://arxiv.org/abs/2410.01854v1",
        "abstract": "Diseases in plants cause significant danger to productive and secure\nagriculture. Plant diseases can be detected early and accurately, reducing crop\nlosses and pesticide use. Traditional methods of plant disease identification,\non the other hand, are generally time-consuming and require professional\nexpertise. It would be beneficial to the farmers if they could detect the\ndisease quickly by taking images of the leaf directly. This will be a\ntime-saving process and they can take remedial actions immediately. To achieve\nthis a novel feature extraction approach for detecting tomato plant illnesses\nfrom leaf photos using low-cost computing systems such as mobile phones is\nproposed in this study. The proposed approach integrates various types of Deep\nLearning techniques to extract robust and discriminative features from leaf\nimages. After the proposed feature extraction comparisons have been made on\nfive cutting-edge deep learning models: AlexNet, ResNet50, VGG16, VGG19, and\nMobileNet. The dataset contains 10,000 leaf photos from ten classes of tomato\nillnesses and one class of healthy leaves. Experimental findings demonstrate\nthat AlexNet has an accuracy score of 87%, with the benefit of being quick and\nlightweight, making it appropriate for use on embedded systems and other\nlow-processing devices like smartphones."
    },
    {
        "date": "2024-10",
        "title": "Preserving Generalization of Language models in Few-shot Continual Relation Extraction",
        "author": "Quyen Tran, Nguyen Xuan Thanh, Nguyen Hoang Anh, Nam Le Hai, Trung Le, Linh Van Ngo, and Thien Huu Nguyen",
        "link": "http://arxiv.org/abs/2410.00334v1",
        "abstract": "Few-shot Continual Relations Extraction (FCRE) is an emerging and dynamic\narea of study where models can sequentially integrate knowledge from new\nrelations with limited labeled data while circumventing catastrophic forgetting\nand preserving prior knowledge from pre-trained backbones. In this work, we\nintroduce a novel method that leverages often-discarded language model heads.\nBy employing these components via a mutual information maximization strategy,\nour approach helps maintain prior knowledge from the pre-trained backbone and\nstrategically aligns the primary classification head, thereby enhancing model\nperformance. Furthermore, we explore the potential of Large Language Models\n(LLMs), renowned for their wealth of knowledge, in addressing FCRE challenges.\nOur comprehensive experimental results underscore the efficacy of the proposed\nmethod and offer valuable insights for future work."
    },
    {
        "date": "2024-09",
        "title": "Towards Robust Extractive Question Answering Models: Rethinking the Training Methodology",
        "author": "Son Quoc Tran, and Matt Kretchmar",
        "link": "http://arxiv.org/abs/2409.19766v1",
        "abstract": "This paper proposes a novel training method to improve the robustness of\nExtractive Question Answering (EQA) models. Previous research has shown that\nexisting models, when trained on EQA datasets that include unanswerable\nquestions, demonstrate a significant lack of robustness against distribution\nshifts and adversarial attacks. Despite this, the inclusion of unanswerable\nquestions in EQA training datasets is essential for ensuring real-world\nreliability. Our proposed training method includes a novel loss function for\nthe EQA problem and challenges an implicit assumption present in numerous EQA\ndatasets. Models trained with our method maintain in-domain performance while\nachieving a notable improvement on out-of-domain datasets. This results in an\noverall F1 score improvement of 5.7 across all testing sets. Furthermore, our\nmodels exhibit significantly enhanced robustness against two types of\nadversarial attacks, with a performance decrease of only about a third compared\nto the default models."
    },
    {
        "date": "2024-09",
        "title": "INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning",
        "author": "Pablo Romero, Lifeng Han, and Goran Nenadic",
        "link": "http://arxiv.org/abs/2409.19467v2",
        "abstract": "Medication Extraction and Mining play an important role in healthcare NLP\nresearch due to its practical applications in hospital settings, such as their\nmapping into standard clinical knowledge bases (SNOMED-CT, BNF, etc.). In this\nwork, we investigate state-of-the-art LLMs in text mining tasks on medications\nand their related attributes such as dosage, route, strength, and adverse\neffects. In addition, we explore different ensemble learning methods\n(\\textsc{Stack-Ensemble} and \\textsc{Voting-Ensemble}) to augment the model\nperformances from individual LLMs. Our ensemble learning result demonstrated\nbetter performances than individually fine-tuned base models BERT, RoBERTa,\nRoBERTa-L, BioBERT, BioClinicalBERT, BioMedRoBERTa, ClinicalBERT, and\nPubMedBERT across general and specific domains. Finally, we build up an entity\nlinking function to map extracted medical terminologies into the SNOMED-CT\ncodes and the British National Formulary (BNF) codes, which are further mapped\nto the Dictionary of Medicines and Devices (dm+d), and ICD. Our model's toolkit\nand desktop applications are publicly available (at\n\\url{https://github.com/HECTA-UoM/ensemble-NER})."
    },
    {
        "date": "2024-09",
        "title": "Feature-to-Image Data Augmentation: Improving Model Feature Extraction with Cluster-Guided Synthetic Samples",
        "author": "Yasaman Haghbin, Hadi Moradi, and Reshad Hosseini",
        "link": "http://arxiv.org/abs/2409.17685v2",
        "abstract": "One of the growing trends in machine learning is the use of data generation\ntechniques, since the performance of machine learning models is dependent on\nthe quantity of the training dataset. However, in many real-world applications,\nparticularly in medical and low-resource domains, collecting large datasets is\nchallenging due to resource constraints, which leads to overfitting and poor\ngeneralization. This study introduces FICAug, a novel feature-to-image data\naugmentation framework designed to improve model generalization under limited\ndata conditions by generating structured synthetic samples.\n  FICAug first operates in the feature space, where original data are clustered\nusing the k-means algorithm. Within pure-label clusters, synthetic data are\ngenerated through Gaussian sampling to increase diversity while maintaining\nlabel consistency. These synthetic features are then projected back into the\nimage domain using a generative neural network, and a convolutional neural\nnetwork is trained on the reconstructed images to learn enhanced\nrepresentations.\n  Experimental results demonstrate that FICAug significantly improves\nclassification accuracy. In feature space, it achieved a cross-validation\naccuracy of 84.09%, while training a ResNet-18 model on the reconstructed\nimages further boosted performance to 88.63%, illustrating the effectiveness of\nthe proposed framework in extracting new and task-relevant features."
    },
    {
        "date": "2024-09",
        "title": "Semi-strong Efficient Market of Bitcoin and Twitter: an Analysis of Semantic Vector Spaces of Extracted Keywords and Light Gradient Boosting Machine Models",
        "author": "Fang Wang, and Marko Gacesa",
        "link": "http://arxiv.org/abs/2409.15988v1",
        "abstract": "This study extends the examination of the Efficient-Market Hypothesis in\nBitcoin market during a five year fluctuation period, from September 1 2017 to\nSeptember 1 2022, by analyzing 28,739,514 qualified tweets containing the\ntargeted topic \"Bitcoin\". Unlike previous studies, we extracted fundamental\nkeywords as an informative proxy for carrying out the study of the EMH in the\nBitcoin market rather than focusing on sentiment analysis, information volume,\nor price data. We tested market efficiency in hourly, 4-hourly, and daily time\nperiods to understand the speed and accuracy of market reactions towards the\ninformation within different thresholds. A sequence of machine learning methods\nand textual analyses were used, including measurements of distances of semantic\nvector spaces of information, keywords extraction and encoding model, and Light\nGradient Boosting Machine (LGBM) classifiers. Our results suggest that 78.06%\n(83.08%), 84.63% (87.77%), and 94.03% (94.60%) of hourly, 4-hourly, and daily\nbullish (bearish) market movements can be attributed to public information\nwithin organic tweets."
    },
    {
        "date": "2024-09",
        "title": "ASTE Transformer Modelling Dependencies in Aspect-Sentiment Triplet Extraction",
        "author": "Iwo Naglik, and Mateusz Lango",
        "link": "http://arxiv.org/abs/2409.15202v2",
        "abstract": "Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of\naspect-based sentiment analysis that consists in extracting (aspect phrase,\nopinion phrase, sentiment polarity) triples from a given sentence. Recent\nstate-of-the-art methods approach this task by first extracting all possible\ntext spans from a given text, then filtering the potential aspect and opinion\nphrases with a classifier, and finally considering all their pairs with another\nclassifier that additionally assigns sentiment polarity to them. Although\nseveral variations of the above scheme have been proposed, the common feature\nis that the final result is constructed by a sequence of independent classifier\ndecisions. This hinders the exploitation of dependencies between extracted\nphrases and prevents the use of knowledge about the interrelationships between\nclassifier predictions to improve performance. In this paper, we propose a new\nASTE approach consisting of three transformer-inspired layers, which enables\nthe modelling of dependencies both between phrases and between the final\nclassifier decisions. Experimental results show that the method achieves higher\nperformance in terms of F1 measure than other methods studied on popular\nbenchmarks. In addition, we show that a simple pre-training technique further\nimproves the performance of the model."
    },
    {
        "date": "2024-09",
        "title": "Efficient and Effective Model Extraction",
        "author": "Hongyu Zhu, Wentao Hu, Sichu Liang, Fangqi Li, Wenwen Wang, and Shilin Wang",
        "link": "http://arxiv.org/abs/2409.14122v2",
        "abstract": "Model extraction aims to create a functionally similar copy from a machine\nlearning as a service (MLaaS) API with minimal overhead, typically for illicit\nprofit or as a precursor to further attacks, posing a significant threat to the\nMLaaS ecosystem. However, recent studies have shown that model extraction is\nhighly inefficient, particularly when the target task distribution is\nunavailable. In such cases, even substantially increasing the attack budget\nfails to produce a sufficiently similar replica, reducing the adversary's\nmotivation to pursue extraction attacks. In this paper, we revisit the\nelementary design choices throughout the extraction lifecycle. We propose an\nembarrassingly simple yet dramatically effective algorithm, Efficient and\nEffective Model Extraction (E3), focusing on both query preparation and\ntraining routine. E3 achieves superior generalization compared to\nstate-of-the-art methods while minimizing computational costs. For instance,\nwith only 0.005 times the query budget and less than 0.2 times the runtime, E3\noutperforms classical generative model based data-free model extraction by an\nabsolute accuracy improvement of over 50% on CIFAR-10. Our findings underscore\nthe persistent threat posed by model extraction and suggest that it could serve\nas a valuable benchmarking algorithm for future security evaluations."
    },
    {
        "date": "2024-09",
        "title": "Hard-Label Cryptanalytic Extraction of Neural Network Models",
        "author": "Yi Chen, Xiaoyang Dong, Jian Guo, Yantian Shen, Anyu Wang, and Xiaoyun Wang",
        "link": "http://arxiv.org/abs/2409.11646v1",
        "abstract": "The machine learning problem of extracting neural network parameters has been\nproposed for nearly three decades. Functionally equivalent extraction is a\ncrucial goal for research on this problem. When the adversary has access to the\nraw output of neural networks, various attacks, including those presented at\nCRYPTO 2020 and EUROCRYPT 2024, have successfully achieved this goal. However,\nthis goal is not achieved when neural networks operate under a hard-label\nsetting where the raw output is inaccessible.\n  In this paper, we propose the first attack that theoretically achieves\nfunctionally equivalent extraction under the hard-label setting, which applies\nto ReLU neural networks. The effectiveness of our attack is validated through\npractical experiments on a wide range of ReLU neural networks, including neural\nnetworks trained on two real benchmarking datasets (MNIST, CIFAR10) widely used\nin computer vision. For a neural network consisting of $10^5$ parameters, our\nattack only requires several hours on a single core."
    },
    {
        "date": "2024-09",
        "title": "CaBaGe: Data-Free Model Extraction using ClAss BAlanced Generator Ensemble",
        "author": "Jonathan Rosenthal, Shanchao Liang, Kevin Zhang, and Lin Tan",
        "link": "http://arxiv.org/abs/2409.10643v1",
        "abstract": "Machine Learning as a Service (MLaaS) is often provided as a pay-per-query,\nblack-box system to clients. Such a black-box approach not only hinders open\nreplication, validation, and interpretation of model results, but also makes it\nharder for white-hat researchers to identify vulnerabilities in the MLaaS\nsystems. Model extraction is a promising technique to address these challenges\nby reverse-engineering black-box models. Since training data is typically\nunavailable for MLaaS models, this paper focuses on the realistic version of\nit: data-free model extraction. We propose a data-free model extraction\napproach, CaBaGe, to achieve higher model extraction accuracy with a small\nnumber of queries. Our innovations include (1) a novel experience replay for\nfocusing on difficult training samples; (2) an ensemble of generators for\nsteadily producing diverse synthetic data; and (3) a selective filtering\nprocess for querying the victim model with harder, more balanced samples. In\naddition, we create a more realistic setting, for the first time, where the\nattacker has no knowledge of the number of classes in the victim training data,\nand create a solution to learn the number of classes on the fly. Our evaluation\nshows that CaBaGe outperforms existing techniques on seven datasets -- MNIST,\nFMNIST, SVHN, CIFAR-10, CIFAR-100, ImageNet-subset, and Tiny ImageNet -- with\nan accuracy improvement of the extracted models by up to 43.13%. Furthermore,\nthe number of queries required to extract a clone model matching the final\naccuracy of prior work is reduced by up to 75.7%."
    },
    {
        "date": "2024-09",
        "title": "Language Models and Retrieval Augmented Generation for Automated Structured Data Extraction from Diagnostic Reports",
        "author": "Mohamed Sobhi Jabal, Pranav Warman, Jikai Zhang, Kartikeye Gupta, Ayush Jain, Maciej Mazurowski, Walter Wiggins, Kirti Magudia, and Evan Calabrese",
        "link": "http://arxiv.org/abs/2409.10576v2",
        "abstract": "Purpose: To develop and evaluate an automated system for extracting\nstructured clinical information from unstructured radiology and pathology\nreports using open-weights large language models (LMs) and retrieval augmented\ngeneration (RAG), and to assess the effects of model configuration variables on\nextraction performance. Methods and Materials: The study utilized two datasets:\n7,294 radiology reports annotated for Brain Tumor Reporting and Data System\n(BT-RADS) scores and 2,154 pathology reports annotated for isocitrate\ndehydrogenase (IDH) mutation status. An automated pipeline was developed to\nbenchmark the performance of various LMs and RAG configurations. The impact of\nmodel size, quantization, prompting strategies, output formatting, and\ninference parameters was systematically evaluated. Results: The best performing\nmodels achieved over 98% accuracy in extracting BT-RADS scores from radiology\nreports and over 90% for IDH mutation status extraction from pathology reports.\nThe top model being medical fine-tuned llama3. Larger, newer, and domain\nfine-tuned models consistently outperformed older and smaller models. Model\nquantization had minimal impact on performance. Few-shot prompting\nsignificantly improved accuracy. RAG improved performance for complex pathology\nreports but not for shorter radiology reports. Conclusions: Open LMs\ndemonstrate significant potential for automated extraction of structured\nclinical data from unstructured clinical reports with local privacy-preserving\napplication. Careful model selection, prompt engineering, and semi-automated\noptimization using annotated data are critical for optimal performance. These\napproaches could be reliable enough for practical use in research workflows,\nhighlighting the potential for human-machine collaboration in healthcare data\nextraction."
    },
    {
        "date": "2024-09",
        "title": "TSELM: Target Speaker Extraction using Discrete Tokens and Language Models",
        "author": "Beilong Tang, Bang Zeng, and Ming Li",
        "link": "http://arxiv.org/abs/2409.07841v3",
        "abstract": "We propose TSELM, a novel target speaker extraction network that leverages\ndiscrete tokens and language models. TSELM utilizes multiple discretized layers\nfrom WavLM as input tokens and incorporates cross-attention mechanisms to\nintegrate target speaker information. Language models are employed to capture\nthe sequence dependencies, while a scalable HiFi-GAN is used to reconstruct the\naudio from the tokens. By applying a cross-entropy loss, TSELM models the\nprobability distribution of output tokens, thus converting the complex\nregression problem of audio generation into a classification task. Experimental\nresults show that TSELM achieves excellent results in speech quality and\ncomparable results in speech intelligibility."
    },
    {
        "date": "2024-09",
        "title": "\"Yes, My LoRD.\" Guiding Language Model Extraction with Locality Reinforced Distillation",
        "author": "Zi Liang, Qingqing Ye, Yanyun Wang, Sen Zhang, Yaxin Xiao, Ronghua Li, Jianliang Xu, and Haibo Hu",
        "link": "http://arxiv.org/abs/2409.02718v3",
        "abstract": "Model extraction attacks (MEAs) on large language models (LLMs) have received\nincreasing attention in recent research. However, existing attack methods\ntypically adapt the extraction strategies originally developed for deep neural\nnetworks (DNNs). They neglect the underlying inconsistency between the training\ntasks of MEA and LLM alignment, leading to suboptimal attack performance. To\ntackle this issue, we propose Locality Reinforced Distillation (LoRD), a novel\nmodel extraction algorithm specifically designed for LLMs. In particular, LoRD\nemploys a newly defined policy-gradient-style training task that utilizes the\nresponses of victim model as the signal to guide the crafting of preference for\nthe local model. Theoretical analyses demonstrate that I) The convergence\nprocedure of LoRD in model extraction is consistent with the alignment\nprocedure of LLMs, and II) LoRD can reduce query complexity while mitigating\nwatermark protection through our exploration-based stealing. Extensive\nexperiments validate the superiority of our method in extracting various\nstate-of-the-art commercial LLMs. Our code is available at:\nhttps://github.com/liangzid/LoRD-MEA ."
    },
    {
        "date": "2024-09",
        "title": "AdaComp: Extractive Context Compression with Adaptive Predictor for Retrieval-Augmented Large Language Models",
        "author": "Qianchi Zhang, Hainan Zhang, Liang Pang, Hongwei Zheng, and Zhiming Zheng",
        "link": "http://arxiv.org/abs/2409.01579v1",
        "abstract": "Retrieved documents containing noise will hinder RAG from detecting answer\nclues and make the inference process slow and expensive. Therefore, context\ncompression is necessary to enhance its accuracy and efficiency. Existing\ncontext compression methods use extractive or generative models to retain the\nmost query-relevant sentences or apply the information bottleneck theory to\npreserve sufficient information. However, these methods may face issues such as\nover-compression or high computational costs. We observe that the retriever\noften ranks relevant documents at the top, but the exact number of documents\nneeded to answer the query is uncertain due to the impact of query complexity\nand retrieval quality: complex queries like multi-hop questions may require\nretaining more documents than simpler queries, and a low-quality retrieval may\nneed to rely on more documents to generate accurate outputs. Therefore,\ndetermining the minimum number of required documents (compression rate) is\nstill a challenge for RAG. In this paper, we introduce AdaComp, a low-cost\nextractive context compression method that adaptively determines the\ncompression rate based on both query complexity and retrieval quality.\nSpecifically, we first annotate the minimum top-k documents necessary for the\nRAG system to answer the current query as the compression rate and then\nconstruct triplets of the query, retrieved documents, and its compression rate.\nThen, we use this triplet dataset to train a compression-rate predictor.\nExperiments on three QA datasets and one conversational Muiti-doc QA dataset\nshow that AdaComp significantly reduces inference costs while maintaining\nperformance nearly identical to uncompressed models, achieving a balance\nbetween efficiency and performance."
    },
    {
        "date": "2024-08",
        "title": "Extraction of Research Objectives, Machine Learning Model Names, and Dataset Names from Academic Papers and Analysis of Their Interrelationships Using LLM and Network Analysis",
        "author": "S. Nishio, H. Nonaka, N. Tsuchiya, A. Migita, Y. Banno, T. Hayashi, H. Sakaji, T. Sakumoto, and K. Watabe",
        "link": "http://arxiv.org/abs/2408.12097v1",
        "abstract": "Machine learning is widely utilized across various industries. Identifying\nthe appropriate machine learning models and datasets for specific tasks is\ncrucial for the effective industrial application of machine learning. However,\nthis requires expertise in both machine learning and the relevant domain,\nleading to a high learning cost. Therefore, research focused on extracting\ncombinations of tasks, machine learning models, and datasets from academic\npapers is critically important, as it can facilitate the automatic\nrecommendation of suitable methods. Conventional information extraction methods\nfrom academic papers have been limited to identifying machine learning models\nand other entities as named entities. To address this issue, this study\nproposes a methodology extracting tasks, machine learning methods, and dataset\nnames from scientific papers and analyzing the relationships between these\ninformation by using LLM, embedding model, and network clustering. The proposed\nmethod's expression extraction performance, when using Llama3, achieves an\nF-score exceeding 0.8 across various categories, confirming its practical\nutility. Benchmarking results on financial domain papers have demonstrated the\neffectiveness of this method, providing insights into the use of the latest\ndatasets, including those related to ESG (Environmental, Social, and\nGovernance) data."
    },
    {
        "date": "2024-08",
        "title": "JieHua Paintings Style Feature Extracting Model using Stable Diffusion with ControlNet",
        "author": "Yujia Gu, Haofeng Li, Xinyu Fang, Zihan Peng, and Yinan Peng",
        "link": "http://arxiv.org/abs/2408.11744v1",
        "abstract": "This study proposes a novel approach to extract stylistic features of Jiehua:\nthe utilization of the Fine-tuned Stable Diffusion Model with ControlNet\n(FSDMC) to refine depiction techniques from artists' Jiehua. The training data\nfor FSDMC is based on the opensource Jiehua artist's work collected from the\nInternet, which were subsequently manually constructed in the format of\n(Original Image, Canny Edge Features, Text Prompt). By employing the optimal\nhyperparameters identified in this paper, it was observed FSDMC outperforms\nCycleGAN, another mainstream style transfer model. FSDMC achieves FID of 3.27\non the dataset and also surpasses CycleGAN in terms of expert evaluation. This\nnot only demonstrates the model's high effectiveness in extracting Jiehua's\nstyle features, but also preserves the original pre-trained semantic\ninformation. The findings of this study suggest that the application of FSDMC\nwith appropriate hyperparameters can enhance the efficacy of the Stable\nDiffusion Model in the field of traditional art style migration tasks,\nparticularly within the context of Jiehua."
    },
    {
        "date": "2024-08",
        "title": "Extracting Sentence Embeddings from Pretrained Transformer Models",
        "author": "Lukas Stankevi\u010dius, and Mantas Luko\u0161evi\u010dius",
        "link": "http://arxiv.org/abs/2408.08073v2",
        "abstract": "Pre-trained transformer models shine in many natural language processing\ntasks and therefore are expected to bear the representation of the input\nsentence or text meaning. These sentence-level embeddings are also important in\nretrieval-augmented generation. But do commonly used plain averaging or prompt\ntemplates sufficiently capture and represent the underlying meaning? After\nproviding a comprehensive review of existing sentence embedding extraction and\nrefinement methods, we thoroughly test different combinations and our original\nextensions of the most promising ones on pretrained models. Namely, given 110 M\nparameters, BERT's hidden representations from multiple layers, and many\ntokens, we try diverse ways to extract optimal sentence embeddings. We test\nvarious token aggregation and representation post-processing techniques. We\nalso test multiple ways of using a general Wikitext dataset to complement\nBERT's sentence embeddings. All methods are tested on eight Semantic Textual\nSimilarity (STS), six short text clustering, and twelve classification tasks.\nWe also evaluate our representation-shaping techniques on other static models,\nincluding random token representations. Proposed representation extraction\nmethods improve the performance on STS and clustering tasks for all models\nconsidered. Very high improvements for static token-based models, especially\nrandom embeddings for STS tasks, almost reach the performance of BERT-derived\nrepresentations. Our work shows that the representation-shaping techniques\nsignificantly improve sentence embeddings extracted from BERT-based and simple\nbaseline models."
    },
    {
        "date": "2024-08",
        "title": "Automatic Feature Recognition and Dimensional Attributes Extraction From CAD Models for Hybrid Additive-Subtractive Manufacturing",
        "author": "Muhammad Tayyab Khan, Wenhe Feng, Lequn Chen, Ye Han Ng, Nicholas Yew Jin Tan, and Seung Ki Moon",
        "link": "http://arxiv.org/abs/2408.06891v2",
        "abstract": "The integration of Computer-Aided Design (CAD), Computer-Aided Process\nPlanning (CAPP), and Computer-Aided Manufacturing (CAM) plays a crucial role in\nmodern manufacturing, facilitating seamless transitions from digital designs to\nphysical products. However, a significant challenge within this integration is\nthe Automatic Feature Recognition (AFR) of CAD models, especially in the\ncontext of hybrid manufacturing that combines subtractive and additive\nmanufacturing processes. Traditional AFR methods, focused mainly on the\nidentification of subtractive (machined) features including holes, fillets,\nchamfers, pockets, and slots, fail to recognize features pertinent to additive\nmanufacturing. Furthermore, the traditional methods fall short in accurately\nextracting geometric dimensions and orientations, which are also key factors\nfor effective manufacturing process planning. This paper presents a novel\napproach for creating a synthetic CAD dataset that encompasses features\nrelevant to both additive and subtractive machining through Python Open\nCascade. The Hierarchical Graph Convolutional Neural Network (HGCNN) model is\nimplemented to accurately identify the composite additive-subtractive features\nwithin the synthetic CAD dataset. The key novelty and contribution of the\nproposed methodology lie in its ability to recognize a wide range of\nmanufacturing features, and precisely extracting their dimensions,\norientations, and stock sizes. The proposed model demonstrates remarkable\nfeature recognition accuracy exceeding 97% and a dimension extraction accuracy\nof 100% for identified features. Therefore, the proposed methodology enhances\nthe integration of CAD, CAPP, and CAM within hybrid manufacturing by providing\nprecise feature recognition and dimension extraction. It facilitates improved\nmanufacturing process planning, by enabling more informed decision-making."
    },
    {
        "date": "2024-08",
        "title": "Target Prompting for Information Extraction with Vision Language Model",
        "author": "Dipankar Medhi",
        "link": "http://arxiv.org/abs/2408.03834v1",
        "abstract": "The recent trend in the Large Vision and Language model has brought a new\nchange in how information extraction systems are built. VLMs have set a new\nbenchmark with their State-of-the-art techniques in understanding documents and\nbuilding question-answering systems across various industries. They are\nsignificantly better at generating text from document images and providing\naccurate answers to questions. However, there are still some challenges in\neffectively utilizing these models to build a precise conversational system.\nGeneral prompting techniques used with large language models are often not\nsuitable for these specially designed vision language models. The output\ngenerated by such generic input prompts is ordinary and may contain information\ngaps when compared with the actual content of the document. To obtain more\naccurate and specific answers, a well-targeted prompt is required by the vision\nlanguage model, along with the document image. In this paper, a technique is\ndiscussed called Target prompting, which focuses on explicitly targeting parts\nof document images and generating related answers from those specific regions\nonly. The paper also covers the evaluation of response for each prompting\ntechnique using different user queries and input prompts."
    },
    {
        "date": "2024-08",
        "title": "Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction",
        "author": "Benjamin Matthias Ruppik, Michael Heck, Carel van Niekerk, Renato Vukovic, Hsien-chin Lin, Shutong Feng, Marcus Zibrowius, and Milica Ga\u0161i\u0107",
        "link": "http://arxiv.org/abs/2408.03706v1",
        "abstract": "A common approach for sequence tagging tasks based on contextual word\nrepresentations is to train a machine learning classifier directly on these\nembedding vectors. This approach has two shortcomings. First, such methods\nconsider single input sequences in isolation and are unable to put an\nindividual embedding vector in relation to vectors outside the current local\ncontext of use. Second, the high performance of these models relies on\nfine-tuning the embedding model in conjunction with the classifier, which may\nnot always be feasible due to the size or inaccessibility of the underlying\nfeature-generation model. It is thus desirable, given a collection of embedding\nvectors of a corpus, i.e., a datastore, to find features of each vector that\ndescribe its relation to other, similar vectors in the datastore. With this in\nmind, we introduce complexity measures of the local topology of the latent\nspace of a contextual language model with respect to a given datastore. The\neffectiveness of our features is demonstrated through their application to\ndialogue term extraction. Our work continues a line of research that explores\nthe manifold hypothesis for word embeddings, demonstrating that local structure\nin the space carved out by word embeddings can be exploited to infer semantic\nproperties."
    },
    {
        "date": "2024-08",
        "title": "Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection",
        "author": "Sajal Aggarwal, Ananya Pandey, and Dinesh Kumar Vishwakarma",
        "link": "http://arxiv.org/abs/2408.02595v1",
        "abstract": "Sarcasm is a type of irony, characterized by an inherent mismatch between the\nliteral interpretation and the intended connotation. Though sarcasm detection\nin text has been extensively studied, there are situations in which textual\ninput alone might be insufficient to perceive sarcasm. The inclusion of\nadditional contextual cues, such as images, is essential to recognize sarcasm\nin social media data effectively. This study presents a novel framework for\nmultimodal sarcasm detection that can process input triplets. Two components of\nthese triplets comprise the input text and its associated image, as provided in\nthe datasets. Additionally, a supplementary modality is introduced in the form\nof descriptive image captions. The motivation behind incorporating this visual\nsemantic representation is to more accurately capture the discrepancies between\nthe textual and visual content, which are fundamental to the sarcasm detection\ntask. The primary contributions of this study are: (1) a robust textual feature\nextraction branch that utilizes a cross-lingual language model; (2) a visual\nfeature extraction branch that incorporates a self-regulated residual ConvNet\nintegrated with a lightweight spatially aware attention module; (3) an\nadditional modality in the form of image captions generated using an\nencoder-decoder architecture capable of reading text embedded in images; (4)\ndistinct attention modules to effectively identify the incongruities between\nthe text and two levels of image representations; (5) multi-level cross-domain\nsemantic incongruity representation achieved through feature fusion. Compared\nwith cutting-edge baselines, the proposed model achieves the best accuracy of\n92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and\nMultiBully datasets."
    },
    {
        "date": "2024-08",
        "title": "Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models",
        "author": "Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, and Haoyang Li",
        "link": "http://arxiv.org/abs/2408.02416v2",
        "abstract": "The drastic increase of large language models' (LLMs) parameters has led to a\nnew research direction of fine-tuning-free downstream customization by prompts,\ni.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)\nplay an important role in many businesses, there has emerged growing concerns\nabout the prompt leakage, which undermines the intellectual properties of these\nservices and causes downstream attacks. In this paper, we analyze the\nunderlying mechanism of prompt leakage, which we refer to as prompt\nmemorization, and develop corresponding defending strategies. By exploring the\nscaling laws in prompt extraction, we analyze key attributes that influence\nprompt extraction, including model sizes, prompt lengths, as well as the types\nof prompts. Then we propose two hypotheses that explain how LLMs expose their\nprompts. The first is attributed to the perplexity, i.e. the familiarity of\nLLMs to texts, whereas the second is based on the straightforward token\ntranslation path in attention matrices. To defend against such threats, we\ninvestigate whether alignments can undermine the extraction of prompts. We find\nthat current LLMs, even those with safety alignments like GPT-4, are highly\nvulnerable to prompt extraction attacks, even under the most straightforward\nuser attacks. Therefore, we put forward several defense strategies with the\ninspiration of our findings, which achieve 83.8\\% and 71.0\\% drop in the prompt\nextraction rate for Llama2-7B and GPT-3.5, respectively. Source code is\navaliable at https://github.com/liangzid/PromptExtractionEval."
    },
    {
        "date": "2024-08",
        "title": "A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models",
        "author": "Vanni Zavarella, Juan Carlos Gamero-Salinas, and Sergio Consoli",
        "link": "http://arxiv.org/abs/2408.02377v1",
        "abstract": "Knowledge graphs (KGs) have been successfully applied to the analysis of\ncomplex scientific and technological domains, with automatic KG generation\nmethods typically building upon relation extraction models capturing\nfine-grained relations between domain entities in text. While these relations\nare fully applicable across scientific areas, existing models are trained on\nfew domain-specific datasets such as SciERC and do not perform well on new\ntarget domains. In this paper, we experiment with leveraging in-context\nlearning capabilities of Large Language Models to perform schema-constrained\ndata annotation, collecting in-domain training instances for a\nTransformer-based relation extraction model deployed on titles and abstracts of\nresearch papers in the Architecture, Construction, Engineering and Operations\n(AECO) domain. By assessing the performance gain with respect to a baseline\nDeep Learning architecture trained on off-domain data, we show that by using a\nfew-shot learning strategy with structured prompts and only minimal expert\nannotation the presented approach can potentially support domain adaptation of\na science KG generation model."
    },
    {
        "date": "2024-08",
        "title": "VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces",
        "author": "Somnath Sendhil Kumar, Yuvaraj Govindarajulu, Pavan Kulkarni, and Manojkumar Parmar",
        "link": "http://arxiv.org/abs/2408.02140v1",
        "abstract": "In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels."
    },
    {
        "date": "2024-08",
        "title": "Knowledge AI: Fine-tuning NLP Models for Facilitating Scientific Knowledge Extraction and Understanding",
        "author": "Balaji Muralidharan, Hayden Beadles, Reza Marzban, and Kalyan Sashank Mupparaju",
        "link": "http://arxiv.org/abs/2408.04651v1",
        "abstract": "This project investigates the efficacy of Large Language Models (LLMs) in\nunderstanding and extracting scientific knowledge across specific domains and\nto create a deep learning framework: Knowledge AI. As a part of this framework,\nwe employ pre-trained models and fine-tune them on datasets in the scientific\ndomain. The models are adapted for four key Natural Language Processing (NLP)\ntasks: summarization, text generation, question answering, and named entity\nrecognition. Our results indicate that domain-specific fine-tuning\nsignificantly enhances model performance in each of these tasks, thereby\nimproving their applicability for scientific contexts. This adaptation enables\nnon-experts to efficiently query and extract information within targeted\nscientific fields, demonstrating the potential of fine-tuned LLMs as a tool for\nknowledge discovery in the sciences."
    },
    {
        "date": "2024-08",
        "title": "Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data",
        "author": "Antonio De Santis, Marco Balduini, Federico De Santis, Andrea Proia, Arsenio Leo, Marco Brambilla, and Emanuele Della Valle",
        "link": "http://arxiv.org/abs/2408.01700v1",
        "abstract": "Aerospace manufacturing companies, such as Thales Alenia Space, design,\ndevelop, integrate, verify, and validate products characterized by high\ncomplexity and low volume. They carefully document all phases for each product\nbut analyses across products are challenging due to the heterogeneity and\nunstructured nature of the data in documents. In this paper, we propose a\nhybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with\nLarge Language Models (LLMs) to extract and validate data contained in these\ndocuments. We consider a case study focused on test data related to electronic\nboards for satellites. To do so, we extend the Semantic Sensor Network\nontology. We store the metadata of the reports in a KG, while the actual test\nresults are stored in parquet accessible via a Virtual Knowledge Graph. The\nvalidation process is managed using an LLM-based approach. We also conduct a\nbenchmarking study to evaluate the performance of state-of-the-art LLMs in\nexecuting this task. Finally, we analyze the costs and benefits of automating\npreexisting processes of manual data extraction and validation for subsequent\ncross-report analyses."
    },
    {
        "date": "2024-07",
        "title": "FIARSE: Model-Heterogeneous Federated Learning via Importance-Aware Submodel Extraction",
        "author": "Feijie Wu, Xingchen Wang, Yaqing Wang, Tianci Liu, Lu Su, and Jing Gao",
        "link": "http://arxiv.org/abs/2407.19389v3",
        "abstract": "In federated learning (FL), accommodating clients' varied computational\ncapacities poses a challenge, often limiting the participation of those with\nconstrained resources in global model training. To address this issue, the\nconcept of model heterogeneity through submodel extraction has emerged,\noffering a tailored solution that aligns the model's complexity with each\nclient's computational capacity. In this work, we propose Federated\nImportance-Aware Submodel Extraction (FIARSE), a novel approach that\ndynamically adjusts submodels based on the importance of model parameters,\nthereby overcoming the limitations of previous static and dynamic submodel\nextraction methods. Compared to existing works, the proposed method offers a\ntheoretical foundation for the submodel extraction and eliminates the need for\nadditional information beyond the model parameters themselves to determine\nparameter importance, significantly reducing the overhead on clients. Extensive\nexperiments are conducted on various datasets to showcase the superior\nperformance of the proposed FIARSE."
    },
    {
        "date": "2024-07",
        "title": "Human-artificial intelligence teaming for scientific information extraction from data-driven additive manufacturing research using large language models",
        "author": "Mutahar Safdar, Jiarui Xie, Andrei Mircea, and Yaoyao Fiona Zhao",
        "link": "http://arxiv.org/abs/2407.18827v1",
        "abstract": "Data-driven research in Additive Manufacturing (AM) has gained significant\nsuccess in recent years. This has led to a plethora of scientific literature to\nemerge. The knowledge in these works consists of AM and Artificial Intelligence\n(AI) contexts that have not been mined and formalized in an integrated way. It\nrequires substantial effort and time to extract scientific information from\nthese works. AM domain experts have contributed over two dozen review papers to\nsummarize these works. However, information specific to AM and AI contexts\nstill requires manual effort to extract. The recent success of foundation\nmodels such as BERT (Bidirectional Encoder Representations for Transformers) or\nGPT (Generative Pre-trained Transformers) on textual data has opened the\npossibility of expediting scientific information extraction. We propose a\nframework that enables collaboration between AM and AI experts to continuously\nextract scientific information from data-driven AM literature. A demonstration\ntool is implemented based on the proposed framework and a case study is\nconducted to extract information relevant to the datasets, modeling, sensing,\nand AM system categories. We show the ability of LLMs (Large Language Models)\nto expedite the extraction of relevant information from data-driven AM\nliterature. In the future, the framework can be used to extract information\nfrom the broader design and manufacturing literature in the engineering\ndiscipline."
    },
    {
        "date": "2024-07",
        "title": "A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models",
        "author": "Julian Neuberger, Lars Ackermann, Han van der Aa, and Stefan Jablonski",
        "link": "http://arxiv.org/abs/2407.18540v1",
        "abstract": "Over the past decade, extensive research efforts have been dedicated to the\nextraction of information from textual process descriptions. Despite the\nremarkable progress witnessed in natural language processing (NLP), information\nextraction within the Business Process Management domain remains predominantly\nreliant on rule-based systems and machine learning methodologies. Data scarcity\nhas so far prevented the successful application of deep learning techniques.\nHowever, the rapid progress in generative large language models (LLMs) makes it\npossible to solve many NLP tasks with very high quality without the need for\nextensive data. Therefore, we systematically investigate the potential of LLMs\nfor extracting information from textual process descriptions, targeting the\ndetection of process elements such as activities and actors, and relations\nbetween them. Using a heuristic algorithm, we demonstrate the suitability of\nthe extracted information for process model generation. Based on a novel\nprompting strategy, we show that LLMs are able to outperform state-of-the-art\nmachine learning approaches with absolute performance improvements of up to 8\\%\n$F_1$ score across three different datasets. We evaluate our prompting strategy\non eight different LLMs, showing it is universally applicable, while also\nanalyzing the impact of certain prompt parts on extraction quality. The number\nof example texts, the specificity of definitions, and the rigour of format\ninstructions are identified as key for improving the accuracy of extracted\ninformation. Our code, prompts, and data are publicly available."
    },
    {
        "date": "2024-07",
        "title": "SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)",
        "author": "Bernardo Consoli, Xizhi Wu, Song Wang, Xinyu Zhao, Yanshan Wang, Justin Rousseau, Tom Hartvigsen, Li Shen, Huanmei Wu, Yifan Peng, Qi Long, Tianlong Chen, and Ying Ding",
        "link": "http://arxiv.org/abs/2407.17126v1",
        "abstract": "Extracting social determinants of health (SDoH) from unstructured medical\nnotes depends heavily on labor-intensive annotations, which are typically\ntask-specific, hampering reusability and limiting sharing. In this study we\nintroduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM)\nmethod leveraging contrastive examples and concise instructions to extract SDoH\nwithout relying on extensive medical annotations or costly human intervention.\nIt achieved tenfold and twentyfold reductions in time and cost respectively,\nand superior consistency with human annotators measured by Cohen's kappa of up\nto 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the\nstrengths of both, ensuring high accuracy and computational efficiency while\nconsistently maintaining 0.90+ AUROC scores. Testing across three distinct\ndatasets has confirmed its robustness and accuracy. This study highlights the\npotential of leveraging LLMs to revolutionize medical note classification,\ndemonstrating their capability to achieve highly accurate classifications with\nsignificantly reduced time and cost."
    },
    {
        "date": "2024-07",
        "title": "From Text to Insight: Large Language Models for Materials Science Data Extraction",
        "author": "Mara Schilling-Wilhelmi, Marti\u00f1o R\u00edos-Garc\u00eda, Sherjeel Shabih, Mar\u00eda Victoria Gil, Santiago Miret, Christoph T. Koch, Jos\u00e9 A. M\u00e1rquez, and Kevin Maik Jablonka",
        "link": "http://arxiv.org/abs/2407.16867v2",
        "abstract": "The vast majority of materials science knowledge exists in unstructured\nnatural language, yet structured data is crucial for innovative and systematic\nmaterials design. Traditionally, the field has relied on manual curation and\npartial automation for data extraction for specific use cases. The advent of\nlarge language models (LLMs) represents a significant shift, potentially\nenabling efficient extraction of structured, actionable data from unstructured\ntext by non-experts. While applying LLMs to materials science data extraction\npresents unique challenges, domain knowledge offers opportunities to guide and\nvalidate LLM outputs. This review provides a comprehensive overview of\nLLM-based structured data extraction in materials science, synthesizing current\nknowledge and outlining future directions. We address the lack of standardized\nguidelines and present frameworks for leveraging the synergy between LLMs and\nmaterials science expertise. This work serves as a foundational resource for\nresearchers aiming to harness LLMs for data-driven materials research. The\ninsights presented here could significantly enhance how researchers across\ndisciplines access and utilize scientific information, potentially accelerating\nthe development of novel materials for critical societal needs."
    },
    {
        "date": "2024-07",
        "title": "Causality extraction from medical text using Large Language Models (LLMs)",
        "author": "Seethalakshmi Gopalakrishnan, Luciana Garbayo, and Wlodek Zadrozny",
        "link": "http://arxiv.org/abs/2407.10020v1",
        "abstract": "This study explores the potential of natural language models, including large\nlanguage models, to extract causal relations from medical texts, specifically\nfrom Clinical Practice Guidelines (CPGs). The outcomes causality extraction\nfrom Clinical Practice Guidelines for gestational diabetes are presented,\nmarking a first in the field. We report on a set of experiments using variants\nof BERT (BioBERT, DistilBERT, and BERT) and using Large Language Models (LLMs),\nnamely GPT-4 and LLAMA2. Our experiments show that BioBERT performed better\nthan other models, including the Large Language Models, with an average\nF1-score of 0.72. GPT-4 and LLAMA2 results show similar performance but less\nconsistency. We also release the code and an annotated a corpus of causal\nstatements within the Clinical Practice Guidelines for gestational diabetes."
    },
    {
        "date": "2024-07",
        "title": "Empowering Few-Shot Relation Extraction with The Integration of Traditional RE Methods and Large Language Models",
        "author": "Ye Liu, Kai Zhang, Aoran Gan, Linan Yue, Feng Hu, Qi Liu, and Enhong Chen",
        "link": "http://arxiv.org/abs/2407.08967v1",
        "abstract": "Few-Shot Relation Extraction (FSRE), a subtask of Relation Extraction (RE)\nthat utilizes limited training instances, appeals to more researchers in\nNatural Language Processing (NLP) due to its capability to extract textual\ninformation in extremely low-resource scenarios. The primary methodologies\nemployed for FSRE have been fine-tuning or prompt tuning techniques based on\nPre-trained Language Models (PLMs). Recently, the emergence of Large Language\nModels (LLMs) has prompted numerous researchers to explore FSRE through\nIn-Context Learning (ICL). However, there are substantial limitations\nassociated with methods based on either traditional RE models or LLMs.\nTraditional RE models are hampered by a lack of necessary prior knowledge,\nwhile LLMs fall short in their task-specific capabilities for RE. To address\nthese shortcomings, we propose a Dual-System Augmented Relation Extractor\n(DSARE), which synergistically combines traditional RE models with LLMs.\nSpecifically, DSARE innovatively injects the prior knowledge of LLMs into\ntraditional RE models, and conversely enhances LLMs' task-specific aptitude for\nRE through relation extraction augmentation. Moreover, an Integrated Prediction\nmodule is employed to jointly consider these two respective predictions and\nderive the final results. Extensive experiments demonstrate the efficacy of our\nproposed method."
    },
    {
        "date": "2024-07",
        "title": "Extracting Training Data from Document-Based VQA Models",
        "author": "Francesco Pinto, Nathalie Rauschmayr, Florian Tram\u00e8r, Philip Torr, and Federico Tombari",
        "link": "http://arxiv.org/abs/2407.08707v1",
        "abstract": "Vision-Language Models (VLMs) have made remarkable progress in document-based\nVisual Question Answering (i.e., responding to queries about the contents of an\ninput document provided as an image). In this work, we show these models can\nmemorize responses for training samples and regurgitate them even when the\nrelevant visual information has been removed. This includes Personal\nIdentifiable Information (PII) repeated once in the training set, indicating\nthese models could divulge memorised sensitive information and therefore pose a\nprivacy risk. We quantitatively measure the extractability of information in\ncontrolled experiments and differentiate between cases where it arises from\ngeneralization capabilities or from memorization. We further investigate the\nfactors that influence memorization across multiple state-of-the-art models and\npropose an effective heuristic countermeasure that empirically prevents the\nextractability of PII."
    },
    {
        "date": "2024-07",
        "title": "ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction",
        "author": "Shaozhe Hao, Kai Han, Zhengyao Lv, Shihao Zhao, and Kwan-Yee K. Wong",
        "link": "http://arxiv.org/abs/2407.07077v1",
        "abstract": "While personalized text-to-image generation has enabled the learning of a\nsingle concept from multiple images, a more practical yet challenging scenario\ninvolves learning multiple concepts within a single image. However, existing\nworks tackling this scenario heavily rely on extensive human annotations. In\nthis paper, we introduce a novel task named Unsupervised Concept Extraction\n(UCE) that considers an unsupervised setting without any human knowledge of the\nconcepts. Given an image that contains multiple concepts, the task aims to\nextract and recreate individual concepts solely relying on the existing\nknowledge from pretrained diffusion models. To achieve this, we present\nConceptExpress that tackles UCE by unleashing the inherent capabilities of\npretrained diffusion models in two aspects. Specifically, a concept\nlocalization approach automatically locates and disentangles salient concepts\nby leveraging spatial correspondence from diffusion self-attention; and based\non the lookup association between a concept and a conceptual token, a\nconcept-wise optimization process learns discriminative tokens that represent\neach individual concept. Finally, we establish an evaluation protocol tailored\nfor the UCE task. Extensive experiments demonstrate that ConceptExpress is a\npromising solution to the UCE task. Our code and data are available at:\nhttps://github.com/haoosz/ConceptExpress"
    },
    {
        "date": "2024-07",
        "title": "Large Language Models for Judicial Entity Extraction: A Comparative Study",
        "author": "Atin Sakkeer Hussain, and Anu Thomas",
        "link": "http://arxiv.org/abs/2407.05786v1",
        "abstract": "Domain-specific Entity Recognition holds significant importance in legal\ncontexts, serving as a fundamental task that supports various applications such\nas question-answering systems, text summarization, machine translation,\nsentiment analysis, and information retrieval specifically within case law\ndocuments. Recent advancements have highlighted the efficacy of Large Language\nModels in natural language processing tasks, demonstrating their capability to\naccurately detect and classify domain-specific facts (entities) from\nspecialized texts like clinical and financial documents. This research\ninvestigates the application of Large Language Models in identifying\ndomain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents,\nFIR nos.) within case law documents, with a specific focus on their aptitude\nfor handling domain-specific language complexity and contextual variations. The\nstudy evaluates the performance of state-of-the-art Large Language Model\narchitectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in\nthe context of extracting judicial facts tailored to Indian judicial texts.\nMistral and Gemma emerged as the top-performing models, showcasing balanced\nprecision and recall crucial for accurate entity identification. These findings\nconfirm the value of Large Language Models in judicial documents and\ndemonstrate how they can facilitate and quicken scientific research by\nproducing precise, organised data outputs that are appropriate for in-depth\nexamination."
    },
    {
        "date": "2024-07",
        "title": "Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation",
        "author": "Pablo Messina, Ren\u00e9 Vidal, Denis Parra, \u00c1lvaro Soto, and Vladimir Araujo",
        "link": "http://arxiv.org/abs/2407.01948v1",
        "abstract": "Advancing representation learning in specialized fields like medicine remains\nchallenging due to the scarcity of expert annotations for text and images. To\ntackle this issue, we present a novel two-stage framework designed to extract\nhigh-quality factual statements from free-text radiology reports in order to\nimprove the representations of text encoders and, consequently, their\nperformance on various downstream tasks. In the first stage, we propose a\n\\textit{Fact Extractor} that leverages large language models (LLMs) to identify\nfactual statements from well-curated domain-specific datasets. In the second\nstage, we introduce a \\textit{Fact Encoder} (CXRFE) based on a BERT model\nfine-tuned with objective functions designed to improve its representations\nusing the extracted factual data. Our framework also includes a new\nembedding-based metric (CXRFEScore) for evaluating chest X-ray text generation\nsystems, leveraging both stages of our approach. Extensive evaluations show\nthat our fact extractor and encoder outperform current state-of-the-art methods\nin tasks such as sentence ranking, natural language inference, and label\nextraction from radiology reports. Additionally, our metric proves to be more\nrobust and effective than existing metrics commonly used in the radiology\nreport generation literature. The code of this project is available at\n\\url{https://github.com/PabloMessina/CXR-Fact-Encoder}."
    },
    {
        "date": "2024-07",
        "title": "QUEEN: Query Unlearning against Model Extraction",
        "author": "Huajie Chen, Tianqing Zhu, Lefeng Zhang, Bo Liu, Derui Wang, Wanlei Zhou, and Minhui Xue",
        "link": "http://arxiv.org/abs/2407.01251v1",
        "abstract": "Model extraction attacks currently pose a non-negligible threat to the\nsecurity and privacy of deep learning models. By querying the model with a\nsmall dataset and usingthe query results as the ground-truth labels, an\nadversary can steal a piracy model with performance comparable to the original\nmodel. Two key issues that cause the threat are, on the one hand, accurate and\nunlimited queries can be obtained by the adversary; on the other hand, the\nadversary can aggregate the query results to train the model step by step. The\nexisting defenses usually employ model watermarking or fingerprinting to\nprotect the ownership. However, these methods cannot proactively prevent the\nviolation from happening. To mitigate the threat, we propose QUEEN (QUEry\nunlEarNing) that proactively launches counterattacks on potential model\nextraction attacks from the very beginning. To limit the potential threat,\nQUEEN has sensitivity measurement and outputs perturbation that prevents the\nadversary from training a piracy model with high performance. In sensitivity\nmeasurement, QUEEN measures the single query sensitivity by its distance from\nthe center of its cluster in the feature space. To reduce the learning accuracy\nof attacks, for the highly sensitive query batch, QUEEN applies query\nunlearning, which is implemented by gradient reverse to perturb the softmax\noutput such that the piracy model will generate reverse gradients to worsen its\nperformance unconsciously. Experiments show that QUEEN outperforms the\nstate-of-the-art defenses against various model extraction attacks with a\nrelatively low cost to the model accuracy. The artifact is publicly available\nat https://anonymous.4open.science/r/queen implementation-5408/."
    },
    {
        "date": "2024-06",
        "title": "Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs",
        "author": "Lokesh Mishra, Sohayl Dhibi, Yusik Kim, Cesar Berrospi Ramis, Shubham Gupta, Michele Dolfi, and Peter Staar",
        "link": "http://arxiv.org/abs/2406.19102v1",
        "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability\nin the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based\nStatement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports."
    },
    {
        "date": "2024-06",
        "title": "Research on Information Extraction of LCSTS Dataset Based on an Improved BERTSum-LSTM Model",
        "author": "Yiming Chen, Haobin Chen, Simin Liu, Yunyun Liu, Fanhao Zhou, and Bing Wei",
        "link": "http://arxiv.org/abs/2406.18364v1",
        "abstract": "With the continuous advancement of artificial intelligence, natural language\nprocessing technology has become widely utilized in various fields. At the same\ntime, there are many challenges in creating Chinese news summaries. First of\nall, the semantics of Chinese news is complex, and the amount of information is\nenormous. Extracting critical information from Chinese news presents a\nsignificant challenge. Second, the news summary should be concise and clear,\nfocusing on the main content and avoiding redundancy. In addition, the\nparticularity of the Chinese language, such as polysemy, word segmentation,\netc., makes it challenging to generate Chinese news summaries. Based on the\nabove, this paper studies the information extraction method of the LCSTS\ndataset based on an improved BERTSum-LSTM model. We improve the BERTSum-LSTM\nmodel to make it perform better in generating Chinese news summaries. The\nexperimental results show that the proposed method has a good effect on\ncreating news summaries, which is of great importance to the construction of\nnews summaries."
    },
    {
        "date": "2024-06",
        "title": "Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources",
        "author": "Yiming Li, Deepthi Viswaroopan, William He, Jianfu Li, Xu Zuo, Hua Xu, and Cui Tao",
        "link": "http://arxiv.org/abs/2406.18049v1",
        "abstract": "Adverse event (AE) extraction following COVID-19 vaccines from text data is\ncrucial for monitoring and analyzing the safety profiles of immunizations.\nTraditional deep learning models are adept at learning intricate feature\nrepresentations and dependencies in sequential data, but often require\nextensive labeled data. In contrast, large language models (LLMs) excel in\nunderstanding contextual information, but exhibit unstable performance on named\nentity recognition tasks, possibly due to their broad but unspecific training.\nThis study aims to evaluate the effectiveness of LLMs and traditional deep\nlearning models in AE extraction, and to assess the impact of ensembling these\nmodels on performance. In this study, we utilized reports and posts from the\nVAERS (n=621), Twitter (n=9,133), and Reddit (n=131) as our corpora. Our goal\nwas to extract three types of entities: \"vaccine\", \"shot\", and \"ae\". We\nexplored and fine-tuned (except GPT-4) multiple LLMs, including GPT-2, GPT-3.5,\nGPT-4, and Llama-2, as well as traditional deep learning models like RNN and\nBioBERT. To enhance performance, we created ensembles of the three models with\nthe best performance. For evaluation, we used strict and relaxed F1 scores to\nevaluate the performance for each entity type, and micro-average F1 was used to\nassess the overall performance. The ensemble model achieved the highest\nperformance in \"vaccine\", \"shot\", and \"ae\" with strict F1-scores of 0.878,\n0.930, and 0.925, respectively, along with a micro-average score of 0.903. In\nconclusion, this study demonstrates the effectiveness and robustness of\nensembling fine-tuned traditional deep learning models and LLMs, for extracting\nAE-related information. This study contributes to the advancement of biomedical\nnatural language processing, providing valuable insights into improving AE\nextraction from text data for pharmacovigilance and public health surveillance."
    },
    {
        "date": "2024-06",
        "title": "Enabling Regional Explainability by Automatic and Model-agnostic Rule Extraction",
        "author": "Yu Chen, Tianyu Cui, Alexander Capstick, Nan Fletcher-Loyd, and Payam Barnaghi",
        "link": "http://arxiv.org/abs/2406.17885v3",
        "abstract": "In Explainable AI, rule extraction translates model knowledge into logical\nrules, such as IF-THEN statements, crucial for understanding patterns learned\nby black-box models. This could significantly aid in fields like disease\ndiagnosis, disease progression estimation, or drug discovery. However, such\napplication domains often contain imbalanced data, with the class of interest\nunderrepresented. Existing methods inevitably compromise the performance of\nrules for the minor class to maximise the overall performance. As the first\nattempt in this field, we propose a model-agnostic approach for extracting\nrules from specific subgroups of data, featuring automatic rule generation for\nnumerical features. This method enhances the regional explainability of machine\nlearning models and offers wider applicability compared to existing methods. We\nadditionally introduce a new method for selecting features to compose rules,\nreducing computational costs in high-dimensional spaces. Experiments across\nvarious datasets and models demonstrate the effectiveness of our methods."
    },
    {
        "date": "2024-06",
        "title": "Compact Model Parameter Extraction via Derivative-Free Optimization",
        "author": "Rafael Perez Martinez, Masaya Iwamoto, Kelly Woo, Zhengliang Bian, Roberto Tinti, Stephen Boyd, and Srabanti Chowdhury",
        "link": "http://arxiv.org/abs/2406.16355v2",
        "abstract": "In this paper, we address the problem of compact model parameter extraction\nto simultaneously extract tens of parameters via derivative-free optimization.\nTraditionally, parameter extraction is performed manually by dividing the\ncomplete set of parameters into smaller subsets, each targeting different\noperational regions of the device, a process that can take several days or\nweeks. Our approach streamlines this process by employing derivative-free\noptimization to identify a good parameter set that best fits the compact model\nwithout performing an exhaustive number of simulations. We further enhance the\noptimization process to address three critical issues in device modeling by\ncarefully choosing a loss function that focuses on relative errors rather than\nabsolute errors to ensure consistent performance across different orders of\nmagnitude, prioritizes accuracy in key operational regions above a specific\nthreshold, and reduces sensitivity to outliers. Furthermore, we utilize the\nconcept of train-test split to assess the model fit and avoid overfitting. We\ndemonstrate the effectiveness of our approach by successfully modeling a\ndiamond Schottky diode with the SPICE diode model and a GaN-on-SiC HEMT with\nthe ASM-HEMT model. For the latter, which involves extracting 35 parameters for\nthe ASM-HEMT DC model, we identified the best set of parameters in under 6,000\ntrials. Additional examples using both devices are provided to demonstrate\nrobustness to outliers, showing that an excellent fit is achieved even with\nover 25% of the data purposely corrupted. These examples demonstrate the\npracticality of our approach, highlighting the benefits of derivative-free\noptimization in device modeling."
    },
    {
        "date": "2024-06",
        "title": "Large Language Models for Link Stealing Attacks Against Graph Neural Networks",
        "author": "Faqian Guan, Tianqing Zhu, Hui Sun, Wanlei Zhou, and Philip S. Yu",
        "link": "http://arxiv.org/abs/2406.16963v1",
        "abstract": "Graph data contains rich node features and unique edge information, which\nhave been applied across various domains, such as citation networks or\nrecommendation systems. Graph Neural Networks (GNNs) are specialized for\nhandling such data and have shown impressive performance in many applications.\nHowever, GNNs may contain of sensitive information and susceptible to privacy\nattacks. For example, link stealing is a type of attack in which attackers\ninfer whether two nodes are linked or not. Previous link stealing attacks\nprimarily relied on posterior probabilities from the target GNN model,\nneglecting the significance of node features. Additionally, variations in node\nclasses across different datasets lead to different dimensions of posterior\nprobabilities. The handling of these varying data dimensions posed a challenge\nin using a single model to effectively conduct link stealing attacks on\ndifferent datasets. To address these challenges, we introduce Large Language\nModels (LLMs) to perform link stealing attacks on GNNs. LLMs can effectively\nintegrate textual features and exhibit strong generalizability, enabling\nattacks to handle diverse data dimensions across various datasets. We design\ntwo distinct LLM prompts to effectively combine textual features and posterior\nprobabilities of graph nodes. Through these designed prompts, we fine-tune the\nLLM to adapt to the link stealing attack task. Furthermore, we fine-tune the\nLLM using multiple datasets and enable the LLM to learn features from different\ndatasets simultaneously. Experimental results show that our approach\nsignificantly enhances the performance of existing link stealing attack tasks\nin both white-box and black-box scenarios. Our method can execute link stealing\nattacks across different datasets using only a single model, making link\nstealing attacks more applicable to real-world scenarios."
    },
    {
        "date": "2024-06",
        "title": "Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks",
        "author": "Sefika Efeoglu, and Adrian Paschke",
        "link": "http://arxiv.org/abs/2406.14745v2",
        "abstract": "Information Extraction (IE) is crucial for converting unstructured data into\nstructured formats like Knowledge Graphs (KGs). A key task within IE is\nRelation Extraction (RE), which identifies relationships between entities in\ntext. Various RE methods exist, including supervised, unsupervised, weakly\nsupervised, and rule-based approaches. Recent studies leveraging pre-trained\nlanguage models (PLMs) have shown significant success in this area. In the\ncurrent era dominated by Large Language Models (LLMs), fine-tuning these models\ncan overcome limitations associated with zero-shot LLM prompting-based RE\nmethods, especially regarding domain adaptation challenges and identifying\nimplicit relations between entities in sentences. These implicit relations,\nwhich cannot be easily extracted from a sentence's dependency tree, require\nlogical inference for accurate identification. This work explores the\nperformance of fine-tuned LLMs and their integration into the Retrieval\nAugmented-based (RAG) RE approach to address the challenges of identifying\nimplicit relations at the sentence level, particularly when LLMs act as\ngenerators within the RAG framework. Empirical evaluations on the TACRED,\nTACRED-Revisited (TACREV), Re-TACRED, and SemEVAL datasets show significant\nperformance improvements with fine-tuned LLMs, including Llama2-7B, Mistral-7B,\nand T5 (Large). Notably, our approach achieves substantial gains on SemEVAL,\nwhere implicit relations are common, surpassing previous results on this\ndataset. Additionally, our method outperforms previous works on TACRED, TACREV,\nand Re-TACRED, demonstrating exceptional performance across diverse evaluation\nscenarios."
    },
    {
        "date": "2024-06",
        "title": "Extracting Training Data from Unconditional Diffusion Models",
        "author": "Yunhao Chen, Xingjun Ma, Difan Zou, and Yu-Gang Jiang",
        "link": "http://arxiv.org/abs/2406.12752v2",
        "abstract": "As diffusion probabilistic models (DPMs) are being employed as mainstream\nmodels for generative artificial intelligence (AI), the study of their\nmemorization of the raw training data has attracted growing attention. Existing\nworks in this direction aim to establish an understanding of whether or to what\nextent DPMs learn by memorization. Such an understanding is crucial for\nidentifying potential risks of data leakage and copyright infringement in\ndiffusion models and, more importantly, for more controllable generation and\ntrustworthy application of Artificial Intelligence Generated Content (AIGC).\nWhile previous works have made important observations of when DPMs are prone to\nmemorization, these findings are mostly empirical, and the developed data\nextraction methods only work for conditional diffusion models. In this work, we\naim to establish a theoretical understanding of memorization in DPMs with 1) a\nmemorization metric for theoretical analysis, 2) an analysis of conditional\nmemorization with informative and random labels, and 3) two better evaluation\nmetrics for measuring memorization. Based on the theoretical analysis, we\nfurther propose a novel data extraction method called \\textbf{Surrogate\ncondItional Data Extraction (SIDE)} that leverages a classifier trained on\ngenerated data as a surrogate condition to extract training data directly from\nunconditional diffusion models. Our empirical results demonstrate that SIDE can\nextract training data from diffusion models where previous methods fail, and it\nis on average over 50\\% more effective across different scales of the CelebA\ndataset."
    },
    {
        "date": "2024-06",
        "title": "Adaptive Reinforcement Learning Planning: Harnessing Large Language Models for Complex Information Extraction",
        "author": "Zepeng Ding, Ruiyang Ke, Wenhao Huang, Guochao Jiang, Yanda Li, Deqing Yang, and Jiaqing Liang",
        "link": "http://arxiv.org/abs/2406.11455v2",
        "abstract": "Existing research on large language models (LLMs) shows that they can solve\ninformation extraction tasks through multi-step planning. However, their\nextraction behavior on complex sentences and tasks is unstable, emerging issues\nsuch as false positives and missing elements. We observe that decomposing\ncomplex extraction tasks and extracting them step by step can effectively\nimprove LLMs' performance, and the extraction orders of entities significantly\naffect the final results of LLMs. This paper proposes a two-stage multi-step\nmethod for LLM-based information extraction and adopts the RL framework to\nexecute the multi-step planning. We regard sequential extraction as a Markov\ndecision process, build an LLM-based extraction environment, design a decision\nmodule to adaptively provide the optimal order for sequential entity extraction\non different sentences, and utilize the DDQN algorithm to train the decision\nmodel. We also design the rewards and evaluation metrics suitable for the\nextraction results of LLMs. We conduct extensive experiments on multiple public\ndatasets to demonstrate the effectiveness of our method in improving the\ninformation extraction capabilities of LLMs."
    },
    {
        "date": "2024-06",
        "title": "How Should We Extract Discrete Audio Tokens from Self-Supervised Models?",
        "author": "Pooneh Mousavi, Jarod Duret, Salah Zaiem, Luca Della Libera, Artem Ploujnikov, Cem Subakan, and Mirco Ravanelli",
        "link": "http://arxiv.org/abs/2406.10735v1",
        "abstract": "Discrete audio tokens have recently gained attention for their potential to\nbridge the gap between audio and language processing. Ideal audio tokens must\npreserve content, paralinguistic elements, speaker identity, and many other\naudio details. Current audio tokenization methods fall into two categories:\nSemantic tokens, acquired through quantization of Self-Supervised Learning\n(SSL) models, and Neural compression-based tokens (codecs). Although previous\nstudies have benchmarked codec models to identify optimal configurations, the\nideal setup for quantizing pretrained SSL models remains unclear. This paper\nexplores the optimal configuration of semantic tokens across discriminative and\ngenerative tasks. We propose a scalable solution to train a universal vocoder\nacross multiple SSL layers. Furthermore, an attention mechanism is employed to\nidentify task-specific influential layers, enhancing the adaptability and\nperformance of semantic tokens in diverse audio applications."
    },
    {
        "date": "2024-06",
        "title": "GLiNER multi-task: Generalist Lightweight Model for Various Information Extraction Tasks",
        "author": "Ihor Stepanov, and Mykhailo Shtopko",
        "link": "http://arxiv.org/abs/2406.12925v2",
        "abstract": "Information extraction tasks require both accurate, efficient, and\ngeneralisable models. Classical supervised deep learning approaches can achieve\nthe required performance, but they need large datasets and are limited in their\nability to adapt to different tasks. On the other hand, large language models\n(LLMs) demonstrate good generalization, meaning that they can adapt to many\ndifferent tasks based on user requests. However, LLMs are computationally\nexpensive and tend to fail to generate structured outputs. In this article, we\nwill introduce a new kind of GLiNER model that can be used for various\ninformation extraction tasks while being a small encoder model. Our model\nachieved SoTA performance on zero-shot NER benchmarks and leading performance\non question-answering, summarization and relation extraction tasks.\nAdditionally, in this article, we will cover experimental results on\nself-learning approaches for named entity recognition using GLiNER models."
    },
    {
        "date": "2024-06",
        "title": "Beyond Slow Signs in High-fidelity Model Extraction",
        "author": "Hanna Foerster, Robert Mullins, Ilia Shumailov, and Jamie Hayes",
        "link": "http://arxiv.org/abs/2406.10011v1",
        "abstract": "Deep neural networks, costly to train and rich in intellectual property\nvalue, are increasingly threatened by model extraction attacks that compromise\ntheir confidentiality. Previous attacks have succeeded in reverse-engineering\nmodel parameters up to a precision of float64 for models trained on random data\nwith at most three hidden layers using cryptanalytical techniques. However, the\nprocess was identified to be very time consuming and not feasible for larger\nand deeper models trained on standard benchmarks. Our study evaluates the\nfeasibility of parameter extraction methods of Carlini et al. [1] further\nenhanced by Canales-Mart\\'inez et al. [2] for models trained on standard\nbenchmarks. We introduce a unified codebase that integrates previous methods\nand reveal that computational tools can significantly influence performance. We\ndevelop further optimisations to the end-to-end attack and improve the\nefficiency of extracting weight signs by up to 14.8 times compared to former\nmethods through the identification of easier and harder to extract neurons.\nContrary to prior assumptions, we identify extraction of weights, not\nextraction of weight signs, as the critical bottleneck. With our improvements,\na 16,721 parameter model with 2 hidden layers trained on MNIST is extracted\nwithin only 98 minutes compared to at least 150 minutes previously. Finally,\naddressing methodological deficiencies observed in previous studies, we propose\nnew ways of robust benchmarking for future model extraction attacks."
    },
    {
        "date": "2024-06",
        "title": "RadEx: A Framework for Structured Information Extraction from Radiology Reports based on Large Language Models",
        "author": "Daniel Reichenpfader, Jonas Knupp, Andr\u00e9 Sander, and Kerstin Denecke",
        "link": "http://arxiv.org/abs/2406.15465v1",
        "abstract": "Annually and globally, over three billion radiography examinations and\ncomputer tomography scans result in mostly unstructured radiology reports\ncontaining free text. Despite the potential benefits of structured reporting,\nits adoption is limited by factors such as established processes, resource\nconstraints and potential loss of information. However, structured information\nwould be necessary for various use cases, including automatic analysis,\nclinical trial matching, and prediction of health outcomes. This study\nintroduces RadEx, an end-to-end framework comprising 15 software components and\nten artifacts to develop systems that perform automated information extraction\nfrom radiology reports. It covers the complete process from annotating training\ndata to extracting information by offering a consistent generic information\nmodel and setting boundaries for model development. Specifically, RadEx allows\nclinicians to define relevant information for clinical domains (e.g.,\nmammography) and to create report templates. The framework supports both\ngenerative and encoder-only models and the decoupling of information extraction\nfrom template filling enables independent model improvements. Developing\ninformation extraction systems according to the RadEx framework facilitates\nimplementation and maintenance as components are easily exchangeable, while\nstandardized artifacts ensure interoperability between components."
    },
    {
        "date": "2024-06",
        "title": "Research on Deep Learning Model of Feature Extraction Based on Convolutional Neural Network",
        "author": "Houze Liu, Iris Li, Yaxin Liang, Dan Sun, Yining Yang, and Haowei Yang",
        "link": "http://arxiv.org/abs/2406.08837v1",
        "abstract": "Neural networks with relatively shallow layers and simple structures may have\nlimited ability in accurately identifying pneumonia. In addition, deep neural\nnetworks also have a large demand for computing resources, which may cause\nconvolutional neural networks to be unable to be implemented on terminals.\nTherefore, this paper will carry out the optimal classification of\nconvolutional neural networks. Firstly, according to the characteristics of\npneumonia images, AlexNet and InceptionV3 were selected to obtain better image\nrecognition results. Combining the features of medical images, the forward\nneural network with deeper and more complex structure is learned. Finally,\nknowledge extraction technology is used to extract the obtained data into the\nAlexNet model to achieve the purpose of improving computing efficiency and\nreducing computing costs. The results showed that the prediction accuracy,\nspecificity, and sensitivity of the trained AlexNet model increased by 4.25\npercentage points, 7.85 percentage points, and 2.32 percentage points,\nrespectively. The graphics processing usage has decreased by 51% compared to\nthe InceptionV3 mode."
    },
    {
        "date": "2024-06",
        "title": "A Combination Model for Time Series Prediction using LSTM via Extracting Dynamic Features Based on Spatial Smoothing and Sequential General Variational Mode Decomposition",
        "author": "Jianyu Liu, Wei Chen, Yong Zhang, Zhenfeng Chen, Bin Wan, and Jinwei Hu",
        "link": "http://arxiv.org/abs/2406.03144v1",
        "abstract": "In order to solve the problems such as difficult to extract effective\nfeatures and low accuracy of sales volume prediction caused by complex\nrelationships such as market sales volume in time series prediction, we\nproposed a time series prediction method of market sales volume based on\nSequential General VMD and spatial smoothing Long short-term memory neural\nnetwork (SS-LSTM) combination model. Firstly, the spatial smoothing algorithm\nis used to decompose and calculate the sample data of related industry sectors\naffected by the linkage effect of market sectors, extracting modal features\ncontaining information via Sequential General VMD on overall market and\nspecific price trends; Then, according to the background of different Market\ndata sets, LSTM network is used to model and predict the price of fundamental\ndata and modal characteristics. The experimental results of data prediction\nwith seasonal and periodic trends show that this method can achieve higher\nprice prediction accuracy and more accurate accuracy in specific market\ncontexts compared to traditional prediction methods Describe the changes in\nmarket sales volume."
    },
    {
        "date": "2024-05",
        "title": "Large Language Model Watermark Stealing With Mixed Integer Programming",
        "author": "Zhaoxi Zhang, Xiaomei Zhang, Yanjun Zhang, Leo Yu Zhang, Chao Chen, Shengshan Hu, Asif Gill, and Shirui Pan",
        "link": "http://arxiv.org/abs/2405.19677v1",
        "abstract": "The Large Language Model (LLM) watermark is a newly emerging technique that\nshows promise in addressing concerns surrounding LLM copyright, monitoring\nAI-generated text, and preventing its misuse. The LLM watermark scheme commonly\nincludes generating secret keys to partition the vocabulary into green and red\nlists, applying a perturbation to the logits of tokens in the green list to\nincrease their sampling likelihood, thus facilitating watermark detection to\nidentify AI-generated text if the proportion of green tokens exceeds a\nthreshold. However, recent research indicates that watermarking methods using\nnumerous keys are susceptible to removal attacks, such as token editing,\nsynonym substitution, and paraphrasing, with robustness declining as the number\nof keys increases. Therefore, the state-of-the-art watermark schemes that\nemploy fewer or single keys have been demonstrated to be more robust against\ntext editing and paraphrasing. In this paper, we propose a novel green list\nstealing attack against the state-of-the-art LLM watermark scheme and\nsystematically examine its vulnerability to this attack. We formalize the\nattack as a mixed integer programming problem with constraints. We evaluate our\nattack under a comprehensive threat model, including an extreme scenario where\nthe attacker has no prior knowledge, lacks access to the watermark detector\nAPI, and possesses no information about the LLM's parameter settings or\nwatermark injection/detection scheme. Extensive experiments on LLMs, such as\nOPT and LLaMA, demonstrate that our attack can successfully steal the green\nlist and remove the watermark across all settings."
    },
    {
        "date": "2024-05",
        "title": "Extracting Heuristics from Large Language Models for Reward Shaping in Reinforcement Learning",
        "author": "Siddhant Bhambri, Amrita Bhattacharjee, Durgesh Kalwar, Lin Guan, Huan Liu, and Subbarao Kambhampati",
        "link": "http://arxiv.org/abs/2405.15194v2",
        "abstract": "Reinforcement Learning (RL) suffers from sample inefficiency in sparse reward\ndomains, and the problem is further pronounced in case of stochastic\ntransitions. To improve the sample efficiency, reward shaping is a well-studied\napproach to introduce intrinsic rewards that can help the RL agent converge to\nan optimal policy faster. However, designing a useful reward shaping function\nfor all desirable states in the Markov Decision Process (MDP) is challenging,\neven for domain experts. Given that Large Language Models (LLMs) have\ndemonstrated impressive performance across a magnitude of natural language\ntasks, we aim to answer the following question: `Can we obtain heuristics using\nLLMs for constructing a reward shaping function that can boost an RL agent's\nsample efficiency?' To this end, we aim to leverage off-the-shelf LLMs to\ngenerate a plan for an abstraction of the underlying MDP. We further use this\nLLM-generated plan as a heuristic to construct the reward shaping signal for\nthe downstream RL agent. By characterizing the type of abstraction based on the\nMDP horizon length, we analyze the quality of heuristics when generated using\nan LLM, with and without a verifier in the loop. Our experiments across\nmultiple domains with varying horizon length and number of sub-goals from the\nBabyAI environment suite, Household, Mario, and, Minecraft domain, show 1) the\nadvantages and limitations of querying LLMs with and without a verifier to\ngenerate a reward shaping heuristic, and, 2) a significant improvement in the\nsample efficiency of PPO, A2C, and Q-learning when guided by the LLM-generated\nheuristics."
    },
    {
        "date": "2024-05",
        "title": "Evaluating Large Language Models for Public Health Classification and Extraction Tasks",
        "author": "Joshua Harris, Timothy Laurence, Leo Loman, Fan Grayson, Toby Nonnenmacher, Harry Long, Loes WalsGriffith, Amy Douglas, Holly Fountain, Stelios Georgiou, Jo Hardstaff, Kathryn Hopkins, Y-Ling Chi, Galena Kuyumdzhieva, Lesley Larkin, Samuel Collins, Hamish Mohammed, Thomas Finnie, Luke Hounsome, Michael Borowitz, and Steven Riley",
        "link": "http://arxiv.org/abs/2405.14766v2",
        "abstract": "Advances in Large Language Models (LLMs) have led to significant interest in\ntheir potential to support human experts across a range of domains, including\npublic health. In this work we present automated evaluations of LLMs for public\nhealth tasks involving the classification and extraction of free text. We\ncombine six externally annotated datasets with seven new internally annotated\ndatasets to evaluate LLMs for processing text related to: health burden,\nepidemiological risk factors, and public health interventions. We evaluate\neleven open-weight LLMs (7-123 billion parameters) across all tasks using\nzero-shot in-context learning. We find that Llama-3.3-70B-Instruct is the\nhighest performing model, achieving the best results on 8/16 tasks (using\nmicro-F1 scores). We see significant variation across tasks with all\nopen-weight LLMs scoring below 60% micro-F1 on some challenging tasks, such as\nContact Classification, while all LLMs achieve greater than 80% micro-F1 on\nothers, such as GI Illness Classification. For a subset of 11 tasks, we also\nevaluate three GPT-4 and GPT-4o series models and find comparable results to\nLlama-3.3-70B-Instruct. Overall, based on these initial results we find\npromising signs that LLMs may be useful tools for public health experts to\nextract information from a wide variety of free text sources, and support\npublic health surveillance, research, and interventions."
    },
    {
        "date": "2024-05",
        "title": "Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study",
        "author": "Lena Schmidt, Kaitlyn Hair, Sergio Graziosi, Fiona Campbell, Claudia Kapp, Alireza Khanteymoori, Dawn Craig, Mark Engelbert, and James Thomas",
        "link": "http://arxiv.org/abs/2405.14445v2",
        "abstract": "This paper describes a rapid feasibility study of using GPT-4, a large\nlanguage model (LLM), to (semi)automate data extraction in systematic reviews.\nDespite the recent surge of interest in LLMs there is still a lack of\nunderstanding of how to design LLM-based automation tools and how to robustly\nevaluate their performance. During the 2023 Evidence Synthesis Hackathon we\nconducted two feasibility studies. Firstly, to automatically extract study\ncharacteristics from human clinical, animal, and social science domain studies.\nWe used two studies from each category for prompt-development; and ten for\nevaluation. Secondly, we used the LLM to predict Participants, Interventions,\nControls and Outcomes (PICOs) labelled within 100 abstracts in the EBM-NLP\ndataset. Overall, results indicated an accuracy of around 80%, with some\nvariability between domains (82% for human clinical, 80% for animal, and 72%\nfor studies of human social sciences). Causal inference methods and study\ndesign were the data extraction items with the most errors. In the PICO study,\nparticipants and intervention/control showed high accuracy (>80%), outcomes\nwere more challenging. Evaluation was done manually; scoring methods such as\nBLEU and ROUGE showed limited value. We observed variability in the LLMs\npredictions and changes in response quality. This paper presents a template for\nfuture evaluations of LLMs in the context of data extraction for systematic\nreview automation. Our results show that there might be value in using LLMs,\nfor example as second or third reviewers. However, caution is advised when\nintegrating models such as GPT-4 into tools. Further research on stability and\nreliability in practical settings is warranted for each type of data that is\nprocessed by the LLM."
    },
    {
        "date": "2024-05",
        "title": "A Set-based Approach for Feature Extraction of 3D CAD Models",
        "author": "Peng Xu, Qi Gao, and Ying-Jie Wu",
        "link": "http://arxiv.org/abs/2406.18543v1",
        "abstract": "Feature extraction is a critical technology to realize the automatic\ntransmission of feature information throughout product life cycles. As CAD\nmodels primarily capture the 3D geometry of products, feature extraction\nheavily relies on geometric information. However, existing feature extraction\nmethods often yield inaccurate outcomes due to the diverse interpretations of\ngeometric information. This report presents a set-based feature extraction\napproach to address this uncertainty issue. Unlike existing methods that seek\naccurate feature results, our approach aims to transform the uncertainty of\ngeometric information into a set of feature subgraphs. First, we define the\nconvexity of basic geometric entities and introduce the concept of two-level\nattributed adjacency graphs. Second, a feature extraction workflow is designed\nto determine feature boundaries and identify feature subgraphs from CAD models.\nThis set of feature subgraphs can be used for further feature recognition. A\nfeature extraction system is programmed using C++ and UG/Open to demonstrate\nthe feasibility of our proposed approach."
    },
    {
        "date": "2024-05",
        "title": "Dataset Mention Extraction in Scientific Articles Using Bi-LSTM-CRF Model",
        "author": "Tong Zeng, and Daniel Acuna",
        "link": "http://arxiv.org/abs/2405.13135v1",
        "abstract": "Datasets are critical for scientific research, playing an important role in\nreplication, reproducibility, and efficiency. Researchers have recently shown\nthat datasets are becoming more important for science to function properly,\neven serving as artifacts of study themselves. However, citing datasets is not\na common or standard practice in spite of recent efforts by data repositories\nand funding agencies. This greatly affects our ability to track their usage and\nimportance. A potential solution to this problem is to automatically extract\ndataset mentions from scientific articles. In this work, we propose to achieve\nsuch extraction by using a neural network based on a Bi-LSTM-CRF architecture.\nOur method achieves F1 = 0.885 in social science articles released as part of\nthe Rich Context Dataset. We discuss the limitations of the current datasets\nand propose modifications to the model to be done in the future."
    },
    {
        "date": "2024-05",
        "title": "Efficient Model-Stealing Attacks Against Inductive Graph Neural Networks",
        "author": "Marcin Podhajski, Jan Dubi\u0144ski, Franziska Boenisch, Adam Dziedzic, Agnieszka Pregowska, and Tomasz P. Michalak",
        "link": "http://arxiv.org/abs/2405.12295v4",
        "abstract": "Graph Neural Networks (GNNs) are recognized as potent tools for processing\nreal-world data organized in graph structures. Especially inductive GNNs, which\nallow for the processing of graph-structured data without relying on predefined\ngraph structures, are becoming increasingly important in a wide range of\napplications. As such these networks become attractive targets for\nmodel-stealing attacks where an adversary seeks to replicate the functionality\nof the targeted network. Significant efforts have been devoted to developing\nmodel-stealing attacks that extract models trained on images and texts.\nHowever, little attention has been given to stealing GNNs trained on graph\ndata. This paper identifies a new method of performing unsupervised\nmodel-stealing attacks against inductive GNNs, utilizing graph contrastive\nlearning and spectral graph augmentations to efficiently extract information\nfrom the targeted model. The new type of attack is thoroughly evaluated on six\ndatasets and the results show that our approach outperforms the current\nstate-of-the-art by Shen et al. (2021). In particular, our attack surpasses the\nbaseline across all benchmarks, attaining superior fidelity and downstream\naccuracy of the stolen model while necessitating fewer queries directed toward\nthe target model."
    },
    {
        "date": "2024-05",
        "title": "Fully Exploiting Every Real Sample: SuperPixel Sample Gradient Model Stealing",
        "author": "Yunlong Zhao, Xiaoheng Deng, Yijing Liu, Xinjun Pei, Jiazhi Xia, and Wei Chen",
        "link": "http://arxiv.org/abs/2406.18540v1",
        "abstract": "Model stealing (MS) involves querying and observing the output of a machine\nlearning model to steal its capabilities. The quality of queried data is\ncrucial, yet obtaining a large amount of real data for MS is often challenging.\nRecent works have reduced reliance on real data by using generative models.\nHowever, when high-dimensional query data is required, these methods are\nimpractical due to the high costs of querying and the risk of model collapse.\nIn this work, we propose using sample gradients (SG) to enhance the utility of\neach real sample, as SG provides crucial guidance on the decision boundaries of\nthe victim model. However, utilizing SG in the model stealing scenario faces\ntwo challenges: 1. Pixel-level gradient estimation requires extensive query\nvolume and is susceptible to defenses. 2. The estimation of sample gradients\nhas a significant variance. This paper proposes Superpixel Sample Gradient\nstealing (SPSG) for model stealing under the constraint of limited real\nsamples. With the basic idea of imitating the victim model's low-variance\npatch-level gradients instead of pixel-level gradients, SPSG achieves efficient\nsample gradient estimation through two steps. First, we perform patch-wise\nperturbations on query images to estimate the average gradient in different\nregions of the image. Then, we filter the gradients through a threshold\nstrategy to reduce variance. Exhaustive experiments demonstrate that, with the\nsame number of real samples, SPSG achieves accuracy, agreements, and\nadversarial success rate significantly surpassing the current state-of-the-art\nMS methods. Codes are available at https://github.com/zyl123456aB/SPSG_attack."
    },
    {
        "date": "2024-05",
        "title": "Dynamic In-context Learning with Conversational Models for Data Extraction and Materials Property Prediction",
        "author": "Chinedu Ekuma",
        "link": "http://arxiv.org/abs/2405.10448v2",
        "abstract": "The advent of natural language processing and large language models (LLMs)\nhas revolutionized the extraction of data from unstructured scholarly papers.\nHowever, ensuring data trustworthiness remains a significant challenge. In this\npaper, we introduce PropertyExtractor, an open-source tool that leverages\nadvanced conversational LLMs like Google gemini-pro and OpenAI gpt-4, blends\nzero-shot with few-shot in-context learning, and employs engineered prompts for\nthe dynamic refinement of structured information hierarchies - enabling\nautonomous, efficient, scalable, and accurate identification, extraction, and\nverification of material property data. Our tests on material data demonstrate\nprecision and recall that exceed 95\\% with an error rate of approximately 9%,\nhighlighting the effectiveness and versatility of the toolkit. Finally,\ndatabases for 2D material thicknesses, a critical parameter for device\nintegration, and energy bandgap values are developed using PropertyExtractor.\nSpecifically for the thickness database, the rapid evolution of the field has\noutpaced both experimental measurements and computational methods, creating a\nsignificant data gap. Our work addresses this gap and showcases the potential\nof PropertyExtractor as a reliable and efficient tool for the autonomous\ngeneration of various material property databases, advancing the field."
    },
    {
        "date": "2024-05",
        "title": "Unsupervised Work Behavior Pattern Extraction Based on Hierarchical Probabilistic Model",
        "author": "Issei Saito, Tomoaki Nakamura, Toshiyuki Hatta, Wataru Fujita, Shintaro Watanabe, and Shotaro Miwa",
        "link": "http://arxiv.org/abs/2405.09838v1",
        "abstract": "Evolving consumer demands and market trends have led to businesses\nincreasingly embracing a production approach that prioritizes flexibility and\ncustomization. Consequently, factory workers must engage in tasks that are more\ncomplex than before. Thus, productivity depends on each worker's skills in\nassembling products. Therefore, analyzing the behavior of a worker is crucial\nfor work improvement. However, manual analysis is time consuming and does not\nprovide quick and accurate feedback. Machine learning have been attempted to\nautomate the analyses; however, most of these methods need several labels for\ntraining. To this end, we extend the Gaussian process hidden semi-Markov model\n(GP-HSMM), to enable the rapid and automated analysis of worker behavior\nwithout pre-training. The model does not require labeled data and can\nautomatically and accurately segment continuous motions into motion classes.\nThe proposed model is a probabilistic model that hierarchically connects\nGP-HSMM and HSMM, enabling the extraction of behavioral patterns with different\ngranularities. Furthermore, it mutually infers the parameters between the\nGP-HSMM and HSMM, resulting in accurate motion pattern extraction. We applied\nthe proposed method to motion data in which workers assembled products at an\nactual production site. The accuracy of behavior pattern extraction was\nevaluated using normalized Levenshtein distance (NLD). The smaller the value of\nNLD, the more accurate is the pattern extraction. The NLD of motion patterns\ncaptured by GP-HSMM and HSMM layers in our proposed method was 0.50 and 0.33,\nrespectively, which are the smallest compared to that of the baseline methods."
    },
    {
        "date": "2024-05",
        "title": "The object detection model uses combined extraction with KNN and RF classification",
        "author": "Florentina Tatrin Kurniati, Daniel HF Manongga, Irwan Sembiring, Sutarto Wijono, and Roy Rudolf Huizen",
        "link": "http://arxiv.org/abs/2405.05551v1",
        "abstract": "Object detection plays an important role in various fields. Developing\ndetection models for 2D objects that experience rotation and texture variations\nis a challenge. In this research, the initial stage of the proposed model\nintegrates the gray-level co-occurrence matrix (GLCM) and local binary patterns\n(LBP) texture feature extraction to obtain feature vectors. The next stage is\nclassifying features using k-nearest neighbors (KNN) and random forest (RF), as\nwell as voting ensemble (VE). System testing used a dataset of 4,437 2D images,\nthe results for KNN accuracy were 92.7% and F1-score 92.5%, while RF\nperformance was lower. Although GLCM features improve performance on both\nalgorithms, KNN is more consistent. The VE approach provides the best\nperformance with an accuracy of 93.9% and an F1 score of 93.8%, this shows the\neffectiveness of the ensemble technique in increasing object detection\naccuracy. This study contributes to the field of object detection with a new\napproach combining GLCM and LBP as feature vectors as well as VE for\nclassification"
    },
    {
        "date": "2024-05",
        "title": "Special Characters Attack: Toward Scalable Training Data Extraction From Large Language Models",
        "author": "Yang Bai, Ge Pei, Jindong Gu, Yong Yang, and Xingjun Ma",
        "link": "http://arxiv.org/abs/2405.05990v2",
        "abstract": "Large language models (LLMs) have achieved remarkable performance on a wide\nrange of tasks. However, recent studies have shown that LLMs can memorize\ntraining data and simple repeated tokens can trick the model to leak the data.\nIn this paper, we take a step further and show that certain special characters\nor their combinations with English letters are stronger memory triggers,\nleading to more severe data leakage. The intuition is that, since LLMs are\ntrained with massive data that contains a substantial amount of special\ncharacters (e.g. structural symbols {, } of JSON files, and @, # in emails and\nonline posts), the model may memorize the co-occurrence between these special\ncharacters and the raw texts. This motivates us to propose a simple but\neffective Special Characters Attack (SCA) to induce training data leakage. Our\nexperiments verify the high effectiveness of SCA against state-of-the-art LLMs:\nthey can leak diverse training data, such as code corpus, web pages, and\npersonally identifiable information, and sometimes generate non-stop outputs as\na byproduct. We further show that the composition of the training data corpus\ncan be revealed by inspecting the leaked data -- one crucial piece of\ninformation for pre-training high-performance LLMs. Our work can help\nunderstand the sensitivity of LLMs to special characters and identify potential\nareas for improvement."
    },
    {
        "date": "2024-05",
        "title": "Lightweight Spatial Modeling for Combinatorial Information Extraction From Documents",
        "author": "Yanfei Dong, Lambert Deng, Jiazheng Zhang, Xiaodong Yu, Ting Lin, Francesco Gelli, Soujanya Poria, and Wee Sun Lee",
        "link": "http://arxiv.org/abs/2405.06701v1",
        "abstract": "Documents that consist of diverse templates and exhibit complex spatial\nstructures pose a challenge for document entity classification. We propose\nKNN-former, which incorporates a new kind of spatial bias in attention\ncalculation based on the K-nearest-neighbor (KNN) graph of document entities.\nWe limit entities' attention only to their local radius defined by the KNN\ngraph. We also use combinatorial matching to address the one-to-one mapping\nproperty that exists in many documents, where one field has only one\ncorresponding entity. Moreover, our method is highly parameter-efficient\ncompared to existing approaches in terms of the number of trainable parameters.\nDespite this, experiments across various datasets show our method outperforms\nbaselines in most entity types. Many real-world documents exhibit combinatorial\nproperties which can be leveraged as inductive biases to improve extraction\naccuracy, but existing datasets do not cover these documents. To facilitate\nfuture research into these types of documents, we release a new ID document\ndataset that covers diverse templates and languages. We also release enhanced\nannotations for an existing dataset."
    },
    {
        "date": "2024-05",
        "title": "ModelShield: Adaptive and Robust Watermark against Model Extraction Attack",
        "author": "Kaiyi Pang, Tao Qi, Chuhan Wu, Minhao Bai, Minghu Jiang, and Yongfeng Huang",
        "link": "http://arxiv.org/abs/2405.02365v4",
        "abstract": "Large language models (LLMs) demonstrate general intelligence across a\nvariety of machine learning tasks, thereby enhancing the commercial value of\ntheir intellectual property (IP). To protect this IP, model owners typically\nallow user access only in a black-box manner, however, adversaries can still\nutilize model extraction attacks to steal the model intelligence encoded in\nmodel generation. Watermarking technology offers a promising solution for\ndefending against such attacks by embedding unique identifiers into the\nmodel-generated content. However, existing watermarking methods often\ncompromise the quality of generated content due to heuristic alterations and\nlack robust mechanisms to counteract adversarial strategies, thus limiting\ntheir practicality in real-world scenarios. In this paper, we introduce an\nadaptive and robust watermarking method (named ModelShield) to protect the IP\nof LLMs. Our method incorporates a self-watermarking mechanism that allows LLMs\nto autonomously insert watermarks into their generated content to avoid the\ndegradation of model content. We also propose a robust watermark detection\nmechanism capable of effectively identifying watermark signals under the\ninterference of varying adversarial strategies. Besides, ModelShield is a\nplug-and-play method that does not require additional model training, enhancing\nits applicability in LLM deployments. Extensive evaluations on two real-world\ndatasets and three LLMs demonstrate that our method surpasses existing methods\nin terms of defense effectiveness and robustness while significantly reducing\nthe degradation of watermarking on the model-generated content."
    },
    {
        "date": "2024-05",
        "title": "Automatically Extracting Numerical Results from Randomized Controlled Trials with Large Language Models",
        "author": "Hye Sun Yun, David Pogrebitskiy, Iain J. Marshall, and Byron C. Wallace",
        "link": "http://arxiv.org/abs/2405.01686v2",
        "abstract": "Meta-analyses statistically aggregate the findings of different randomized\ncontrolled trials (RCTs) to assess treatment effectiveness. Because this yields\nrobust estimates of treatment effectiveness, results from meta-analyses are\nconsidered the strongest form of evidence. However, rigorous evidence syntheses\nare time-consuming and labor-intensive, requiring manual extraction of data\nfrom individual trials to be synthesized. Ideally, language technologies would\npermit fully automatic meta-analysis, on demand. This requires accurately\nextracting numerical results from individual trials, which has been beyond the\ncapabilities of natural language processing (NLP) models to date. In this work,\nwe evaluate whether modern large language models (LLMs) can reliably perform\nthis task. We annotate (and release) a modest but granular evaluation dataset\nof clinical trial reports with numerical findings attached to interventions,\ncomparators, and outcomes. Using this dataset, we evaluate the performance of\nseven LLMs applied zero-shot for the task of conditionally extracting numerical\nfindings from trial reports. We find that massive LLMs that can accommodate\nlengthy inputs are tantalizingly close to realizing fully automatic\nmeta-analysis, especially for dichotomous (binary) outcomes (e.g., mortality).\nHowever, LLMs -- including ones trained on biomedical texts -- perform poorly\nwhen the outcome measures are complex and tallying the results requires\ninference. This work charts a path toward fully automatic meta-analysis of RCTs\nvia LLMs, while also highlighting the limitations of existing models for this\naim."
    },
    {
        "date": "2024-05",
        "title": "Enhancing Language Models for Financial Relation Extraction with Named Entities and Part-of-Speech",
        "author": "Menglin Li, and Kwan Hui Lim",
        "link": "http://arxiv.org/abs/2405.06665v1",
        "abstract": "The Financial Relation Extraction (FinRE) task involves identifying the\nentities and their relation, given a piece of financial statement/text. To\nsolve this FinRE problem, we propose a simple but effective strategy that\nimproves the performance of pre-trained language models by augmenting them with\nNamed Entity Recognition (NER) and Part-Of-Speech (POS), as well as different\napproaches to combine these information. Experiments on a financial relations\ndataset show promising results and highlights the benefits of incorporating NER\nand POS in existing models. Our dataset and codes are available at\nhttps://github.com/kwanhui/FinRelExtract."
    },
    {
        "date": "2024-04",
        "title": "ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction",
        "author": "Yupeng Cao, Zhi Chen, Qingyun Pei, Nathan Jinseok Lee, K. P. Subbalakshmi, and Papa Momar Ndiaye",
        "link": "http://arxiv.org/abs/2404.18470v2",
        "abstract": "In the realm of financial analytics, leveraging unstructured data, such as\nearnings conference calls (ECCs), to forecast stock volatility is a critical\nchallenge that has attracted both academics and investors. While previous\nstudies have used multimodal deep learning-based models to obtain a general\nview of ECCs for volatility predicting, they often fail to capture detailed,\ncomplex information. Our research introduces a novel framework: \\textbf{ECC\nAnalyzer}, which utilizes large language models (LLMs) to extract richer, more\npredictive content from ECCs to aid the model's prediction performance. We use\nthe pre-trained large models to extract textual and audio features from ECCs\nand implement a hierarchical information extraction strategy to extract more\nfine-grained information. This strategy first extracts paragraph-level general\ninformation by summarizing the text and then extracts fine-grained focus\nsentences using Retrieval-Augmented Generation (RAG). These features are then\nfused through multimodal feature fusion to perform volatility prediction.\nExperimental results demonstrate that our model outperforms traditional\nanalytical benchmarks, confirming the effectiveness of advanced LLM techniques\nin financial analysis."
    },
    {
        "date": "2024-04",
        "title": "Learnable Linguistic Watermarks for Tracing Model Extraction Attacks on Large Language Models",
        "author": "Minhao Bai, Kaiyi Pang, and Yongfeng Huang",
        "link": "http://arxiv.org/abs/2405.01509v1",
        "abstract": "In the rapidly evolving domain of artificial intelligence, safeguarding the\nintellectual property of Large Language Models (LLMs) is increasingly crucial.\nCurrent watermarking techniques against model extraction attacks, which rely on\nsignal insertion in model logits or post-processing of generated text, remain\nlargely heuristic. We propose a novel method for embedding learnable linguistic\nwatermarks in LLMs, aimed at tracing and preventing model extraction attacks.\nOur approach subtly modifies the LLM's output distribution by introducing\ncontrolled noise into token frequency distributions, embedding an statistically\nidentifiable controllable watermark.We leverage statistical hypothesis testing\nand information theory, particularly focusing on Kullback-Leibler Divergence,\nto differentiate between original and modified distributions effectively. Our\nwatermarking method strikes a delicate well balance between robustness and\noutput quality, maintaining low false positive/negative rates and preserving\nthe LLM's original performance."
    },
    {
        "date": "2024-04",
        "title": "Utilizing Large Language Models for Information Extraction from Real Estate Transactions",
        "author": "Yu Zhao, and Haoxiang Gao",
        "link": "http://arxiv.org/abs/2404.18043v2",
        "abstract": "Real estate sales contracts contain crucial information for property\ntransactions, but manual data extraction can be time-consuming and error-prone.\nThis paper explores the application of large language models, specifically\ntransformer-based architectures, for automated information extraction from real\nestate contracts. We discuss challenges, techniques, and future directions in\nleveraging these models to improve efficiency and accuracy in real estate\ncontract analysis. We generated synthetic contracts using the real-world\ntransaction dataset, thereby fine-tuning the large-language model and achieving\nsignificant metrics improvements and qualitative improvements in information\nretrieval and reasoning tasks."
    },
    {
        "date": "2024-04",
        "title": "Empirical Analysis of Dialogue Relation Extraction with Large Language Models",
        "author": "Guozheng Li, Zijie Xu, Ziyu Shang, Jiajun Liu, Ke Ji, and Yikai Guo",
        "link": "http://arxiv.org/abs/2404.17802v1",
        "abstract": "Dialogue relation extraction (DRE) aims to extract relations between two\narguments within a dialogue, which is more challenging than standard RE due to\nthe higher person pronoun frequency and lower information density in dialogues.\nHowever, existing DRE methods still suffer from two serious issues: (1) hard to\ncapture long and sparse multi-turn information, and (2) struggle to extract\ngolden relations based on partial dialogues, which motivates us to discover\nmore effective methods that can alleviate the above issues. We notice that the\nrise of large language models (LLMs) has sparked considerable interest in\nevaluating their performance across diverse tasks. To this end, we initially\ninvestigate the capabilities of different LLMs in DRE, considering both\nproprietary models and open-source models. Interestingly, we discover that LLMs\nsignificantly alleviate two issues in existing DRE methods. Generally, we have\nfollowing findings: (1) scaling up model size substantially boosts the overall\nDRE performance and achieves exceptional results, tackling the difficulty of\ncapturing long and sparse multi-turn information; (2) LLMs encounter with much\nsmaller performance drop from entire dialogue setting to partial dialogue\nsetting compared to existing methods; (3) LLMs deliver competitive or superior\nperformances under both full-shot and few-shot settings compared to current\nstate-of-the-art; (4) LLMs show modest performances on inverse relations but\nmuch stronger improvements on general relations, and they can handle dialogues\nof various lengths especially for longer sequences."
    },
    {
        "date": "2024-04",
        "title": "GraphER: A Structure-aware Text-to-Graph Model for Entity and Relation Extraction",
        "author": "Urchade Zaratiana, Nadi Tomeh, Niama El Khbir, Pierre Holat, and Thierry Charnois",
        "link": "http://arxiv.org/abs/2404.12491v1",
        "abstract": "Information extraction (IE) is an important task in Natural Language\nProcessing (NLP), involving the extraction of named entities and their\nrelationships from unstructured text. In this paper, we propose a novel\napproach to this task by formulating it as graph structure learning (GSL). By\nformulating IE as GSL, we enhance the model's ability to dynamically refine and\noptimize the graph structure during the extraction process. This formulation\nallows for better interaction and structure-informed decisions for entity and\nrelation prediction, in contrast to previous models that have separate or\nuntied predictions for these tasks. When compared against state-of-the-art\nbaselines on joint entity and relation extraction benchmarks, our model,\nGraphER, achieves competitive results."
    },
    {
        "date": "2024-04",
        "title": "AI-Enhanced Cognitive Behavioral Therapy: Deep Learning and Large Language Models for Extracting Cognitive Pathways from Social Media Texts",
        "author": "Meng Jiang, Yi Jing Yu, Qing Zhao, Jianqiang Li, Changwei Song, Hongzhi Qi, Wei Zhai, Dan Luo, Xiaoqin Wang, Guanghui Fu, and Bing Xiang Yang",
        "link": "http://arxiv.org/abs/2404.11449v1",
        "abstract": "Cognitive Behavioral Therapy (CBT) is an effective technique for addressing\nthe irrational thoughts stemming from mental illnesses, but it necessitates\nprecise identification of cognitive pathways to be successfully implemented in\npatient care. In current society, individuals frequently express negative\nemotions on social media on specific topics, often exhibiting cognitive\ndistortions, including suicidal behaviors in extreme cases. Yet, there is a\nnotable absence of methodologies for analyzing cognitive pathways that could\naid psychotherapists in conducting effective interventions online. In this\nstudy, we gathered data from social media and established the task of\nextracting cognitive pathways, annotating the data based on a cognitive\ntheoretical framework. We initially categorized the task of extracting\ncognitive pathways as a hierarchical text classification with four main\ncategories and nineteen subcategories. Following this, we structured a text\nsummarization task to help psychotherapists quickly grasp the essential\ninformation. Our experiments evaluate the performance of deep learning and\nlarge language models (LLMs) on these tasks. The results demonstrate that our\ndeep learning method achieved a micro-F1 score of 62.34% in the hierarchical\ntext classification task. Meanwhile, in the text summarization task, GPT-4\nattained a Rouge-1 score of 54.92 and a Rouge-2 score of 30.86, surpassing the\nexperimental deep learning model's performance. However, it may suffer from an\nissue of hallucination. We have made all models and codes publicly available to\nsupport further research in this field."
    },
    {
        "date": "2024-04",
        "title": "TransLinkGuard: Safeguarding Transformer Models Against Model Stealing in Edge Deployment",
        "author": "Qinfeng Li, Zhiqiang Shen, Zhenghan Qin, Yangfan Xie, Xuhong Zhang, Tianyu Du, and Jianwei Yin",
        "link": "http://arxiv.org/abs/2404.11121v2",
        "abstract": "Proprietary large language models (LLMs) have been widely applied in various\nscenarios. Additionally, deploying LLMs on edge devices is trending for\nefficiency and privacy reasons. However, edge deployment of proprietary LLMs\nintroduces new security challenges: edge-deployed models are exposed as\nwhite-box accessible to users, enabling adversaries to conduct effective model\nstealing (MS) attacks. Unfortunately, existing defense mechanisms fail to\nprovide effective protection. Specifically, we identify four critical\nprotection properties that existing methods fail to simultaneously satisfy: (1)\nmaintaining protection after a model is physically copied; (2) authorizing\nmodel access at request level; (3) safeguarding runtime reverse engineering;\n(4) achieving high security with negligible runtime overhead. To address the\nabove issues, we propose TransLinkGuard, a plug-and-play model protection\napproach against model stealing on edge devices. The core part of\nTransLinkGuard is a lightweight authorization module residing in a secure\nenvironment, e.g., TEE. The authorization module can freshly authorize each\nrequest based on its input. Extensive experiments show that TransLinkGuard\nachieves the same security protection as the black-box security guarantees with\nnegligible overhead."
    },
    {
        "date": "2024-04",
        "title": "A LayoutLMv3-Based Model for Enhanced Relation Extraction in Visually-Rich Documents",
        "author": "Wiam Adnan, Joel Tang, Yassine Bel Khayat Zouggari, Seif Edinne Laatiri, Laurent Lam, and Fabien Caspani",
        "link": "http://arxiv.org/abs/2404.10848v1",
        "abstract": "Document Understanding is an evolving field in Natural Language Processing\n(NLP). In particular, visual and spatial features are essential in addition to\nthe raw text itself and hence, several multimodal models were developed in the\nfield of Visual Document Understanding (VDU). However, while research is mainly\nfocused on Key Information Extraction (KIE), Relation Extraction (RE) between\nidentified entities is still under-studied. For instance, RE is crucial to\nregroup entities or obtain a comprehensive hierarchy of data in a document. In\nthis paper, we present a model that, initialized from LayoutLMv3, can match or\noutperform the current state-of-the-art results in RE applied to Visually-Rich\nDocuments (VRD) on FUNSD and CORD datasets, without any specific pre-training\nand with fewer parameters. We also report an extensive ablation study performed\non FUNSD, highlighting the great impact of certain features and modelization\nchoices on the performances."
    },
    {
        "date": "2024-04",
        "title": "Relation Extraction Using Large Language Models: A Case Study on Acupuncture Point Locations",
        "author": "Yiming Li, Xueqing Peng, Jianfu Li, Xu Zuo, Suyuan Peng, Donghong Pei, Cui Tao, Hua Xu, and Na Hong",
        "link": "http://arxiv.org/abs/2404.05415v2",
        "abstract": "In acupuncture therapy, the accurate location of acupoints is essential for\nits effectiveness. The advanced language understanding capabilities of large\nlanguage models (LLMs) like Generative Pre-trained Transformers (GPT) present a\nsignificant opportunity for extracting relations related to acupoint locations\nfrom textual knowledge sources. This study aims to compare the performance of\nGPT with traditional deep learning models (Long Short-Term Memory (LSTM) and\nBidirectional Encoder Representations from Transformers for Biomedical Text\nMining (BioBERT)) in extracting acupoint-related location relations and assess\nthe impact of pretraining and fine-tuning on GPT's performance. We utilized the\nWorld Health Organization Standard Acupuncture Point Locations in the Western\nPacific Region (WHO Standard) as our corpus, which consists of descriptions of\n361 acupoints. Five types of relations ('direction_of,' 'distance_of,'\n'part_of,' 'near_acupoint,' and 'located_near') (n= 3,174) between acupoints\nwere annotated. Five models were compared: BioBERT, LSTM, pre-trained GPT-3.5,\nfine-tuned GPT-3.5, as well as pre-trained GPT-4. Performance metrics included\nmicro-average exact match precision, recall, and F1 scores. Our results\ndemonstrate that fine-tuned GPT-3.5 consistently outperformed other models in\nF1 scores across all relation types. Overall, it achieved the highest\nmicro-average F1 score of 0.92. This study underscores the effectiveness of\nLLMs like GPT in extracting relations related to acupoint locations, with\nimplications for accurately modeling acupuncture knowledge and promoting\nstandard implementation in acupuncture training and practice. The findings also\ncontribute to advancing informatics applications in traditional and\ncomplementary medicine, showcasing the potential of LLMs in natural language\nprocessing."
    },
    {
        "date": "2024-04",
        "title": "PerkwE_COQA: Enhanced Persian Conversational Question Answering by combining contextual keyword extraction with Large Language Models",
        "author": "Pardis Moradbeiki, and Nasser Ghadiri",
        "link": "http://arxiv.org/abs/2404.05406v2",
        "abstract": "Smart cities need the involvement of their residents to enhance quality of\nlife. Conversational query-answering is an emerging approach for user\nengagement. There is an increasing demand of an advanced conversational\nquestion-answering that goes beyond classic systems. Existing approaches have\nshown that LLMs offer promising capabilities for CQA, but may struggle to\ncapture the nuances of conversational contexts. The new approach involves\nunderstanding the content and engaging in a multi-step conversation with the\nuser to fulfill their needs. This paper presents a novel method to elevate the\nperformance of Persian Conversational question-answering (CQA) systems. It\ncombines the strengths of Large Language Models (LLMs) with contextual keyword\nextraction. Our method extracts keywords specific to the conversational flow,\nproviding the LLM with additional context to understand the user's intent and\ngenerate more relevant and coherent responses. We evaluated the effectiveness\nof this combined approach through various metrics, demonstrating significant\nimprovements in CQA performance compared to an LLM-only baseline. The proposed\nmethod effectively handles implicit questions, delivers contextually relevant\nanswers, and tackles complex questions that rely heavily on conversational\ncontext. The findings indicate that our method outperformed the evaluation\nbenchmarks up to 8% higher than existing methods and the LLM-only baseline."
    },
    {
        "date": "2024-04",
        "title": "GLCM-Based Feature Combination for Extraction Model Optimization in Object Detection Using Machine Learning",
        "author": "Florentina Tatrin Kurniati, Daniel HF Manongga, Eko Sediyono, Sri Yulianto Joko Prasetyo, and Roy Rudolf Huizen",
        "link": "http://arxiv.org/abs/2404.04578v1",
        "abstract": "In the era of modern technology, object detection using the Gray Level\nCo-occurrence Matrix (GLCM) extraction method plays a crucial role in object\nrecognition processes. It finds applications in real-time scenarios such as\nsecurity surveillance and autonomous vehicle navigation, among others.\nComputational efficiency becomes a critical factor in achieving real-time\nobject detection. Hence, there is a need for a detection model with low\ncomplexity and satisfactory accuracy. This research aims to enhance\ncomputational efficiency by selecting appropriate features within the GLCM\nframework. Two classification models, namely K-Nearest Neighbours (K-NN) and\nSupport Vector Machine (SVM), were employed, with the results indicating that\nK-Nearest Neighbours (K-NN) outperforms SVM in terms of computational\ncomplexity. Specifically, K-NN, when utilizing a combination of Correlation,\nEnergy, and Homogeneity features, achieves a 100% accuracy rate with low\ncomplexity. Moreover, when using a combination of Energy and Homogeneity\nfeatures, K-NN attains an almost perfect accuracy level of 99.9889%, while\nmaintaining low complexity. On the other hand, despite SVM achieving 100%\naccuracy in certain feature combinations, its high or very high complexity can\npose challenges, particularly in real-time applications. Therefore, based on\nthe trade-off between accuracy and complexity, the K-NN model with a\ncombination of Correlation, Energy, and Homogeneity features emerges as a more\nsuitable choice for real-time applications that demand high accuracy and low\ncomplexity. This research provides valuable insights for optimizing object\ndetection in various applications requiring both high accuracy and rapid\nresponsiveness."
    },
    {
        "date": "2024-04",
        "title": "Knowledge Distillation-Based Model Extraction Attack using GAN-based Private Counterfactual Explanations",
        "author": "Fatima Ezzeddine, Omran Ayoub, and Silvia Giordano",
        "link": "http://arxiv.org/abs/2404.03348v2",
        "abstract": "In recent years, there has been a notable increase in the deployment of\nmachine learning (ML) models as services (MLaaS) across diverse production\nsoftware applications. In parallel, explainable AI (XAI) continues to evolve,\naddressing the necessity for transparency and trustworthiness in ML models. XAI\ntechniques aim to enhance the transparency of ML models by providing insights,\nin terms of model's explanations, into their decision-making process.\nSimultaneously, some MLaaS platforms now offer explanations alongside the ML\nprediction outputs. This setup has elevated concerns regarding vulnerabilities\nin MLaaS, particularly in relation to privacy leakage attacks such as model\nextraction attacks (MEA). This is due to the fact that explanations can unveil\ninsights about the inner workings of the model which could be exploited by\nmalicious users. In this work, we focus on investigating how model\nexplanations, particularly counterfactual explanations (CFs), can be exploited\nfor performing MEA within the MLaaS platform. We also delve into assessing the\neffectiveness of incorporating differential privacy (DP) as a mitigation\nstrategy. To this end, we first propose a novel approach for MEA based on\nKnowledge Distillation (KD) to enhance the efficiency of extracting a\nsubstitute model of a target model exploiting CFs, without any knowledge about\nthe training data distribution by the attacker. Then, we advise an approach for\ntraining CF generators incorporating DP to generate private CFs. We conduct\nthorough experimental evaluations on real-world datasets and demonstrate that\nour proposed KD-based MEA can yield a high-fidelity substitute model with a\nreduced number of queries with respect to baseline approaches. Furthermore, our\nfindings reveal that including a privacy layer can allow mitigating the MEA.\nHowever, on the account of the quality of CFs, impacts the performance of the\nexplanations."
    },
    {
        "date": "2024-04",
        "title": "Comparative Study of Domain Driven Terms Extraction Using Large Language Models",
        "author": "Sandeep Chataut, Tuyen Do, Bichar Dip Shrestha Gurung, Shiva Aryal, Anup Khanal, Carol Lushbough, and Etienne Gnimpieba",
        "link": "http://arxiv.org/abs/2404.02330v1",
        "abstract": "Keywords play a crucial role in bridging the gap between human understanding\nand machine processing of textual data. They are essential to data enrichment\nbecause they form the basis for detailed annotations that provide a more\ninsightful and in-depth view of the underlying data. Keyword/domain driven term\nextraction is a pivotal task in natural language processing, facilitating\ninformation retrieval, document summarization, and content categorization. This\nreview focuses on keyword extraction methods, emphasizing the use of three\nmajor Large Language Models(LLMs): Llama2-7B, GPT-3.5, and Falcon-7B. We\nemployed a custom Python package to interface with these LLMs, simplifying\nkeyword extraction. Our study, utilizing the Inspec and PubMed datasets,\nevaluates the performance of these models. The Jaccard similarity index was\nused for assessment, yielding scores of 0.64 (Inspec) and 0.21 (PubMed) for\nGPT-3.5, 0.40 and 0.17 for Llama2-7B, and 0.23 and 0.12 for Falcon-7B. This\npaper underlines the role of prompt engineering in LLMs for better keyword\nextraction and discusses the impact of hallucination in LLMs on result\nevaluation. It also sheds light on the challenges in using LLMs for keyword\nextraction, including model complexity, resource demands, and optimization\ntechniques."
    },
    {
        "date": "2024-04",
        "title": "Towards System Modelling to Support Diseases Data Extraction from the Electronic Health Records for Physicians Research Activities",
        "author": "Bushra F. Alsaqer, Alaa F. Alsaqer, and Amna Asif",
        "link": "http://arxiv.org/abs/2404.01218v1",
        "abstract": "The use of Electronic Health Records (EHRs) has increased dramatically in the\npast 15 years, as, it is considered an important source of managing data od\npatients. The EHRs are primary sources of disease diagnosis and demographic\ndata of patients worldwide. Therefore, the data can be utilized for secondary\ntasks such as research. This paper aims to make such data usable for research\nactivities such as monitoring disease statistics for a specific population. As\na result, the researchers can detect the disease causes for the behavior and\nlifestyle of the target group. One of the limitations of EHRs systems is that\nthe data is not available in the standard format but in various forms.\nTherefore, it is required to first convert the names of the diseases and\ndemographics data into one standardized form to make it usable for research\nactivities. There is a large amount of EHRs available, and solving the\nstandardizing issues requires some optimized techniques. We used a first-hand\nEHR dataset extracted from EHR systems. Our application uploads the dataset\nfrom the EHRs and converts it to the ICD-10 coding system to solve the\nstandardization problem. So, we first apply the steps of pre-processing,\nannotation, and transforming the data to convert it into the standard form. The\ndata pre-processing is applied to normalize demographic formats. In the\nannotation step, a machine learning model is used to recognize the diseases\nfrom the text. Furthermore, the transforming step converts the disease name to\nthe ICD-10 coding format. The model was evaluated manually by comparing its\nperformance in terms of disease recognition with an available dictionary-based\nsystem (MetaMap). The accuracy of the proposed machine learning model is 81%,\nthat outperformed MetaMap accuracy of 67%. This paper contributed to system\nmodelling for EHR data extraction to support research activities."
    },
    {
        "date": "2024-03",
        "title": "MIPS at SemEval-2024 Task 3: Multimodal Emotion-Cause Pair Extraction in Conversations with Multimodal Language Models",
        "author": "Zebang Cheng, Fuqiang Niu, Yuxiang Lin, Zhi-Qi Cheng, Bowen Zhang, and Xiaojiang Peng",
        "link": "http://arxiv.org/abs/2404.00511v3",
        "abstract": "This paper presents our winning submission to Subtask 2 of SemEval 2024 Task\n3 on multimodal emotion cause analysis in conversations. We propose a novel\nMultimodal Emotion Recognition and Multimodal Emotion Cause Extraction\n(MER-MCE) framework that integrates text, audio, and visual modalities using\nspecialized emotion encoders. Our approach sets itself apart from\ntop-performing teams by leveraging modality-specific features for enhanced\nemotion understanding and causality inference. Experimental evaluation\ndemonstrates the advantages of our multimodal approach, with our submission\nachieving a competitive weighted F1 score of 0.3435, ranking third with a\nmargin of only 0.0339 behind the 1st team and 0.0025 behind the 2nd team.\nProject: https://github.com/MIPS-COLT/MER-MCE.git"
    },
    {
        "date": "2024-03",
        "title": "Privacy Backdoors: Stealing Data with Corrupted Pretrained Models",
        "author": "Shanglun Feng, and Florian Tram\u00e8r",
        "link": "http://arxiv.org/abs/2404.00473v1",
        "abstract": "Practitioners commonly download pretrained machine learning models from open\nrepositories and finetune them to fit specific applications. We show that this\npractice introduces a new risk of privacy backdoors. By tampering with a\npretrained model's weights, an attacker can fully compromise the privacy of the\nfinetuning data. We show how to build privacy backdoors for a variety of\nmodels, including transformers, which enable an attacker to reconstruct\nindividual finetuning samples, with a guaranteed success! We further show that\nbackdoored models allow for tight privacy attacks on models trained with\ndifferential privacy (DP). The common optimistic practice of training DP models\nwith loose privacy guarantees is thus insecure if the model is not trusted.\nOverall, our work highlights a crucial and overlooked supply chain attack on\nmachine learning privacy."
    },
    {
        "date": "2024-03",
        "title": "Efficient Data-Free Model Stealing with Label Diversity",
        "author": "Yiyong Liu, Rui Wen, Michael Backes, and Yang Zhang",
        "link": "http://arxiv.org/abs/2404.00108v1",
        "abstract": "Machine learning as a Service (MLaaS) allows users to query the machine\nlearning model in an API manner, which provides an opportunity for users to\nenjoy the benefits brought by the high-performance model trained on valuable\ndata. This interface boosts the proliferation of machine learning based\napplications, while on the other hand, it introduces the attack surface for\nmodel stealing attacks. Existing model stealing attacks have relaxed their\nattack assumptions to the data-free setting, while keeping the effectiveness.\nHowever, these methods are complex and consist of several components, which\nobscure the core on which the attack really depends. In this paper, we revisit\nthe model stealing problem from a diversity perspective and demonstrate that\nkeeping the generated data samples more diverse across all the classes is the\ncritical point for improving the attack performance. Based on this conjecture,\nwe provide a simplified attack framework. We empirically signify our conjecture\nby evaluating the effectiveness of our attack, and experimental results show\nthat our approach is able to achieve comparable or even better performance\ncompared with the state-of-the-art method. Furthermore, benefiting from the\nabsence of redundant components, our method demonstrates its advantages in\nattack efficiency and query budget."
    },
    {
        "date": "2024-03",
        "title": "Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models",
        "author": "Hyunbyung Park, Sukyung Lee, Gyoungjin Gim, Yungi Kim, Dahyun Kim, and Chanjun Park",
        "link": "http://arxiv.org/abs/2403.19340v2",
        "abstract": "To address the challenges associated with data processing at scale, we\npropose Dataverse, a unified open-source Extract-Transform-Load (ETL) pipeline\nfor large language models (LLMs) with a user-friendly design at its core. Easy\naddition of custom processors with block-based interface in Dataverse allows\nusers to readily and efficiently use Dataverse to build their own ETL pipeline.\nWe hope that Dataverse will serve as a vital tool for LLM development and open\nsource the entire library to welcome community contribution. Additionally, we\nprovide a concise, two-minute video demonstration of our system, illustrating\nits capabilities and implementation."
    },
    {
        "date": "2024-03",
        "title": "MisGUIDE : Defense Against Data-Free Deep Learning Model Extraction",
        "author": "Mahendra Gurve, Sankar Behera, Satyadev Ahlawat, and Yamuna Prasad",
        "link": "http://arxiv.org/abs/2403.18580v1",
        "abstract": "The rise of Machine Learning as a Service (MLaaS) has led to the widespread\ndeployment of machine learning models trained on diverse datasets. These models\nare employed for predictive services through APIs, raising concerns about the\nsecurity and confidentiality of the models due to emerging vulnerabilities in\nprediction APIs. Of particular concern are model cloning attacks, where\nindividuals with limited data and no knowledge of the training dataset manage\nto replicate a victim model's functionality through black-box query access.\nThis commonly entails generating adversarial queries to query the victim model,\nthereby creating a labeled dataset.\n  This paper proposes \"MisGUIDE\", a two-step defense framework for Deep\nLearning models that disrupts the adversarial sample generation process by\nproviding a probabilistic response when the query is deemed OOD. The first step\nemploys a Vision Transformer-based framework to identify OOD queries, while the\nsecond step perturbs the response for such queries, introducing a probabilistic\nloss function to MisGUIDE the attackers. The aim of the proposed defense method\nis to reduce the accuracy of the cloned model while maintaining accuracy on\nauthentic queries. Extensive experiments conducted on two benchmark datasets\ndemonstrate that the proposed framework significantly enhances the resistance\nagainst state-of-the-art data-free model extraction in black-box settings."
    },
    {
        "date": "2024-03",
        "title": "A Path Towards Legal Autonomy: An interoperable and explainable approach to extracting, transforming, loading and computing legal information using large language models, expert systems and Bayesian networks",
        "author": "Axel Constant, Hannes Westermann, Bryan Wilson, Alex Kiefer, Ines Hipolito, Sylvain Pronovost, Steven Swanson, Mahault Albarracin, and Maxwell J. D. Ramstead",
        "link": "http://arxiv.org/abs/2403.18537v1",
        "abstract": "Legal autonomy - the lawful activity of artificial intelligence agents - can\nbe achieved in one of two ways. It can be achieved either by imposing\nconstraints on AI actors such as developers, deployers and users, and on AI\nresources such as data, or by imposing constraints on the range and scope of\nthe impact that AI agents can have on the environment. The latter approach\ninvolves encoding extant rules concerning AI driven devices into the software\nof AI agents controlling those devices (e.g., encoding rules about limitations\non zones of operations into the agent software of an autonomous drone device).\nThis is a challenge since the effectivity of such an approach requires a method\nof extracting, loading, transforming and computing legal information that would\nbe both explainable and legally interoperable, and that would enable AI agents\nto reason about the law. In this paper, we sketch a proof of principle for such\na method using large language models (LLMs), expert legal systems known as\nlegal decision paths, and Bayesian networks. We then show how the proposed\nmethod could be applied to extant regulation in matters of autonomous cars,\nsuch as the California Vehicle Code."
    }
]